=== PROJETO: animehub ===
=== ESTRUTURA VISUAL ===
.
‚îú‚îÄ‚îÄ DIR docs
‚îÇ   ‚îú‚îÄ‚îÄ [X] ANIMEHUB_TECHNICAL_BASELINE.md
‚îÇ   ‚îú‚îÄ‚îÄ [X] DATA_MODEL.md
‚îÇ   ‚îú‚îÄ‚îÄ [X] DOMAIN_CONTRACTS.md
‚îÇ   ‚îú‚îÄ‚îÄ [X] EVENT_MAP.md
‚îÇ   ‚îú‚îÄ‚îÄ [X] FOUNDATION SEAL.md
‚îÇ   ‚îú‚îÄ‚îÄ [X] PHASE_4_RESOLUTION_FREEZE.md
‚îÇ   ‚îú‚îÄ‚îÄ [X] README.md
‚îÇ   ‚îú‚îÄ‚îÄ [X] SERVICE_CONTRACTS.md
‚îÇ   ‚îú‚îÄ‚îÄ [X] UI_LAYOUT.md
‚îÇ   ‚îî‚îÄ‚îÄ [X] UI_PRINCIPLES.md
‚îú‚îÄ‚îÄ DIR .svelte-kit
‚îÇ   ‚îú‚îÄ‚îÄ DIR generated
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR client
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR nodes
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] 0.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] 1.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] 2.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] 3.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] 4.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] 5.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] 6.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] 7.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] app.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] matchers.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR server
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] internal.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] root.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] root.svelte
‚îÇ   ‚îú‚îÄ‚îÄ DIR types
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR src
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DIR routes
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ DIR anime
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ DIR [id]
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ [X] $types.d.ts
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ DIR calendar
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ [X] $types.d.ts
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ DIR library
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ [X] $types.d.ts
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ DIR statistics
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ [X] $types.d.ts
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ DIR subtitles
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ [X] $types.d.ts
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ [X] $types.d.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] route_meta_data.json
‚îÇ   ‚îú‚îÄ‚îÄ [X] ambient.d.ts
‚îÇ   ‚îú‚îÄ‚îÄ [X] non-ambient.d.ts
‚îÇ   ‚îî‚îÄ‚îÄ [ ] tsconfig.json
‚îú‚îÄ‚îÄ DIR src
‚îÇ   ‚îú‚îÄ‚îÄ DIR lib
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR api
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] anime.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] episode.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] file.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] playback.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] subtitle.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR anime
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] AnimeHeader.svelte
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] EpisodeItem.svelte
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] EpisodeList.svelte
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR calendar
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR common
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] Sidebar.svelte
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR library
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] AnimeCard.svelte
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] AnimeGrid.svelte
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR player
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR statistics
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DIR subtitles
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR stores
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] anime.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] episode.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] playback.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] ui.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DIR types
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ [X] anime.ts
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ [X] episode.ts
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ [X] events.ts
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ [X] file.ts
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ [X] subtitle.ts
‚îÇ   ‚îú‚îÄ‚îÄ DIR routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR anime
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DIR [id]
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ [X] +page.svelte
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR calendar
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] +page.svelte
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR library
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] +page.svelte
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR statistics
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] +page.svelte
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR subtitles
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] +page.svelte
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] +layout.svelte
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] +page.svelte
‚îÇ   ‚îú‚îÄ‚îÄ [X] app.css
‚îÇ   ‚îî‚îÄ‚îÄ [X] app.html
‚îú‚îÄ‚îÄ DIR src-tauri
‚îÇ   ‚îú‚îÄ‚îÄ DIR capabilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] default.json
‚îÇ   ‚îú‚îÄ‚îÄ DIR examples
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] anilist_query.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mpv_test.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] playback_e2e_test.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] playback_event_validation_test.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] playback_invalid_state_test.rs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] scan_validation_test.rs
‚îÇ   ‚îú‚îÄ‚îÄ DIR gen
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DIR schemas
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ [X] acl-manifests.json
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ [X] capabilities.json
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ [ ] desktop-schema.json
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ [ ] windows-schema.json
‚îÇ   ‚îú‚îÄ‚îÄ DIR icons
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR android
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR mipmap-anydpi-v26
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [ ] ic_launcher.xml
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR mipmap-hdpi
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher_foreground.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [ ] ic_launcher_round.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR mipmap-mdpi
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher_foreground.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [ ] ic_launcher_round.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR mipmap-xhdpi
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher_foreground.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [ ] ic_launcher_round.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR mipmap-xxhdpi
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher_foreground.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [ ] ic_launcher_round.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR mipmap-xxxhdpi
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] ic_launcher_foreground.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [ ] ic_launcher_round.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DIR values
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ [ ] ic_launcher_background.xml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR ios
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-20x20@1x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-20x20@2x-1.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-20x20@2x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-20x20@3x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-29x29@1x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-29x29@2x-1.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-29x29@2x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-29x29@3x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-40x40@1x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-40x40@2x-1.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-40x40@2x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-40x40@3x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-512@2x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-60x60@2x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-60x60@3x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-76x76@1x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] AppIcon-76x76@2x.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [ ] AppIcon-83.5x83.5@2x.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] 128x128.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] 128x128@2x.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] 32x32.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] 64x64.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] icon.icns
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] icon.ico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] icon.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] Square107x107Logo.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] Square142x142Logo.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] Square150x150Logo.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] Square284x284Logo.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] Square30x30Logo.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] Square310x310Logo.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] Square44x44Logo.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] Square71x71Logo.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [ ] Square89x89Logo.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [ ] StoreLogo.png
‚îÇ   ‚îú‚îÄ‚îÄ DIR migrations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] 005_materialization_records.sql
‚îÇ   ‚îú‚îÄ‚îÄ DIR src
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR app
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] materialization_init.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR application
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR commands
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] anime_commands.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] episode_commands.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] file_commands.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] playback_commands.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] statistics_commands.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR dto
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] error_handling.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] state.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR db
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] connection.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] migrations.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR domain
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR anime
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] entity.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] invariants.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR collection
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] entity.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR episode
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] entity.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] invariants.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR file
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] entity.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] invariants.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR models
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] statistics.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR resolution
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] value_objects.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR statistics
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] entity.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR subtitle
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] entity.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] invariants.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] anime_alias.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] external_reference.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR error
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] types.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR events
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR bus
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] event_bus.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR handlers
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] materialization_handler.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] materialization_events.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] resolution_events.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] types.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR infrastructure
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] subtitle_workspace.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR integrations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR anilist
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] client.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR mpv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] client.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] windows.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR repositories
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] anime_alias_repository.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] anime_repository.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] collection_repository.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] episode_repository.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] external_reference_repository.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] file_repository.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] materialization_repository.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] sqlite_materialization_repository.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] statistics_repository.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] subtitle_repository.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR services
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR services
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] anime_service.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] episode_service.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] external_integration_service.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] file_service.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] materialization_service.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] materialization_service_tests.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] materialization_types.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] playback_observer.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] playback_service.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] resolution_service.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] resolution_service_hardening_tests.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] resolution_service_tests.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] statistics_service.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] subtitle_service.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DIR utils
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [X] lib.rs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [X] main.rs
‚îÇ   ‚îú‚îÄ‚îÄ [X] build.rs
‚îÇ   ‚îú‚îÄ‚îÄ [ ] Cargo.lock
‚îÇ   ‚îú‚îÄ‚îÄ [X] Cargo.toml
‚îÇ   ‚îú‚îÄ‚îÄ [ ] run_tests.py
‚îÇ   ‚îú‚îÄ‚îÄ [X] schema.sql
‚îÇ   ‚îî‚îÄ‚îÄ [X] tauri.conf.json
‚îú‚îÄ‚îÄ [ ] .gitignore
‚îú‚îÄ‚îÄ [ ] app-icon.png
‚îú‚îÄ‚îÄ [ ] contexto_animehub.txt
‚îú‚îÄ‚îÄ [X] EVENTS_SYSTEM_DESIGN.md
‚îú‚îÄ‚îÄ [ ] pack.py
‚îú‚îÄ‚îÄ [ ] package-lock.json
‚îú‚îÄ‚îÄ [X] package.json
‚îú‚îÄ‚îÄ [ ] postcss.config.js
‚îú‚îÄ‚îÄ [X] README.md
‚îú‚îÄ‚îÄ [X] svelte.config.js
‚îú‚îÄ‚îÄ [X] tailwind.config.js
‚îú‚îÄ‚îÄ [ ] tsconfig.json
‚îî‚îÄ‚îÄ [X] vite.config.ts

============================================================
CONTE√öDO DOS ARQUIVOS (Ordenado: Docs -> Source)
============================================================

--- FILE: docs\ANIMEHUB_TECHNICAL_BASELINE.md ---
# AnimeHub ‚Äî Technical Baseline & Consolidated State

**Status:** Canonical  
**Last Updated:** 2026-01-10  
**Scope:** Entire AnimeHub codebase  
**Audience:** Engineers (human or AI)

---

## 1. Purpose of This Document

This document defines the **consolidated technical baseline** of the AnimeHub project after:

- Full contract reconciliation
- Removal of hallucinated APIs
- Elimination of invalid tests and mocks
- Structural stabilization of the codebase

Its purpose is to:

- Serve as a **single source of technical truth**
- Prevent architectural or contractual regression
- Define what the system **is**, **is not**, and **must remain**
- Provide a **safe foundation** for continued development

This document is **normative**, not descriptive.

---

## 2. Canonical References

The AnimeHub project is governed by **exactly two canonical artifacts**:

1. **The source code repository**
2. **`Verified AnimeHub Contracts`**

No other documents, comments, or historical intentions override these.

If a conflict arises:
- Contracts > code
- This document constrains interpretation
- Assumptions are invalid

---

## 3. Architectural Closure

The following architectural decisions are **closed and final**:

- Repository-based domain access
- Explicit domain events
- Deterministic materialization
- No implicit orchestration layers
- No generic managers or helpers

Any change to these requires **explicit contract evolution**, not refactoring.

---

## 4. Verified System Guarantees

The system **guarantees** the following invariants:

### 4.1 Determinism
- Fingerprints, IDs, and outcomes are derived exclusively from inputs
- No timestamps, randomness, or external state influence core logic

### 4.2 Idempotency
- Replaying the same event produces no duplicate state
- Materialization is safe to re-run

### 4.3 Explicit Error Propagation
- Errors are never swallowed
- All failures are represented in `AppError` or domain errors
- No silent fallback logic exists

### 4.4 Contract Integrity
- Every method call corresponds to a declared trait method
- Every enum match uses declared variants only
- No implicit fields or dynamic access patterns exist

---

## 5. Explicit Non-Existence (Important)

The following are **explicitly NOT part of the system**:

- `FileRepository::list_by_type`
- `EpisodeRepository::get_linked_files`
- Any mock repository implementations
- Any enum variants not listed in `Verified AnimeHub Contracts`
- Any implicit resolution helpers
- Any background automation or schedulers

Code or tests assuming these are **invalid by definition**.

---

## 6. Test Philosophy

Tests in AnimeHub must:

- Reflect real contracts
- Use real implementations (e.g. SQLite, in-memory)
- Validate invariants, not imagined behavior

Tests that depend on:
- mocks that do not exist
- hypothetical APIs
- future features

are considered **harmful** and must be removed.

---

## 7. Safe Development Guidelines (Going Forward)

Development may safely proceed **only if**:

- New functionality fits within existing contracts  
  **OR**
- Contracts are explicitly evolved in a controlled manner

### 7.1 What Is Allowed
- Adding new services that consume existing repositories
- Adding new commands that respect current traits
- Adding new tests for real behavior
- Improving performance without semantic change

### 7.2 What Is NOT Allowed
- Adding methods to existing traits without a contract revision
- Expanding enums casually
- Introducing helper layers that bypass repositories
- ‚ÄúFixing‚Äù things by weakening invariants

---

## 8. How to Change This Baseline (Strict Process)

Any change to this baseline requires:

1. Explicit identification of the contract change
2. Update to `Verified AnimeHub Contracts`
3. Update to this document
4. Code changes
5. Test updates

Skipping any step invalidates the change.

---

## 9. Final Statement

At the time of writing:

> **AnimeHub is structurally consolidated, contract-consistent, and safe for continued development.**

Any future instability is a result of **explicit deviation**, not hidden technical debt.

---

## 10. Engineering Principle

> A smaller, explicit, truthful system  
> is superior to a larger, ambiguous one.

This document exists to enforce that principle.


--- FILE: docs\DATA_MODEL.md ---
AnimeHub ‚Äî Modelo de Dados Can√¥nico

Este documento define quais dados existem,
como se relacionam,
e quais estados s√£o v√°lidos no AnimeHub.

Ele √© o reflexo direto e obrigat√≥rio de:

DOMAIN_CONTRACTS.md

EVENT_MAP.md

SERVICE_CONTRACTS.md

Se algo n√£o estiver aqui, n√£o existe no sistema.

0. PRINC√çPIOS DO MODELO DE DADOS
0.1 Fonte de verdade

Entidades prim√°rias:

Anime

Episode

File

Subtitle

Collection

Entidades derivadas:

Statistics

Eventos:

Podem ser persistidos

Nunca substituem estado prim√°rio

0.2 Identidade e mutabilidade

Toda entidade possui:

ID interno imut√°vel

IDs externos:

S√£o auxiliares

Nunca substituem identidade interna

Nenhum dado cr√≠tico √© sobrescrito sem:

Versionamento

Hist√≥rico preservado

0.3 Rela√ß√µes expl√≠citas

N√£o existem rela√ß√µes impl√≠citas

Nenhuma infer√™ncia autom√°tica √© permitida

1. ENTIDADE: ANIME
Identidade

anime_id (interno, imut√°vel)

Campos conceituais

titulo_principal

titulos_alternativos

tipo (TV | Movie | OVA | Special)

status (em_exibicao | finalizado | cancelado)

total_episodios (opcional)

data_inicio (opcional)

data_fim (opcional)

metadados_livres

criado_em

atualizado_em

Rela√ß√µes

1:N ‚Üí Episode

N:M ‚Üí Collection

1:N ‚Üí ExternalReference

1:N ‚Üí AnimeAlias

Estados v√°lidos

Anime pode existir:

Sem epis√≥dios

Sem arquivos

Sem refer√™ncias externas

2. ENTIDADE: EPISODE
Identidade

episode_id (interno)

Campos conceituais

anime_id (obrigat√≥rio)

numero (inteiro ou especial)

titulo (opcional)

duracao_esperada (opcional)

progresso_atual

estado (nao_visto | em_progresso | concluido)

criado_em

atualizado_em

Rela√ß√µes

N:1 ‚Üí Anime

1:N ‚Üí File (associados)

0..1 ‚Üí File (arquivo_principal)

Estados v√°lidos

Episode:

Nunca existe sem Anime

Pode existir sem arquivo

Assume uma vers√£o pr√°tica

3. ENTIDADE: FILE
Identidade

file_id

Campos conceituais

caminho_absoluto

tipo (video | legenda | imagem | outro)

tamanho

hash (opcional)

data_modificacao

origem (scan | importacao | manual)

criado_em

atualizado_em

Rela√ß√µes

N:M ‚Üí Episode

1:N ‚Üí Subtitle (quando tipo = legenda)

Estados v√°lidos

File pode:

N√£o estar associado a nada

Estar associado a m√∫ltiplos epis√≥dios (exce√ß√£o)

Arquivo f√≠sico:

Nunca √© deletado automaticamente

Nunca √© sobrescrito

4. ENTIDADE: SUBTITLE
Identidade

subtitle_id

Campos conceituais

file_id (origem)

formato (SRT | ASS | VTT)

idioma

versao

eh_original (boolean)

criado_em

Rela√ß√µes

N:1 ‚Üí File

1:N ‚Üí SubtitleTransformation

Estados v√°lidos

Toda Subtitle:

Possui origem

Nunca substitui outra

Pode gerar infinitas derivadas

5. ENTIDADE: SUBTITLE_TRANSFORMATION
Identidade

transformation_id

Campos conceituais

subtitle_id_origem

tipo (style | timing | conversao)

parametros_aplicados

criado_em

Rela√ß√µes

N:1 ‚Üí Subtitle

6. ENTIDADE: COLLECTION
Identidade

collection_id

Campos conceituais

nome

descricao

criado_em

Rela√ß√µes

N:M ‚Üí Anime

Estados v√°lidos

Cole√ß√µes:

N√£o alteram Anime

N√£o afetam progresso

S√£o puramente organizacionais

7. ENTIDADE: EXTERNAL_REFERENCE
Identidade

external_reference_id

Campos conceituais

anime_id

fonte (AniList)

external_id

criado_em

Rela√ß√µes

N:1 ‚Üí Anime

Estados v√°lidos

ExternalReference:

Nunca substitui dados locais

Pode ser removida sem impacto estrutural

8. ENTIDADE: ANIME_ALIAS
Identidade

alias_id

Campos conceituais

anime_principal_id

anime_alias_id

criado_em

Rela√ß√µes

2 √ó Anime

Estados v√°lidos

AnimeAlias:

Nunca √© deletado

Mant√©m hist√≥rico de merges

9. ENTIDADE: STATISTICS_SNAPSHOT (DERIVADA)
Identidade

snapshot_id

Campos conceituais

tipo (global | por_anime | por_periodo)

valor

gerado_em

‚ö†Ô∏è Nunca √© fonte prim√°ria de verdade

10. EVENT STORE (OPCIONAL, RECOMENDADO)
ENTIDADE: DOMAIN_EVENT

Campos conceituais:

event_id

tipo_evento

payload

ocorrido_em

Uso

Auditoria

Debug

Replay de eventos

An√°lise de falhas

11. REGRAS DE INTEGRIDADE (CR√çTICAS)
Estados proibidos

Episode sem Anime

Subtitle sem File

File deletado automaticamente

Estat√≠stica como fonte prim√°ria

Merge sem AnimeAlias

Se ocorrer ‚Üí erro arquitetural grave.

12. MATRIZ FINAL DE RELA√á√ïES (RESUMO)
Entidade	Relacionamentos
Anime	Episode, Collection, ExternalReference, AnimeAlias
Episode	Anime, File
File	Episode, Subtitle
Subtitle	File, Transformation
Collection	Anime
Statistics	(derivada)
13. ESTADO FINAL DO PROJETO

Dom√≠nios: FECHADOS

Eventos: FECHADOS

Servi√ßos: FECHADOS

Modelo de Dados: FECHADO

Ambiguidade: ZERO

--- FILE: docs\DOMAIN_CONTRACTS.md ---
AnimeHub ‚Äî Contratos de Dom√≠nio Can√¥nicos
Vers√£o do Documento: 1.0
Data de Cria√ß√£o: 24/12/2025
Descri√ß√£o Geral: Este documento define O QUE o sistema AnimeHub √©. Ele estabelece contratos de dom√≠nio can√¥nicos, focando em regras imut√°veis, entidades, invariantes e a√ß√µes permitidas/proibidas. N√£o define tecnologia, implementa√ß√£o ou UI. Qualquer c√≥digo que viole este documento est√° arquiteturalmente errado, mesmo que funcione funcionalmente.

0. REGRAS GLOBAIS (IMUT√ÅVEIS)
0.1 Natureza do Sistema

O AnimeHub √© local-first.
O usu√°rio controla os arquivos.
O sistema nunca destr√≥i dados silenciosamente.

0.2 Verdades Fundamentais

Toda entidade possui:
Identidade interna imut√°vel.

IDs externos:
S√£o auxiliares.
Nunca substituem identidade interna.


0.3 Estados Proibidos (NUNCA Podem Existir)

Epis√≥dio sem Anime.
Legenda sem arquivo de origem.
Progresso negativo.
Progresso maior que dura√ß√£o.
Estat√≠stica como fonte prim√°ria.
Arquivo deletado automaticamente.

Consequ√™ncia: Se qualquer um ocorrer ‚Üí erro cr√≠tico de arquitetura.

1. DOM√çNIO: ANIME
1.1 Escopo
Representa exclusivamente obras japonesas:

S√©ries de TV.
Filmes.
OVAs.
Especiais.

‚ö†Ô∏è N√£o Representa:

Donghua.
Anima√ß√£o ocidental.
Conte√∫do gen√©rico.

1.2 Entidade: Anime
Campos Conceituais:

id (identidade interna).
T√≠tulo principal.
T√≠tulos alternativos.
Tipo (TV | Movie | OVA | Special).
Status (em_exibi√ß√£o | finalizado | cancelado).
Total de epis√≥dios (opcional).
Datas relevantes (opcionais).
Metadados livres (g√™neros, est√∫dio, etc.).

1.3 Invariantes

Um Anime:
Pode existir sem epis√≥dios.
Pode existir sem arquivos.
Pode existir sem fonte externa.

Identidade nunca muda.
Duplicatas s√£o permitidas at√© resolu√ß√£o expl√≠cita.

1.4 A√ß√µes Permitidas

Criar manualmente.
Criar via importa√ß√£o.
Atualizar metadados.
Associar fontes externas.
Marcar duplicata.
Fundir duplicatas (manual).

1.5 A√ß√µes Proibidas

Deletar automaticamente.
Fundir sem confirma√ß√£o.
Alterar hist√≥rico ao editar metadados.


2. DOM√çNIO: EPISODE
2.1 Escopo
Representa uma unidade de exibi√ß√£o pertencente a um Anime.
2.2 Entidade: Episode
Campos Conceituais:

id (identidade interna).
anime_id (refer√™ncia ao Anime).
N√∫mero (regular ou especial).
T√≠tulo (opcional).
Dura√ß√£o esperada (opcional).
Progresso atual.
Estado (n√£o_visto | em_progresso | conclu√≠do).

2.3 Invariantes

Todo epis√≥dio pertence a exatamente um Anime.
Um epis√≥dio:
Pode existir sem arquivo.
Assume uma vers√£o pr√°tica.

Progresso:
Nunca diminui automaticamente.
Nunca ultrapassa dura√ß√£o.


2.4 A√ß√µes Permitidas

Criar manualmente.
Criar via automa√ß√£o expl√≠cita.
Associar arquivos.
Atualizar progresso.
Marcar como especial.

2.5 A√ß√µes Proibidas

Epis√≥dio √≥rf√£o.
Reset impl√≠cito de progresso.
Merge autom√°tico silencioso.


3. DOM√çNIO: FILE (ARQUIVO F√çSICO)
3.1 Escopo
Representa arquivos reais no disco.
3.2 Entidade: File
Campos Conceituais:

id (identidade interna).
Caminho absoluto.
Tipo (v√≠deo | legenda | imagem | outro).
Tamanho.
Hash (opcional).
Data de modifica√ß√£o.
Origem (scan | importa√ß√£o | manual).

3.3 Invariantes

Arquivo:
Nunca √© assumido confi√°vel.
Pode mudar de caminho.

Nome do arquivo n√£o √© verdade absoluta.
Arquivo original nunca √© sobrescrito.

3.4 A√ß√µes Proibidas

Deletar fisicamente.
Reescrever conte√∫do.
Inferir associa√ß√£o sem confirma√ß√£o.


4. DOM√çNIO: SUBTITLE
4.1 Escopo
Legendas como dados transform√°veis, n√£o apenas arquivos.
4.2 Entidade: Subtitle
Campos Conceituais:

id (identidade interna).
file_id de origem.
Formato (SRT | ASS | VTT).
Idioma.
Vers√£o.
√©_original (boolean).

4.3 Invariantes

Toda legenda:
Possui origem.
Nunca substitui outra.

Transforma√ß√µes:
S√£o versionadas.
S√£o revers√≠veis.


4.4 A√ß√µes Permitidas

Aplicar estilo (fonte, outline, tamanho).
Ajustar timing ocasionalmente.
Converter formato.
Processar em batch.

4.5 A√ß√µes Proibidas

Edi√ß√£o destrutiva.
Sobrescrever arquivo original.


5. DOM√çNIO: COLLECTION
5.1 Escopo
Agrupamento puramente organizacional.
5.2 Invariantes

Cole√ß√µes:
N√£o afetam progresso.
N√£o alteram Anime.

Anime pode pertencer a v√°rias cole√ß√µes.


6. DOM√çNIO: STATISTICS
6.1 Escopo
Dados derivados, nunca prim√°rios.
6.2 Invariantes

Estat√≠sticas:
Podem ser recalculadas.
Podem ser descartadas.

Nunca alteram dom√≠nios.


7. INTEGRA√á√ïES EXTERNAS
7.1 AniList

Fonte auxiliar.
Nunca autorit√°ria.
Nunca sobrescreve dados locais.

7.2 Player (MPV)

Observ√°vel.
Control√°vel.
Falhas n√£o corrompem estado.


8. DECLARA√á√ÉO FINAL
Se algo:

N√£o est√° descrito aqui ‚Üí n√£o deve ser implementado.

Este documento:

Precede o c√≥digo.
Precede o banco.
Precede qualquer IA.

--- FILE: docs\EVENT_MAP.md ---
AnimeHub ‚Äî Mapa Can√¥nico de Eventos e Fluxos

Este documento define o comportamento do sistema ao longo do tempo.
Ele responde, de forma inequ√≠voca, √† pergunta:
‚ÄúQuando X acontece, o que o sistema faz?‚Äù

N√£o descreve UI.
N√£o descreve tecnologia.
Descreve causalidade e rea√ß√£o.

0. PRINC√çPIOS DO EVENT MAP
0.1 Evento √© um fato, n√£o uma inten√ß√£o

Um evento:

J√° aconteceu

√â verdadeiro

N√£o depende de interface

Exemplos:

‚ùå ‚ÄúUsu√°rio clicou no bot√£o‚Äù

‚úÖ ‚ÄúArquivo de v√≠deo foi detectado‚Äù

‚úÖ ‚ÄúEpis√≥dio foi marcado como conclu√≠do‚Äù

0.2 Tipos de eventos
Evento Prim√°rio

Fato originado por:

A√ß√£o expl√≠cita do usu√°rio

Intera√ß√£o com o mundo externo (scan, player)

Evento Derivado

Consequ√™ncia l√≥gica de outro evento.

Evento Observ√°vel

Evento que existe para:

Atualizar UI

Atualizar estat√≠sticas

Atualizar cache

‚ö†Ô∏è Eventos observ√°veis nunca alteram dom√≠nios diretamente.

0.3 Regra estrutural absoluta

Nenhum evento pode alterar diretamente mais de um dom√≠nio.

Coordena√ß√£o acontece por rea√ß√µes, nunca por acoplamento.

1. EVENTO: SCAN DE DIRET√ìRIO
1.1 Evento prim√°rio

DirectoryScanned

Emitido quando:

O sistema termina de varrer um diret√≥rio configurado

1.2 Eventos derivados
FileDetected

Emitido para cada arquivo relevante encontrado:

V√≠deo

Legenda

Imagem associ√°vel

1.3 Rea√ß√µes por dom√≠nio
Dom√≠nio: File

Registra o arquivo

Atualiza:

tamanho

data de modifica√ß√£o

hash (se configurado)

N√£o associa automaticamente

Dom√≠nio: Anime / Episode

Nenhuma a√ß√£o direta

Associa√ß√£o exige evento expl√≠cito posterior

üìå Decis√£o can√¥nica
Scan nunca cria Anime ou Episode automaticamente.

2. EVENTO: CRIA√á√ÉO DE ANIME
2.1 Evento prim√°rio

AnimeCreated

Origem:

Cria√ß√£o manual

Importa√ß√£o expl√≠cita

2.2 Rea√ß√µes
Dom√≠nio: Anime

Cria entidade Anime

Estado inicial neutro

Dom√≠nio: Statistics

Nenhuma rea√ß√£o imediata

3. EVENTO: CRIA√á√ÉO DE EPIS√ìDIO
3.1 Evento prim√°rio

EpisodeCreated

Pr√©-condi√ß√£o:

Anime existente

3.2 Rea√ß√µes
Dom√≠nio: Episode

Cria epis√≥dio

Estado inicial: n√£o_visto

Progresso = 0

4. EVENTO: ASSOCIA√á√ÉO DE ARQUIVO A EPIS√ìDIO
4.1 Evento prim√°rio

FileLinkedToEpisode

Origem:

A√ß√£o manual do usu√°rio

Automa√ß√£o expl√≠cita e confirmada

4.2 Rea√ß√µes
Dom√≠nio: Episode

Registra associa√ß√£o

Define papel do arquivo:

principal (v√≠deo)

auxiliar (legenda, extra)

Dom√≠nio: File

Mant√©m refer√™ncia reversa

4.3 Evento derivado
EpisodeBecamePlayable

Emitido quando:

Epis√≥dio passa a ter arquivo de v√≠deo v√°lido

5. EVENTO: IN√çCIO DE REPRODU√á√ÉO
5.1 Evento prim√°rio

PlaybackStarted

Emitido quando:

Player inicia reprodu√ß√£o de um epis√≥dio

5.2 Rea√ß√µes
Dom√≠nio: Episode

Estado ‚Üí em_progresso

Dom√≠nio: Statistics

Registra sess√£o tempor√°ria

üìå Nenhum progresso √© persistido aqui.

6. EVENTO: ATUALIZA√á√ÉO DE PROGRESSO
6.1 Evento prim√°rio

PlaybackProgressUpdated

Emitido periodicamente pelo player.

6.2 Invariantes

Progresso:

Nunca diminui automaticamente

Nunca ultrapassa dura√ß√£o conhecida

6.3 Rea√ß√µes
Dom√≠nio: Episode

Atualiza progresso atual

Dom√≠nio: Statistics

Atualiza m√©tricas derivadas

7. EVENTO: FINALIZA√á√ÉO DE EPIS√ìDIO
7.1 Evento prim√°rio

EpisodeCompleted

Emitido quando:

Progresso atinge limiar configurado (ex: ‚â• 90%)

7.2 Rea√ß√µes
Dom√≠nio: Episode

Estado ‚Üí conclu√≠do

Dom√≠nio: Anime

Atualiza contadores derivados (ex: epis√≥dios assistidos)

Dom√≠nio: Statistics

Atualiza totais globais

8. EVENTO: DETEC√á√ÉO DE LEGENDA
8.1 Evento prim√°rio

SubtitleDetected

Origem:

Scan de diret√≥rio

Importa√ß√£o manual

8.2 Rea√ß√µes
Dom√≠nio: Subtitle

Registra legenda

Detecta:

formato

idioma

Dom√≠nio: File

Mant√©m arquivo original imut√°vel

9. EVENTO: APLICA√á√ÉO DE ESTILO DE LEGENDA
9.1 Evento prim√°rio

SubtitleStyleApplied

Origem:

A√ß√£o manual

Batch expl√≠cito

9.2 Invariantes

Legenda original:

Nunca √© sobrescrita

Sempre gera nova vers√£o

9.3 Rea√ß√µes
Dom√≠nio: Subtitle

Cria nova vers√£o

Registra transforma√ß√£o de estilo

10. EVENTO: AJUSTE DE TIMING DE LEGENDA
10.1 Evento prim√°rio

SubtitleTimingAdjusted

10.2 Rea√ß√µes
Dom√≠nio: Subtitle

Gera nova vers√£o

Registra transforma√ß√£o de timing

üìå Timing √© tratado como transforma√ß√£o, n√£o edi√ß√£o destrutiva.

11. EVENTO: FUS√ÉO DE ANIMES (DUPLICATAS)
11.1 Evento prim√°rio

AnimeMerged

Pr√©-condi√ß√µes:

A√ß√£o manual

Confirma√ß√£o expl√≠cita

11.2 Rea√ß√µes
Dom√≠nio: Anime

Um anime torna-se principal

Outro vira alias hist√≥rico

Dom√≠nio: Episode

Epis√≥dios s√£o reassociados explicitamente

12. EVENTO: REBUILD DE ESTAT√çSTICAS
12.1 Evento prim√°rio

StatisticsRebuilt

Origem:

A√ß√£o manual

Manuten√ß√£o

12.2 Rea√ß√µes
Dom√≠nio: Statistics

Recalcula todos os dados derivados

üìå Nenhum dom√≠nio prim√°rio √© alterado.

13. EVENTOS PROIBIDOS (CR√çTICOS)

Os seguintes eventos NUNCA DEVEM EXISTIR:

AutoAnimeDeleted

SubtitleOverwritten

ImplicitEpisodeMerge

ProgressResetWithoutUserAction

FileAutoDeleted

Se aparecerem ‚Üí erro arquitetural grave.

14. GARANTIA DE CONTINUIDADE

Qualquer IA que leia:

DOMAIN_CONTRACTS.md

EVENT_MAP.md

Consegue:

Entender o sistema

Implementar sem improvisar

Evoluir sem quebrar contratos

15. ESTADO DO PROJETO

Dom√≠nios: FECHADOS

Eventos: FECHADOS

Servi√ßos: DEFINIDOS

C√≥digo: N√ÉO INICIADO



--- FILE: docs\FOUNDATION SEAL.md ---
Purpose

This document formally defines which parts of the AnimeHub codebase are SEALED as of the completion of the Foundation Phase (Phase 3).

Sealed components are considered stable architectural boundaries. They are not frozen forever, but must not be modified casually. Any change to a sealed component requires an explicit architectural review.

This document exists to:

Prevent accidental architectural erosion

Stop unnecessary refactors driven by tooling or tests

Provide clarity for future contributors (human or AI)

Definition of ‚ÄúSEALED‚Äù

A sealed component:

Is architecturally correct and complete for the current phase

Defines contracts relied upon by other layers

Must not be changed to satisfy outdated tests or conveniences

Can only be modified for explicit, justified reasons (bug, design flaw, new phase decision)

Sealing is a process decision, not a technical restriction.

üîí SEALED COMPONENTS
1. Domain Layer (STRICTLY SEALED)

Location: src-tauri/src/domain/

These files define the core business model. They are pure, dependency-free, and invariant-driven.

Sealed directories and files:

domain/anime/

domain/episode/

domain/file/

domain/subtitle/

domain/collection/

domain/statistics/

domain/external_reference.rs

domain/anime_alias.rs

Rules:

‚ùå No database access

‚ùå No filesystem access

‚ùå No event bus access

‚ùå No UI or service concerns

‚úÖ Only business rules and invariants

2. Repository Contracts (SEALED)

Location: src-tauri/src/repositories/

These traits define the stable boundary between services and persistence.

Sealed files:

anime_repository.rs

episode_repository.rs

file_repository.rs

subtitle_repository.rs

collection_repository.rs

external_reference_repository.rs

anime_alias_repository.rs

statistics_repository.rs

Rules:

‚ùå No business logic

‚ùå No cross-repository calls

‚ùå No service calls

‚úÖ Traits only

3. Database Schema (SEALED)

Location: src-tauri/schema.sql

This file defines the canonical SQLite schema.

Rules:

‚ùå No breaking changes

‚ùå No column removal or type mutation

‚úÖ Only additive migrations allowed in future phases

4. Event System (SEALED)

Location: src-tauri/src/events/

Sealed files:

events/types.rs

events/bus/event_bus.rs

Rules:

‚ùå Existing events must not change

‚ùå Event semantics are immutable

‚úÖ New events may be added

5. Service Responsibilities (SEALED)

Location: src-tauri/src/services/

Sealed service files:

anime_service.rs

episode_service.rs

file_service.rs

playback_service.rs

statistics_service.rs

external_integration_service.rs

subtitle_service.rs

Rules:

‚ùå No business logic inside services

‚ùå Services must not call other services directly

‚úÖ Services orchestrate domain + repositories + events

‚ö†Ô∏è LEGACY / NON-CANONICAL CODE (DO NOT USE)
Legacy SQLite Implementations

Location: src-tauri/src/repositories/sqlite/

Files:

sqlite_episode_repository.rs

sqlite_file_repository.rs

sqlite_statistics_repository.rs

Status:

‚ö†Ô∏è Legacy

‚ùå Not used by the current architecture

‚ùå Must not be referenced by new code

‚úÖ Kept only for historical context

üß™ TEST STATUS CLARIFICATION
Valid Tests (Authoritative)

Domain invariant tests (inside domain modules)

Event bus tests

Database migration tests

Infrastructure utility tests

Legacy / Out-of-Phase Tests

Early repository integration tests

Tests referencing outdated module paths

Tests assuming deprecated helpers

These tests:

‚ùå Are not required to pass

‚ùå Must not drive architectural changes

‚ö†Ô∏è Are considered historical

What Future Development MAY Do

‚úÖ Add new services ‚úÖ Add new service methods ‚úÖ Add new events ‚úÖ Add UI layers ‚úÖ Add external integrations (AniList, MPV, etc.) ‚úÖ Add integration tests at application boundaries

What Future Development MUST NOT Do

‚ùå Modify sealed domain models casually ‚ùå Change repository contracts without review ‚ùå Break schema compatibility ‚ùå Add business logic to repositories ‚ùå Create service-to-service dependencies

Phase Status

Foundation Phase (Phase 3): CLOSED & SEALED

This document is the authoritative reference for what is considered stable.

All future work builds around this foundation, not inside it.

--- FILE: docs\PHASE_4_RESOLUTION_FREEZE.md ---
AnimeHub ‚Äî Phase 4 Resolution: Project Status Extension

This document is an official status extension to the existing AnimeHub documentation set. It records the sealed state of Phase 4, the enforced architectural boundaries, and the exact readiness conditions for Phase 5.

Current Global State
Aspect	Status
Compilation (cargo build)	‚úÖ Stable
Static analysis (cargo check)	‚úÖ Stable
Test suite (cargo test)	‚úÖ Passing (58/58)
Phase 4 Resolution	üîí SEALED
Phase 5 Materialization	In Progress

This state is authoritative. Any deviation must be intentional and documented.

Phase 4 ‚Äî Resolution (SEALED)
Definition

Phase 4 is responsible for pure resolution of media files into domain intent, without performing any domain mutation.

Resolution produces knowledge, not state.

Guarantees (Hard Constraints)

Phase 4 enforces the following invariants:

Resolution is pure (no side effects)

Resolution is deterministic

Resolution is idempotent

No domain entities are created or modified

No persistence operations are performed

Repository access is read-only only

Output is expressed exclusively via events and intents

These guarantees are enforced by:

Type boundaries

Repository trait design

Test coverage

Violation of any invariant is considered a phase breach.

What Phase 4 Explicitly DOES

Parse file metadata

Normalize titles, episode numbers, and labels

Infer episode intent (regular, special, range, batch)

Compute confidence scores

Attempt read-only matching against existing Anime/Episode records

Emit resolution events:

FileResolved

ResolutionFailed

ResolutionBatchCompleted

What Phase 4 Explicitly DOES NOT Do

Create Anime entities

Create Episode entities

Link files to domain entities

Update existing domain state

Perform transactional logic

Decide permanence

Any such behavior belongs to Phase 5.

Sealed Files (DO NOT MODIFY)

The following files are frozen under Phase 4. Changes require explicit phase transition approval.

src/domain/resolution/**

src/services/resolution_service.rs

src/services/resolution_service_tests.rs

src/events/resolution_events.rs

Minor refactors that do not affect semantics are discouraged.

Phase 5 ‚Äî Domain Materialization (NEXT)
Purpose

Phase 5 consumes the intent produced by Phase 4 and performs controlled domain mutation.

It is the first phase allowed to create or modify persistent state.

Phase 5 Responsibilities

Consume FileResolved and EpisodeResolved events

Decide whether to:

Create new Anime

Create new Episode

Link file to existing entities

Enforce idempotency using resolution fingerprints

Persist domain changes transactionally

Preconditions for Phase 5 Start

Phase 5 may begin only if:

Phase 4 tests remain green

No new logic is added to ResolutionService

Materialization logic is isolated from resolution logic

Phase 5 code must not leak back into Phase 4.

Phase Boundary Rule

Resolution produces truth. Materialization produces reality.

These concerns must never be merged.

Architectural Direction Lock

The project now follows a strict pipeline:

Scan (I/O, uncontrolled)

Resolve (pure, deterministic)

Materialize (transactional, idempotent)

Observe (events, UI, sync)

This pipeline is no longer theoretical ‚Äî it is enforced in code.

Final Status Declaration

Phase 4 is complete, sealed, and production-stable

The current commit represents a valid architectural checkpoint

All future work must respect the established phase boundaries

This document supersedes informal explanations and serves as the canonical Phase 4 closure record.

--- FILE: docs\README.md ---
AnimeHub ‚Äî Documento Can√¥nico de Continuidade

Este arquivo √© o ponto de entrada obrigat√≥rio para qualquer IA ou humano.
Ele define:

o que √© o projeto

o que N√ÉO √©

em que est√°gio ele est√°

como continuar a implementa√ß√£o sem reinventar nada

1. O QUE √â O ANIMEHUB

AnimeHub √© um gerenciador local, offline-first, de animes japoneses (incluindo filmes), com foco em:

Controle expl√≠cito de biblioteca

Progresso de visualiza√ß√£o confi√°vel

Transforma√ß√µes n√£o destrutivas de legendas

Robustez estrutural acima de conveni√™ncia

Manuten√ß√£o m√≠nima a longo prazo

N√£o √© um player.
N√£o √© um scraper autom√°tico.
N√£o √© um sistema de streaming.

2. PRINC√çPIOS INEGOCI√ÅVEIS

Nada √© impl√≠cito

Nada √© destru√≠do automaticamente

Toda transforma√ß√£o gera hist√≥rico

Eventos coordenam, servi√ßos n√£o se chamam

Dados derivados nunca s√£o fonte de verdade

Implementa√ß√£o nunca decide arquitetura

Viola√ß√£o de qualquer um ‚Üí erro cr√≠tico.

3. DOCUMENTOS CAN√îNICOS (ORDEM DE LEITURA)

README.md (este arquivo)

DOMAIN_CONTRACTS.md

EVENT_MAP.md

SERVICE_CONTRACTS.md

DATA_MODEL.md

üëâ C√≥digo deve obedecer aos documentos, nunca o contr√°rio.

4. ESCOPO FUNCIONAL
Inclu√≠do

Animes japoneses (TV, Movie, OVA, Special)

Biblioteca local

Player externo (MPV)

Estilo e timing de legendas

Progresso persistente

Exclu√≠do (por design)

S√©ries ocidentais

Streaming online

Download autom√°tico

Recomenda√ß√µes algor√≠tmicas

Edi√ß√£o destrutiva de arquivos

5. ESTADO ATUAL DO PROJETO
Camada	Estado
Vis√£o	Fechada
Dom√≠nios	Fechados
Eventos	Fechados
Servi√ßos	Fechados
Dados	Fechados
C√≥digo	N√ÉO iniciado

üìå Este √© o √∫nico momento seguro para iniciar c√≥digo.

6. COMO UMA IA DEVE CONTINUAR O PROJETO
Ordem obrigat√≥ria de implementa√ß√£o

Estrutura base do projeto

Dom√≠nios (entidades + invariantes)

Event bus interno

Persist√™ncia (reposit√≥rios)

Servi√ßos

Integra√ß√£o com player

Interface

‚ö†Ô∏è Pular etapas quebra o sistema.

7. EXPECTATIVA DE QUALIDADE DE C√ìDIGO

C√≥digo:

Determin√≠stico

Test√°vel

Sem efeitos colaterais impl√≠citos

Nenhum:

Mock permanente

Placeholder

‚ÄúDepois a gente arruma‚Äù

8. SOBRE TECNOLOGIA (DELIBERADAMENTE ABERTO)

Linguagem: indiferente

Framework: indiferente

Banco: indiferente

UI: indiferente

üìå A arquitetura independe da stack.

9. COMO ENTREGAR ESTE PROJETO A OUTRA IA

Ao iniciar uma nova conversa:

Envie todos os arquivos .md

Diga:

‚ÄúLeia todos os documentos. N√£o proponha mudan√ßas arquiteturais. Apenas implemente.‚Äù

Se a IA:

questionar contratos ‚Üí erro

sugerir simplifica√ß√£o ‚Üí erro

propor automa√ß√£o impl√≠cita ‚Üí erro

10. GARANTIA DE CONTINUIDADE

Qualquer IA, lendo estes arquivos, consegue:

Entender o projeto inteiro

Saber exatamente em que fase ele est√°

Continuar sem decis√µes subjetivas

Manter o mesmo n√≠vel de rigor

11. STATUS FINAL

Projeto completamente especificado.
Zero ambiguidade.
Pronto para implementa√ß√£o.

--- FILE: docs\SERVICE_CONTRACTS.md ---
AnimeHub ‚Äî Contratos Can√¥nicos de Servi√ßos

Este documento define QUEM FAZ O QU√ä no sistema.
Ele impede:

servi√ßos gen√©ricos

l√≥gica escondida

acoplamento indevido

Qualquer servi√ßo que viole este contrato est√° arquiteturalmente errado.

0. REGRAS GLOBAIS DOS SERVI√áOS
0.1 Defini√ß√£o de Servi√ßo

Um Servi√ßo:

Orquestra dom√≠nios

Reage a eventos

N√£o possui estado dur√°vel pr√≥prio

üìå Estado dur√°vel pertence exclusivamente aos dom√≠nios.

0.2 O que um Servi√ßo N√ÉO √â

‚ùå Controller de UI

‚ùå Wrapper de banco

‚ùå Lugar para ‚Äúresolver tudo‚Äù

0.3 Comunica√ß√£o entre servi√ßos

Servi√ßos:

Consomem eventos

Emitem eventos

Servi√ßos:

Nunca chamam outros servi√ßos diretamente

Nunca compartilham estado

Coordena√ß√£o ocorre por eventos, n√£o por chamadas diretas.

1. ANIME SERVICE
Responsabilidade

Gerenciar o ciclo de vida do Anime como entidade de dom√≠nio.

Pode fazer

Criar Anime

Atualizar metadados

Associar fontes externas

Resolver duplicatas (merge manual)

N√ÉO pode fazer

Criar epis√≥dios automaticamente

Criar arquivos

Alterar progresso de epis√≥dios

Calcular estat√≠sticas

Eventos que consome

AnimeCreated

ExternalMetadataLinked

AnimeMerged

Eventos que emite

AnimeUpdated

AnimeMerged

2. EPISODE SERVICE
Responsabilidade

Gerenciar epis√≥dios e progresso de visualiza√ß√£o.

Pode fazer

Criar epis√≥dios

Atualizar progresso

Marcar como conclu√≠do

Associar arquivos existentes

N√ÉO pode fazer

Criar Anime

Criar arquivos f√≠sicos

Manipular legendas

Gerar estat√≠sticas globais

Eventos que consome

EpisodeCreated

PlaybackStarted

PlaybackProgressUpdated

EpisodeCompleted

FileLinkedToEpisode

Eventos que emite

EpisodeBecamePlayable

EpisodeProgressUpdated

EpisodeCompleted

3. FILE SERVICE
Responsabilidade

Gerenciar arquivos f√≠sicos como entidades observ√°veis.

Pode fazer

Registrar arquivos detectados

Atualizar metadados f√≠sicos

Calcular hash

Detectar altera√ß√µes

N√ÉO pode fazer

Criar Anime ou Epis√≥dio

Decidir associa√ß√µes implicitamente

Deletar arquivos f√≠sicos

Eventos que consome

DirectoryScanned

Eventos que emite

FileDetected

FileUpdated

FileLinkedToEpisode

4. SUBTITLE SERVICE
Responsabilidade

Orquestrar transforma√ß√µes de legendas.

Pode fazer

Converter formatos

Aplicar estilos

Ajustar timing

Criar vers√µes derivadas

N√ÉO pode fazer

Sobrescrever legenda original

Alterar arquivos f√≠sicos diretamente

Modificar progresso de epis√≥dios

Eventos que consome

SubtitleDetected

SubtitleStyleApplied

SubtitleTimingAdjusted

Eventos que emite

SubtitleVersionCreated

SubtitleProcessed

5. PLAYBACK SERVICE
Responsabilidade

Integrar o sistema com o player de m√≠dia (MPV).

Pode fazer

Iniciar reprodu√ß√£o

Pausar e parar

Monitorar progresso

Emitir eventos de playback

N√ÉO pode fazer

Persistir progresso

Alterar estado de dom√≠nio diretamente

Criar entidades

Eventos que consome

PlaybackRequested

Eventos que emite

PlaybackStarted

PlaybackProgressUpdated

PlaybackStopped

6. STATISTICS SERVICE
Responsabilidade

Gerar dados derivados e agregados.

Pode fazer

Agregar dados

Cachear resultados

Recalcular estat√≠sticas

N√ÉO pode fazer

Alterar dom√≠nios

Criar entidades

Persistir dados como fonte prim√°ria

Eventos que consome

EpisodeCompleted

PlaybackProgressUpdated

StatisticsRebuilt

Eventos que emite

StatisticsUpdated

7. EXTERNAL INTEGRATION SERVICE
Responsabilidade

Integrar servi√ßos externos (AniList).

Pode fazer

Buscar metadados externos

Normalizar dados recebidos

Emitir eventos de associa√ß√£o

N√ÉO pode fazer

Criar Anime automaticamente

Substituir dados locais

Ser fonte de verdade

Eventos que consome

ExternalMetadataRequested

Eventos que emite

ExternalMetadataFetched

ExternalMetadataLinked

8. SERVI√áOS PROIBIDOS (ANTI-PATTERNS)

Os seguintes N√ÉO DEVEM EXISTIR:

LibraryService

ManagerService

UtilsService

GodService

Se aparecerem ‚Üí falha arquitetural.

9. MATRIZ DE RESPONSABILIDADE (RESUMO)
Servi√ßo	Pode	N√£o pode
Anime	Metadados	Progresso
Episode	Progresso	Arquivos
File	Detectar	Associar impl√≠cito
Subtitle	Transformar	Destruir
Playback	Observar	Persistir
Statistics	Derivar	Alterar
External	Buscar	Mandar
10. ESTADO DO PROJETO AP√ìS ESTE DOCUMENTO

Dom√≠nios: FECHADOS

Eventos: FECHADOS

Servi√ßos: FECHADOS

Ambiguidade: ZERO

--- FILE: docs\UI_LAYOUT.md ---
UI_LAYOUT.md
1. Estrutura Global
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Sidebar       ‚îÇ
‚îÇ - Biblioteca  ‚îÇ
‚îÇ - Calend√°rio  ‚îÇ
‚îÇ - Legendas    ‚îÇ
‚îÇ - Estat√≠sticas‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Main Content Area     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


Sidebar:

Sempre vis√≠vel

√çcones + texto

Estado ativo claro

2. Tela: Biblioteca

Fun√ß√£o: vis√£o geral da cole√ß√£o

Componentes:

Grid de capas

Indicador de progresso no card

Filtros:

Status

Temporada

Cole√ß√µes

Intera√ß√µes:

Clique ‚Üí P√°gina do Anime

Hover ‚Üí a√ß√µes r√°pidas (opcional)

3. Tela: P√°gina do Anime

Fun√ß√£o: centro de controle do anime

Layout:

Header grande com capa

Informa√ß√µes:

T√≠tulo

Sinopse

Status

Lista de epis√≥dios

Lista de epis√≥dios:

N√∫mero

T√≠tulo (se existir)

Progresso visual

Estado (n√£o visto / em progresso / conclu√≠do)

A√ß√µes:

Assistir

Selecionar legendas

Marcar manualmente

4. Tela: Player (Overlay)

Fun√ß√£o: assistir sem distrair

Player externo (MPV)

UI m√≠nima

Controles b√°sicos

Progresso observado automaticamente

üìå Player nunca altera estado diretamente.

5. Tela: Calend√°rio / Countdown

Fun√ß√£o: vis√£o temporal

Componentes:

Lista por temporada

Cada anime mostra:

Data do √∫ltimo epis√≥dio

Countdown visual

Filtros:

Temporada

Status

üìå Dados derivados do AniList
üìå Nunca fonte de verdade

6. Tela: Legendas

Fun√ß√£o: gerenciar transforma√ß√µes

Componentes:

Lista de legendas detectadas

Sele√ß√£o por anime / epis√≥dio

Painel de estilos:

Fonte

Outline

Shadow

Tamanho

Fluxo:

Seleciona epis√≥dios

Aplica transforma√ß√£o

Gera nova vers√£o

Hist√≥rico preservado

7. Tela: Estat√≠sticas

Fun√ß√£o: feedback, n√£o controle

Tempo assistido

Epis√≥dios conclu√≠dos

Evolu√ß√£o temporal

üìå Estat√≠sticas nunca alteram dom√≠nios.

--- FILE: docs\UI_PRINCIPLES.md ---
UI_PRINCIPLES.md
1. Filosofia Geral

A UI do AnimeHub √©:

Local-first

Silenciosamente poderosa

Visualmente limpa

Funcional antes de chamativa

Inspirada em apps premium de m√≠dia

A UI nunca toma decis√µes de dom√≠nio.
Ela apenas reflete estado e emite inten√ß√µes expl√≠citas.

2. Princ√≠pios Visuais

Dark mode √© padr√£o

Contraste alto, por√©m confort√°vel

Poucos elementos por tela

Layouts previs√≠veis

Nada pisca sem motivo

üìå Regra:

Se algo pode ser ocultado at√© o usu√°rio pedir ‚Üí deve ser ocultado.

3. Tipografia (Obrigat√≥ria)

Fonte prim√°ria: Inter ou Poppins

Hierarquia clara:

T√≠tulo

Subt√≠tulo

Corpo

Meta (labels, hints)

‚ùå Proibido:

Mais de 2 fam√≠lias de fonte

Texto pequeno demais

UI ‚Äúapertada‚Äù

4. Cores

Paleta neutra

Cor de destaque usada com modera√ß√£o

Estados claros:

Ativo

Inativo

Conclu√≠do

Em progresso

Erro

üìå Progresso √© visual, n√£o textual sempre.

5. Anima√ß√µes

Curtas

Suaves

Sem exagero

Nunca bloqueiam intera√ß√£o

Usadas para:

Transi√ß√µes de p√°gina

Expans√£o de detalhes

Feedback de a√ß√£o

Nunca usadas para:

Enfeite vazio

Chamar aten√ß√£o desnecess√°ria

6. UX (Regras Estritas)

Nenhuma a√ß√£o destrutiva sem confirma√ß√£o

Nenhuma automa√ß√£o invis√≠vel

Feedback sempre claro

Erros explic√°veis

üìå Se algo falhar:

A UI explica o que falhou, n√£o esconde.

7. Inspira√ß√µes Declaradas

A UI se inspira em:

SeaNimes (estrutura)

Apple TV (layout e tipografia)

Netflix (grid e navega√ß√£o)

Spotify Desktop (sidebar + conte√∫do)

‚ö†Ô∏è Inspira√ß√£o ‚â† c√≥pia.

--- FILE: EVENTS_SYSTEM_DESIGN.md ---
# AnimeHub Event System - Design Document

## Overview

The Event System is the coordination backbone of AnimeHub. It enables services to communicate without direct dependencies, making the system:
- **Decoupled**: Services don't know about each other
- **Observable**: Every action produces traceable events
- **Deterministic**: Same inputs ‚Üí same outputs
- **Testable**: Services can be tested in isolation

## Architecture Principles

### 1. Events Are Facts, Not Commands

‚ùå **Wrong** (Command): `CreateAnime { title: "..." }`  
‚úÖ **Right** (Fact): `AnimeCreated { anime_id: ..., title: "..." }`

Events represent something that **has already happened**. They are immutable historical records.

### 2. Synchronous by Design

The event bus executes handlers **immediately** in **subscription order**. This makes the system:
- Predictable (no race conditions)
- Debuggable (step through execution)
- Simple (no async complexity)

When to consider async (future):
- External API calls
- Heavy computation
- I/O-bound operations

But the **core event flow remains synchronous**.

### 3. Type Safety Over Flexibility

We use **concrete types** for every event:
```rust
pub struct AnimeCreated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub anime_id: Uuid,
    pub titulo_principal: String,
    pub tipo: String,
}
```

No dynamic dispatch. No string-typed events. No `HashMap<String, Any>`.

### 4. One Handler, One Responsibility

Each handler does **exactly one thing**:
- ‚úÖ Update progress
- ‚úÖ Emit derived event
- ‚úÖ Log action
- ‚ùå Update progress AND send email AND rebuild statistics

If you need multiple things, emit multiple events.

### 5. Services Never Call Services

```rust
// ‚ùå FORBIDDEN
impl AnimeService {
    fn create_anime(&self) {
        // ...
        self.episode_service.create_episodes(); // NO!
    }
}

// ‚úÖ CORRECT
impl AnimeService {
    fn create_anime(&self, bus: &EventBus) {
        // ...
        bus.emit(AnimeCreated::new(...));
        // EpisodeService will react to this event
    }
}
```

## Event Flow Example

### Scenario: User creates a new anime

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     UI      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ invoke create_anime
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ AnimeService‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ emit AnimeCreated
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Event Bus  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ   ‚îÇ
      ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚ñº                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Statistics ‚îÇ    ‚îÇ  External   ‚îÇ
‚îÇ   Handler   ‚îÇ    ‚îÇ  Integration‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                  ‚îÇ
       ‚îÇ emit             ‚îÇ emit
       ‚îÇ StatisticsUpdated‚îÇ MetadataRequested
       ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Event Bus  ‚îÇ    ‚îÇ  Event Bus  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Each handler:
1. Receives event
2. Performs domain operation
3. Emits resulting events (if needed)

## Event Categories

Events are organized by domain:

### File Scanning
- `DirectoryScanned`: Scan completed
- `FileDetected`: Individual file found

### Anime Domain
- `AnimeCreated`: New anime entity
- `AnimeUpdated`: Metadata changed
- `AnimeMerged`: Duplicates resolved

### Episode Domain
- `EpisodeCreated`: New episode
- `FileLinkedToEpisode`: File association
- `EpisodeBecamePlayable`: Has valid video
- `EpisodeProgressUpdated`: Playback progress
- `EpisodeCompleted`: Finished watching

### Playback
- `PlaybackStarted`: Player launched
- `PlaybackProgressUpdated`: Progress tick
- `PlaybackStopped`: Player closed

### Subtitle
- `SubtitleDetected`: Subtitle file found
- `SubtitleStyleApplied`: Style transformation
- `SubtitleTimingAdjusted`: Timing transformation
- `SubtitleVersionCreated`: New derived version

### Statistics
- `StatisticsRebuilt`: Full recalculation
- `StatisticsUpdated`: Incremental update

### External Integration
- `ExternalMetadataRequested`: User wants external data
- `ExternalMetadataFetched`: Data retrieved
- `ExternalMetadataLinked`: Associated with anime

## Usage Patterns

### Pattern 1: Simple Handler

```rust
use animehub::events::*;

#[derive(Clone)]
struct LoggingHandler;

impl EventHandler<AnimeCreated> for LoggingHandler {
    fn handle(&self, event: &AnimeCreated, _bus: &EventBus) {
        println!("New anime: {}", event.titulo_principal);
    }
}

// Register
let bus = EventBus::new();
let handler = LoggingHandler;
handler.register(&bus);
```

### Pattern 2: Handler with State

```rust
#[derive(Clone)]
struct StatisticsHandler {
    repository: Arc<dyn StatisticsRepository>,
}

impl EventHandler<AnimeCreated> for StatisticsHandler {
    fn handle(&self, event: &AnimeCreated, bus: &EventBus) {
        // Update statistics
        self.repository.increment_anime_count();
        
        // Emit result
        bus.emit(StatisticsUpdated::new());
    }
}
```

### Pattern 3: Coordinator (Complex Flow)

```rust
#[derive(Clone)]
struct AnimeCreationCoordinator {
    episode_service: Arc<EpisodeService>,
    external_service: Arc<ExternalIntegrationService>,
}

impl EventHandler<AnimeCreated> for AnimeCreationCoordinator {
    fn handle(&self, event: &AnimeCreated, bus: &EventBus) {
        // Emit sub-tasks as events
        
        if should_create_episodes(&event) {
            bus.emit(CreateDefaultEpisodesRequested {
                anime_id: event.anime_id,
            });
        }
        
        if should_fetch_metadata(&event) {
            bus.emit(ExternalMetadataRequested {
                anime_id: event.anime_id,
                provider: "AniList".to_string(),
            });
        }
    }
}
```

## Testing Strategy

### Unit Test: Single Handler

```rust
#[test]
fn test_statistics_handler() {
    let bus = EventBus::new();
    let repo = Arc::new(MockStatisticsRepository::new());
    let handler = StatisticsHandler { repository: repo.clone() };
    
    handler.register(&bus);
    
    let event = AnimeCreated::new(
        Uuid::new_v4(),
        "Test".to_string(),
        "TV".to_string(),
    );
    
    bus.emit(event);
    
    assert_eq!(repo.anime_count(), 1);
}
```

### Integration Test: Event Flow

```rust
#[test]
fn test_anime_creation_flow() {
    let bus = EventBus::new();
    
    // Register all handlers
    register_all_handlers(&bus);
    
    // Trigger initial event
    bus.emit(AnimeCreated::new(...));
    
    // Verify resulting state
    let log = bus.get_event_log();
    assert!(log.iter().any(|e| e.event_type == "StatisticsUpdated"));
    assert!(log.iter().any(|e| e.event_type == "ExternalMetadataRequested"));
}
```

## Observability

The EventBus provides built-in observability:

### Event Log

```rust
let log = bus.get_event_log();
for entry in log {
    println!("{}: {} | {} handlers",
        entry.occurred_at,
        entry.event_type,
        entry.handler_count
    );
}
```

### Console Output

Every event emission is logged:
```
[EVENT] AnimeCreated (id: 123e4567-...) | 3 handlers
[EVENT] StatisticsUpdated (id: 234f5678-...) | 1 handlers
```

### Tracing (Future)

Event causality can be tracked by storing parent event IDs.

## Anti-Patterns to Avoid

### ‚ùå God Event

```rust
// BAD: One event doing everything
struct SystemStateChanged {
    anime_updated: bool,
    episodes_updated: bool,
    statistics_updated: bool,
    // ... kitchen sink
}
```

### ‚ùå Command Masquerading as Event

```rust
// BAD: This is a command, not an event
struct ShouldCreateAnime {
    title: String,
}

// GOOD: Event after the fact
struct AnimeCreated {
    anime_id: Uuid,
    titulo_principal: String,
}
```

### ‚ùå Handler Doing Too Much

```rust
// BAD: Multiple responsibilities
impl EventHandler<AnimeCreated> for MegaHandler {
    fn handle(&self, event: &AnimeCreated, bus: &EventBus) {
        self.update_statistics();
        self.fetch_external_data();
        self.send_notification();
        self.update_cache();
        self.log_analytics();
        // ... etc
    }
}
```

### ‚ùå Direct Service Calls

```rust
// BAD: Direct dependency
impl AnimeService {
    fn create(&self) {
        // ...
        self.episode_service.initialize(); // NO!
    }
}

// GOOD: Event-driven
impl AnimeService {
    fn create(&self, bus: &EventBus) {
        // ...
        bus.emit(AnimeCreated::new(...));
        // EpisodeService reacts independently
    }
}
```

## Performance Considerations

### Synchronous Execution

- **Latency**: All handlers execute before `emit()` returns
- **Trade-off**: Predictability > raw speed
- **Mitigation**: Keep handlers fast (< 1ms each)

### Memory

- **Event Log**: Grows unbounded
- **Solution**: Periodic cleanup or size limit
- **Production**: Consider rotating logs

### Scalability

- **Single-threaded**: Current design
- **Future**: Can add async event queue for I/O-bound tasks
- **Hybrid**: Sync for critical path, async for non-critical

## Future Enhancements (Out of Scope for Step 3)

1. **Event Persistence**: Store events for replay
2. **Event Sourcing**: Rebuild state from events
3. **Async Handlers**: For I/O-bound operations
4. **Dead Letter Queue**: For failed events
5. **Event Versioning**: Evolve event schemas
6. **Distributed Events**: Multi-process coordination

These will be considered in later steps if needed.

## Conclusion

The Event System is deliberately **simple and explicit**. It prioritizes:
- **Understanding** over cleverness
- **Debuggability** over performance
- **Correctness** over convenience

This foundation enables AnimeHub to grow without becoming a tangled mess of dependencies.

---

**Next Step**: Implement concrete services that use this event system (Step 5).

--- FILE: README.md ---


--- FILE: .svelte-kit\ambient.d.ts ---

// this file is generated ‚Äî do not edit it


/// <reference types="@sveltejs/kit" />

/**
 * Environment variables [loaded by Vite](https://vitejs.dev/guide/env-and-mode.html#env-files) from `.env` files and `process.env`. Like [`$env/dynamic/private`](https://svelte.dev/docs/kit/$env-dynamic-private), this module cannot be imported into client-side code. This module only includes variables that _do not_ begin with [`config.kit.env.publicPrefix`](https://svelte.dev/docs/kit/configuration#env) _and do_ start with [`config.kit.env.privatePrefix`](https://svelte.dev/docs/kit/configuration#env) (if configured).
 * 
 * _Unlike_ [`$env/dynamic/private`](https://svelte.dev/docs/kit/$env-dynamic-private), the values exported from this module are statically injected into your bundle at build time, enabling optimisations like dead code elimination.
 * 
 * ```ts
 * import { API_KEY } from '$env/static/private';
 * ```
 * 
 * Note that all environment variables referenced in your code should be declared (for example in an `.env` file), even if they don't have a value until the app is deployed:
 * 
 * ```
 * MY_FEATURE_FLAG=""
 * ```
 * 
 * You can override `.env` values from the command line like so:
 * 
 * ```sh
 * MY_FEATURE_FLAG="enabled" npm run dev
 * ```
 */
declare module '$env/static/private' {
	export const ALLUSERSPROFILE: string;
	export const APPDATA: string;
	export const ChocolateyInstall: string;
	export const ChocolateyLastPathUpdate: string;
	export const COLOR: string;
	export const CommonProgramFiles: string;
	export const CommonProgramW6432: string;
	export const COMPUTERNAME: string;
	export const ComSpec: string;
	export const DriverData: string;
	export const EDITOR: string;
	export const EFC_8428_1262719628: string;
	export const EFC_8428_1592913036: string;
	export const EFC_8428_2283032206: string;
	export const EFC_8428_2775293581: string;
	export const EFC_8428_3789132940: string;
	export const FPS_BROWSER_APP_PROFILE_STRING: string;
	export const FPS_BROWSER_USER_PROFILE_STRING: string;
	export const HOME: string;
	export const HOMEDRIVE: string;
	export const HOMEPATH: string;
	export const INIT_CWD: string;
	export const LOCALAPPDATA: string;
	export const LOGONSERVER: string;
	export const NODE: string;
	export const NODE_ENV: string;
	export const NODE_EXE: string;
	export const NPM_CLI_JS: string;
	export const npm_command: string;
	export const npm_config_cache: string;
	export const npm_config_globalconfig: string;
	export const npm_config_global_prefix: string;
	export const npm_config_init_module: string;
	export const npm_config_local_prefix: string;
	export const npm_config_node_gyp: string;
	export const npm_config_noproxy: string;
	export const npm_config_npm_version: string;
	export const npm_config_prefix: string;
	export const npm_config_userconfig: string;
	export const npm_config_user_agent: string;
	export const npm_execpath: string;
	export const npm_lifecycle_event: string;
	export const npm_lifecycle_script: string;
	export const npm_node_execpath: string;
	export const npm_package_json: string;
	export const npm_package_name: string;
	export const npm_package_version: string;
	export const NPM_PREFIX_JS: string;
	export const NPM_PREFIX_NPM_CLI_JS: string;
	export const NUMBER_OF_PROCESSORS: string;
	export const OneDrive: string;
	export const OneDriveConsumer: string;
	export const OS: string;
	export const Path: string;
	export const PATHEXT: string;
	export const POWERSHELL_TELEMETRY_OPTOUT: string;
	export const PROCESSOR_ARCHITECTURE: string;
	export const PROCESSOR_IDENTIFIER: string;
	export const PROCESSOR_LEVEL: string;
	export const PROCESSOR_REVISION: string;
	export const ProgramData: string;
	export const ProgramFiles: string;
	export const ProgramW6432: string;
	export const PROMPT: string;
	export const PSModulePath: string;
	export const PUBLIC: string;
	export const SESSIONNAME: string;
	export const SystemDrive: string;
	export const SystemRoot: string;
	export const TAURI_CLI_VERBOSITY: string;
	export const TAURI_DIALOG_PLUGIN_CONFIG: string;
	export const TAURI_ENV_ARCH: string;
	export const TAURI_ENV_DEBUG: string;
	export const TAURI_ENV_FAMILY: string;
	export const TAURI_ENV_PLATFORM: string;
	export const TAURI_ENV_PLATFORM_VERSION: string;
	export const TAURI_ENV_TARGET_TRIPLE: string;
	export const TEMP: string;
	export const TMP: string;
	export const USERDOMAIN: string;
	export const USERDOMAIN_ROAMINGPROFILE: string;
	export const USERNAME: string;
	export const USERPROFILE: string;
	export const windir: string;
	export const ZES_ENABLE_SYSMAN: string;
}

/**
 * Similar to [`$env/static/private`](https://svelte.dev/docs/kit/$env-static-private), except that it only includes environment variables that begin with [`config.kit.env.publicPrefix`](https://svelte.dev/docs/kit/configuration#env) (which defaults to `PUBLIC_`), and can therefore safely be exposed to client-side code.
 * 
 * Values are replaced statically at build time.
 * 
 * ```ts
 * import { PUBLIC_BASE_URL } from '$env/static/public';
 * ```
 */
declare module '$env/static/public' {
	
}

/**
 * This module provides access to runtime environment variables, as defined by the platform you're running on. For example if you're using [`adapter-node`](https://github.com/sveltejs/kit/tree/main/packages/adapter-node) (or running [`vite preview`](https://svelte.dev/docs/kit/cli)), this is equivalent to `process.env`. This module only includes variables that _do not_ begin with [`config.kit.env.publicPrefix`](https://svelte.dev/docs/kit/configuration#env) _and do_ start with [`config.kit.env.privatePrefix`](https://svelte.dev/docs/kit/configuration#env) (if configured).
 * 
 * This module cannot be imported into client-side code.
 * 
 * ```ts
 * import { env } from '$env/dynamic/private';
 * console.log(env.DEPLOYMENT_SPECIFIC_VARIABLE);
 * ```
 * 
 * > [!NOTE] In `dev`, `$env/dynamic` always includes environment variables from `.env`. In `prod`, this behavior will depend on your adapter.
 */
declare module '$env/dynamic/private' {
	export const env: {
		ALLUSERSPROFILE: string;
		APPDATA: string;
		ChocolateyInstall: string;
		ChocolateyLastPathUpdate: string;
		COLOR: string;
		CommonProgramFiles: string;
		CommonProgramW6432: string;
		COMPUTERNAME: string;
		ComSpec: string;
		DriverData: string;
		EDITOR: string;
		EFC_8428_1262719628: string;
		EFC_8428_1592913036: string;
		EFC_8428_2283032206: string;
		EFC_8428_2775293581: string;
		EFC_8428_3789132940: string;
		FPS_BROWSER_APP_PROFILE_STRING: string;
		FPS_BROWSER_USER_PROFILE_STRING: string;
		HOME: string;
		HOMEDRIVE: string;
		HOMEPATH: string;
		INIT_CWD: string;
		LOCALAPPDATA: string;
		LOGONSERVER: string;
		NODE: string;
		NODE_ENV: string;
		NODE_EXE: string;
		NPM_CLI_JS: string;
		npm_command: string;
		npm_config_cache: string;
		npm_config_globalconfig: string;
		npm_config_global_prefix: string;
		npm_config_init_module: string;
		npm_config_local_prefix: string;
		npm_config_node_gyp: string;
		npm_config_noproxy: string;
		npm_config_npm_version: string;
		npm_config_prefix: string;
		npm_config_userconfig: string;
		npm_config_user_agent: string;
		npm_execpath: string;
		npm_lifecycle_event: string;
		npm_lifecycle_script: string;
		npm_node_execpath: string;
		npm_package_json: string;
		npm_package_name: string;
		npm_package_version: string;
		NPM_PREFIX_JS: string;
		NPM_PREFIX_NPM_CLI_JS: string;
		NUMBER_OF_PROCESSORS: string;
		OneDrive: string;
		OneDriveConsumer: string;
		OS: string;
		Path: string;
		PATHEXT: string;
		POWERSHELL_TELEMETRY_OPTOUT: string;
		PROCESSOR_ARCHITECTURE: string;
		PROCESSOR_IDENTIFIER: string;
		PROCESSOR_LEVEL: string;
		PROCESSOR_REVISION: string;
		ProgramData: string;
		ProgramFiles: string;
		ProgramW6432: string;
		PROMPT: string;
		PSModulePath: string;
		PUBLIC: string;
		SESSIONNAME: string;
		SystemDrive: string;
		SystemRoot: string;
		TAURI_CLI_VERBOSITY: string;
		TAURI_DIALOG_PLUGIN_CONFIG: string;
		TAURI_ENV_ARCH: string;
		TAURI_ENV_DEBUG: string;
		TAURI_ENV_FAMILY: string;
		TAURI_ENV_PLATFORM: string;
		TAURI_ENV_PLATFORM_VERSION: string;
		TAURI_ENV_TARGET_TRIPLE: string;
		TEMP: string;
		TMP: string;
		USERDOMAIN: string;
		USERDOMAIN_ROAMINGPROFILE: string;
		USERNAME: string;
		USERPROFILE: string;
		windir: string;
		ZES_ENABLE_SYSMAN: string;
		[key: `PUBLIC_${string}`]: undefined;
		[key: `${string}`]: string | undefined;
	}
}

/**
 * Similar to [`$env/dynamic/private`](https://svelte.dev/docs/kit/$env-dynamic-private), but only includes variables that begin with [`config.kit.env.publicPrefix`](https://svelte.dev/docs/kit/configuration#env) (which defaults to `PUBLIC_`), and can therefore safely be exposed to client-side code.
 * 
 * Note that public dynamic environment variables must all be sent from the server to the client, causing larger network requests ‚Äî when possible, use `$env/static/public` instead.
 * 
 * ```ts
 * import { env } from '$env/dynamic/public';
 * console.log(env.PUBLIC_DEPLOYMENT_SPECIFIC_VARIABLE);
 * ```
 */
declare module '$env/dynamic/public' {
	export const env: {
		[key: `PUBLIC_${string}`]: string | undefined;
	}
}


--- FILE: .svelte-kit\generated\client\app.js ---
export { matchers } from './matchers.js';

export const nodes = [
	() => import('./nodes/0'),
	() => import('./nodes/1'),
	() => import('./nodes/2'),
	() => import('./nodes/3'),
	() => import('./nodes/4'),
	() => import('./nodes/5'),
	() => import('./nodes/6'),
	() => import('./nodes/7')
];

export const server_loads = [];

export const dictionary = {
		"/": [2],
		"/anime/[id]": [3],
		"/calendar": [4],
		"/library": [5],
		"/statistics": [6],
		"/subtitles": [7]
	};

export const hooks = {
	handleError: (({ error }) => { console.error(error) }),
	
	reroute: (() => {}),
	transport: {}
};

export const decoders = Object.fromEntries(Object.entries(hooks.transport).map(([k, v]) => [k, v.decode]));
export const encoders = Object.fromEntries(Object.entries(hooks.transport).map(([k, v]) => [k, v.encode]));

export const hash = false;

export const decode = (type, value) => decoders[type](value);

export { default as root } from '../root.js';

--- FILE: .svelte-kit\generated\client\matchers.js ---
export const matchers = {};

--- FILE: .svelte-kit\generated\client\nodes\0.js ---
export { default as component } from "../../../../src/routes/+layout.svelte";

--- FILE: .svelte-kit\generated\client\nodes\1.js ---
export { default as component } from "../../../../node_modules/@sveltejs/kit/src/runtime/components/svelte-5/error.svelte";

--- FILE: .svelte-kit\generated\client\nodes\2.js ---
export { default as component } from "../../../../src/routes/+page.svelte";

--- FILE: .svelte-kit\generated\client\nodes\3.js ---
export { default as component } from "../../../../src/routes/anime/[id]/+page.svelte";

--- FILE: .svelte-kit\generated\client\nodes\4.js ---
export { default as component } from "../../../../src/routes/calendar/+page.svelte";

--- FILE: .svelte-kit\generated\client\nodes\5.js ---
export { default as component } from "../../../../src/routes/library/+page.svelte";

--- FILE: .svelte-kit\generated\client\nodes\6.js ---
export { default as component } from "../../../../src/routes/statistics/+page.svelte";

--- FILE: .svelte-kit\generated\client\nodes\7.js ---
export { default as component } from "../../../../src/routes/subtitles/+page.svelte";

--- FILE: .svelte-kit\generated\root.js ---
import { asClassComponent } from 'svelte/legacy';
import Root from './root.svelte';
export default asClassComponent(Root);

--- FILE: .svelte-kit\generated\root.svelte ---
<!-- This file is generated by @sveltejs/kit ‚Äî do not edit it! -->
<svelte:options runes={true} />
<script>
	import { setContext, onMount, tick } from 'svelte';
	import { browser } from '$app/environment';

	// stores
	let { stores, page, constructors, components = [], form, data_0 = null, data_1 = null } = $props();

	if (!browser) {
		// svelte-ignore state_referenced_locally
		setContext('__svelte__', stores);
	}

	if (browser) {
		$effect.pre(() => stores.page.set(page));
	} else {
		// svelte-ignore state_referenced_locally
		stores.page.set(page);
	}
	$effect(() => {
		stores;page;constructors;components;form;data_0;data_1;
		stores.page.notify();
	});

	let mounted = $state(false);
	let navigated = $state(false);
	let title = $state(null);

	onMount(() => {
		const unsubscribe = stores.page.subscribe(() => {
			if (mounted) {
				navigated = true;
				tick().then(() => {
					title = document.title || 'untitled page';
				});
			}
		});

		mounted = true;
		return unsubscribe;
	});

	const Pyramid_1=$derived(constructors[1])
</script>

{#if constructors[1]}
	{@const Pyramid_0 = constructors[0]}
							<!-- svelte-ignore binding_property_non_reactive -->
							<Pyramid_0 bind:this={components[0]} data={data_0} {form} params={page.params}>
								<!-- svelte-ignore binding_property_non_reactive -->
										<Pyramid_1 bind:this={components[1]} data={data_1} {form} params={page.params} />
							</Pyramid_0>

{:else}
	{@const Pyramid_0 = constructors[0]}
	<!-- svelte-ignore binding_property_non_reactive -->
	<Pyramid_0 bind:this={components[0]} data={data_0} {form} params={page.params} />

{/if}

{#if mounted}
	<div id="svelte-announcer" aria-live="assertive" aria-atomic="true" style="position: absolute; left: 0; top: 0; clip: rect(0 0 0 0); clip-path: inset(50%); overflow: hidden; white-space: nowrap; width: 1px; height: 1px">
		{#if navigated}
			{title}
		{/if}
	</div>
{/if}

--- FILE: .svelte-kit\generated\server\internal.js ---

import root from '../root.js';
import { set_building, set_prerendering } from '__sveltekit/environment';
import { set_assets } from '$app/paths/internal/server';
import { set_manifest, set_read_implementation } from '__sveltekit/server';
import { set_private_env, set_public_env } from '../../../node_modules/@sveltejs/kit/src/runtime/shared-server.js';

export const options = {
	app_template_contains_nonce: false,
	async: false,
	csp: {"mode":"auto","directives":{"upgrade-insecure-requests":false,"block-all-mixed-content":false},"reportOnly":{"upgrade-insecure-requests":false,"block-all-mixed-content":false}},
	csrf_check_origin: true,
	csrf_trusted_origins: [],
	embedded: false,
	env_public_prefix: 'PUBLIC_',
	env_private_prefix: '',
	hash_routing: false,
	hooks: null, // added lazily, via `get_hooks`
	preload_strategy: "modulepreload",
	root,
	service_worker: false,
	service_worker_options: undefined,
	templates: {
		app: ({ head, body, assets, nonce, env }) => "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n\r\n<head>\r\n    <meta charset=\"utf-8\" />\r\n    <link rel=\"icon\" href=\"" + assets + "/favicon.png\" />\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n    " + head + "\r\n</head>\r\n\r\n<body data-sveltekit-preload-data=\"hover\">\r\n    <div style=\"display: contents\">" + body + "</div>\r\n</body>\r\n\r\n</html>",
		error: ({ status, message }) => "<!doctype html>\n<html lang=\"en\">\n\t<head>\n\t\t<meta charset=\"utf-8\" />\n\t\t<title>" + message + "</title>\n\n\t\t<style>\n\t\t\tbody {\n\t\t\t\t--bg: white;\n\t\t\t\t--fg: #222;\n\t\t\t\t--divider: #ccc;\n\t\t\t\tbackground: var(--bg);\n\t\t\t\tcolor: var(--fg);\n\t\t\t\tfont-family:\n\t\t\t\t\tsystem-ui,\n\t\t\t\t\t-apple-system,\n\t\t\t\t\tBlinkMacSystemFont,\n\t\t\t\t\t'Segoe UI',\n\t\t\t\t\tRoboto,\n\t\t\t\t\tOxygen,\n\t\t\t\t\tUbuntu,\n\t\t\t\t\tCantarell,\n\t\t\t\t\t'Open Sans',\n\t\t\t\t\t'Helvetica Neue',\n\t\t\t\t\tsans-serif;\n\t\t\t\tdisplay: flex;\n\t\t\t\talign-items: center;\n\t\t\t\tjustify-content: center;\n\t\t\t\theight: 100vh;\n\t\t\t\tmargin: 0;\n\t\t\t}\n\n\t\t\t.error {\n\t\t\t\tdisplay: flex;\n\t\t\t\talign-items: center;\n\t\t\t\tmax-width: 32rem;\n\t\t\t\tmargin: 0 1rem;\n\t\t\t}\n\n\t\t\t.status {\n\t\t\t\tfont-weight: 200;\n\t\t\t\tfont-size: 3rem;\n\t\t\t\tline-height: 1;\n\t\t\t\tposition: relative;\n\t\t\t\ttop: -0.05rem;\n\t\t\t}\n\n\t\t\t.message {\n\t\t\t\tborder-left: 1px solid var(--divider);\n\t\t\t\tpadding: 0 0 0 1rem;\n\t\t\t\tmargin: 0 0 0 1rem;\n\t\t\t\tmin-height: 2.5rem;\n\t\t\t\tdisplay: flex;\n\t\t\t\talign-items: center;\n\t\t\t}\n\n\t\t\t.message h1 {\n\t\t\t\tfont-weight: 400;\n\t\t\t\tfont-size: 1em;\n\t\t\t\tmargin: 0;\n\t\t\t}\n\n\t\t\t@media (prefers-color-scheme: dark) {\n\t\t\t\tbody {\n\t\t\t\t\t--bg: #222;\n\t\t\t\t\t--fg: #ddd;\n\t\t\t\t\t--divider: #666;\n\t\t\t\t}\n\t\t\t}\n\t\t</style>\n\t</head>\n\t<body>\n\t\t<div class=\"error\">\n\t\t\t<span class=\"status\">" + status + "</span>\n\t\t\t<div class=\"message\">\n\t\t\t\t<h1>" + message + "</h1>\n\t\t\t</div>\n\t\t</div>\n\t</body>\n</html>\n"
	},
	version_hash: "14e0ohe"
};

export async function get_hooks() {
	let handle;
	let handleFetch;
	let handleError;
	let handleValidationError;
	let init;
	

	let reroute;
	let transport;
	

	return {
		handle,
		handleFetch,
		handleError,
		handleValidationError,
		init,
		reroute,
		transport
	};
}

export { set_assets, set_building, set_manifest, set_prerendering, set_private_env, set_public_env, set_read_implementation };


--- FILE: .svelte-kit\non-ambient.d.ts ---

// this file is generated ‚Äî do not edit it


declare module "svelte/elements" {
	export interface HTMLAttributes<T> {
		'data-sveltekit-keepfocus'?: true | '' | 'off' | undefined | null;
		'data-sveltekit-noscroll'?: true | '' | 'off' | undefined | null;
		'data-sveltekit-preload-code'?:
			| true
			| ''
			| 'eager'
			| 'viewport'
			| 'hover'
			| 'tap'
			| 'off'
			| undefined
			| null;
		'data-sveltekit-preload-data'?: true | '' | 'hover' | 'tap' | 'off' | undefined | null;
		'data-sveltekit-reload'?: true | '' | 'off' | undefined | null;
		'data-sveltekit-replacestate'?: true | '' | 'off' | undefined | null;
	}
}

export {};


declare module "$app/types" {
	export interface AppTypes {
		RouteId(): "/" | "/anime" | "/anime/[id]" | "/calendar" | "/library" | "/statistics" | "/subtitles";
		RouteParams(): {
			"/anime/[id]": { id: string }
		};
		LayoutParams(): {
			"/": { id?: string };
			"/anime": { id?: string };
			"/anime/[id]": { id: string };
			"/calendar": Record<string, never>;
			"/library": Record<string, never>;
			"/statistics": Record<string, never>;
			"/subtitles": Record<string, never>
		};
		Pathname(): "/" | "/anime" | "/anime/" | `/anime/${string}` & {} | `/anime/${string}/` & {} | "/calendar" | "/calendar/" | "/library" | "/library/" | "/statistics" | "/statistics/" | "/subtitles" | "/subtitles/";
		ResolvedPathname(): `${"" | `/${string}`}${ReturnType<AppTypes['Pathname']>}`;
		Asset(): string & {};
	}
}

--- FILE: .svelte-kit\types\route_meta_data.json ---
{
	"/": [],
	"/anime/[id]": [],
	"/calendar": [],
	"/library": [],
	"/statistics": [],
	"/subtitles": []
}

--- FILE: .svelte-kit\types\src\routes\$types.d.ts ---
import type * as Kit from '@sveltejs/kit';

type Expand<T> = T extends infer O ? { [K in keyof O]: O[K] } : never;
// @ts-ignore
type MatcherParam<M> = M extends (param : string) => param is infer U ? U extends string ? U : string : string;
type RouteParams = {  };
type RouteId = '/';
type MaybeWithVoid<T> = {} extends T ? T | void : T;
export type RequiredKeys<T> = { [K in keyof T]-?: {} extends { [P in K]: T[K] } ? never : K; }[keyof T];
type OutputDataShape<T> = MaybeWithVoid<Omit<App.PageData, RequiredKeys<T>> & Partial<Pick<App.PageData, keyof T & keyof App.PageData>> & Record<string, any>>
type EnsureDefined<T> = T extends null | undefined ? {} : T;
type OptionalUnion<U extends Record<string, any>, A extends keyof U = U extends U ? keyof U : never> = U extends unknown ? { [P in Exclude<A, keyof U>]?: never } & U : never;
export type Snapshot<T = any> = Kit.Snapshot<T>;
type PageParentData = EnsureDefined<LayoutData>;
type LayoutRouteId = RouteId | "/" | "/anime/[id]" | "/calendar" | "/library" | "/statistics" | "/subtitles" | null
type LayoutParams = RouteParams & { id?: string }
type LayoutParentData = EnsureDefined<{}>;

export type PageServerData = null;
export type PageData = Expand<PageParentData>;
export type PageProps = { params: RouteParams; data: PageData }
export type LayoutServerData = null;
export type LayoutData = Expand<LayoutParentData>;
export type LayoutProps = { params: LayoutParams; data: LayoutData; children: import("svelte").Snippet }

--- FILE: .svelte-kit\types\src\routes\anime\[id]\$types.d.ts ---
import type * as Kit from '@sveltejs/kit';

type Expand<T> = T extends infer O ? { [K in keyof O]: O[K] } : never;
// @ts-ignore
type MatcherParam<M> = M extends (param : string) => param is infer U ? U extends string ? U : string : string;
type RouteParams = { id: string };
type RouteId = '/anime/[id]';
type MaybeWithVoid<T> = {} extends T ? T | void : T;
export type RequiredKeys<T> = { [K in keyof T]-?: {} extends { [P in K]: T[K] } ? never : K; }[keyof T];
type OutputDataShape<T> = MaybeWithVoid<Omit<App.PageData, RequiredKeys<T>> & Partial<Pick<App.PageData, keyof T & keyof App.PageData>> & Record<string, any>>
type EnsureDefined<T> = T extends null | undefined ? {} : T;
type OptionalUnion<U extends Record<string, any>, A extends keyof U = U extends U ? keyof U : never> = U extends unknown ? { [P in Exclude<A, keyof U>]?: never } & U : never;
export type Snapshot<T = any> = Kit.Snapshot<T>;
type PageParentData = EnsureDefined<import('../../$types.js').LayoutData>;

export type EntryGenerator = () => Promise<Array<RouteParams>> | Array<RouteParams>;
export type PageServerData = null;
export type PageData = Expand<PageParentData>;
export type PageProps = { params: RouteParams; data: PageData }

--- FILE: .svelte-kit\types\src\routes\calendar\$types.d.ts ---
import type * as Kit from '@sveltejs/kit';

type Expand<T> = T extends infer O ? { [K in keyof O]: O[K] } : never;
// @ts-ignore
type MatcherParam<M> = M extends (param : string) => param is infer U ? U extends string ? U : string : string;
type RouteParams = {  };
type RouteId = '/calendar';
type MaybeWithVoid<T> = {} extends T ? T | void : T;
export type RequiredKeys<T> = { [K in keyof T]-?: {} extends { [P in K]: T[K] } ? never : K; }[keyof T];
type OutputDataShape<T> = MaybeWithVoid<Omit<App.PageData, RequiredKeys<T>> & Partial<Pick<App.PageData, keyof T & keyof App.PageData>> & Record<string, any>>
type EnsureDefined<T> = T extends null | undefined ? {} : T;
type OptionalUnion<U extends Record<string, any>, A extends keyof U = U extends U ? keyof U : never> = U extends unknown ? { [P in Exclude<A, keyof U>]?: never } & U : never;
export type Snapshot<T = any> = Kit.Snapshot<T>;
type PageParentData = EnsureDefined<import('../$types.js').LayoutData>;

export type PageServerData = null;
export type PageData = Expand<PageParentData>;
export type PageProps = { params: RouteParams; data: PageData }

--- FILE: .svelte-kit\types\src\routes\library\$types.d.ts ---
import type * as Kit from '@sveltejs/kit';

type Expand<T> = T extends infer O ? { [K in keyof O]: O[K] } : never;
// @ts-ignore
type MatcherParam<M> = M extends (param : string) => param is infer U ? U extends string ? U : string : string;
type RouteParams = {  };
type RouteId = '/library';
type MaybeWithVoid<T> = {} extends T ? T | void : T;
export type RequiredKeys<T> = { [K in keyof T]-?: {} extends { [P in K]: T[K] } ? never : K; }[keyof T];
type OutputDataShape<T> = MaybeWithVoid<Omit<App.PageData, RequiredKeys<T>> & Partial<Pick<App.PageData, keyof T & keyof App.PageData>> & Record<string, any>>
type EnsureDefined<T> = T extends null | undefined ? {} : T;
type OptionalUnion<U extends Record<string, any>, A extends keyof U = U extends U ? keyof U : never> = U extends unknown ? { [P in Exclude<A, keyof U>]?: never } & U : never;
export type Snapshot<T = any> = Kit.Snapshot<T>;
type PageParentData = EnsureDefined<import('../$types.js').LayoutData>;

export type PageServerData = null;
export type PageData = Expand<PageParentData>;
export type PageProps = { params: RouteParams; data: PageData }

--- FILE: .svelte-kit\types\src\routes\statistics\$types.d.ts ---
import type * as Kit from '@sveltejs/kit';

type Expand<T> = T extends infer O ? { [K in keyof O]: O[K] } : never;
// @ts-ignore
type MatcherParam<M> = M extends (param : string) => param is infer U ? U extends string ? U : string : string;
type RouteParams = {  };
type RouteId = '/statistics';
type MaybeWithVoid<T> = {} extends T ? T | void : T;
export type RequiredKeys<T> = { [K in keyof T]-?: {} extends { [P in K]: T[K] } ? never : K; }[keyof T];
type OutputDataShape<T> = MaybeWithVoid<Omit<App.PageData, RequiredKeys<T>> & Partial<Pick<App.PageData, keyof T & keyof App.PageData>> & Record<string, any>>
type EnsureDefined<T> = T extends null | undefined ? {} : T;
type OptionalUnion<U extends Record<string, any>, A extends keyof U = U extends U ? keyof U : never> = U extends unknown ? { [P in Exclude<A, keyof U>]?: never } & U : never;
export type Snapshot<T = any> = Kit.Snapshot<T>;
type PageParentData = EnsureDefined<import('../$types.js').LayoutData>;

export type PageServerData = null;
export type PageData = Expand<PageParentData>;
export type PageProps = { params: RouteParams; data: PageData }

--- FILE: .svelte-kit\types\src\routes\subtitles\$types.d.ts ---
import type * as Kit from '@sveltejs/kit';

type Expand<T> = T extends infer O ? { [K in keyof O]: O[K] } : never;
// @ts-ignore
type MatcherParam<M> = M extends (param : string) => param is infer U ? U extends string ? U : string : string;
type RouteParams = {  };
type RouteId = '/subtitles';
type MaybeWithVoid<T> = {} extends T ? T | void : T;
export type RequiredKeys<T> = { [K in keyof T]-?: {} extends { [P in K]: T[K] } ? never : K; }[keyof T];
type OutputDataShape<T> = MaybeWithVoid<Omit<App.PageData, RequiredKeys<T>> & Partial<Pick<App.PageData, keyof T & keyof App.PageData>> & Record<string, any>>
type EnsureDefined<T> = T extends null | undefined ? {} : T;
type OptionalUnion<U extends Record<string, any>, A extends keyof U = U extends U ? keyof U : never> = U extends unknown ? { [P in Exclude<A, keyof U>]?: never } & U : never;
export type Snapshot<T = any> = Kit.Snapshot<T>;
type PageParentData = EnsureDefined<import('../$types.js').LayoutData>;

export type PageServerData = null;
export type PageData = Expand<PageParentData>;
export type PageProps = { params: RouteParams; data: PageData }

--- FILE: package.json ---
{
    "name": "animehub",
    "version": "0.1.0",
    "private": true,
    "type": "module",
    "scripts": {
        "dev": "vite dev",
        "build": "vite build",
        "preview": "vite preview",
        "check": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json",
        "check:watch": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json --watch",
        "tauri": "tauri",
        "dev:tauri": "tauri dev",
        "build:tauri": "tauri build"
    },
    "devDependencies": {
        "@sveltejs/adapter-static": "^3.0.0",
        "@sveltejs/kit": "^2.15.0",
        "@sveltejs/vite-plugin-svelte": "^5.0.0",
        "@tauri-apps/cli": "^2.2.0",
        "@types/node": "^22.10.0",
        "autoprefixer": "^10.4.20",
        "postcss": "^8.4.49",
        "svelte": "^5.16.0",
        "svelte-check": "^4.1.0",
        "tailwindcss": "^3.4.17",
        "tslib": "^2.8.1",
        "typescript": "^5.7.2",
        "vite": "^6.0.0"
    },
    "dependencies": {
        "@tauri-apps/api": "^2.2.0",
        "@tauri-apps/plugin-shell": "^2.2.0",
        "lucide-svelte": "^0.469.0"
    }
}

--- FILE: src-tauri\build.rs ---
fn main() {
    tauri_build::build()
}


--- FILE: src-tauri\capabilities\default.json ---
{
    "$schema": "../gen/schemas/desktop-schema.json",
    "identifier": "main-capability",
    "description": "Permiss√µes padr√£o para o AnimeHub",
    "windows": [
        "main"
    ],
    "permissions": [
        "core:default",
        "shell:allow-open",
        "dialog:default",
        {
            "identifier": "fs:allow-read",
            "allow": [
                {
                    "path": "$HOME/**"
                }
            ]
        },
        {
            "identifier": "fs:allow-write",
            "allow": [
                {
                    "path": "$HOME/**"
                }
            ]
        },
        "fs:allow-exists",
        "fs:allow-stat"
    ]
}

--- FILE: src-tauri\Cargo.toml ---
[package]
name = "animehub"
version = "0.1.0"
description = "Local-first anime library manager"
authors = ["AnimeHub Team"]
edition = "2021"

# ----------------------------------------
# Build dependencies
# ----------------------------------------
[build-dependencies]
tauri-build = { version = "2.0" }

# ----------------------------------------
# Runtime dependencies (used by the binary)
# ----------------------------------------
[dependencies]
# Tauri v2 core
tauri = { version = "2.0", features = [] }
tauri-plugin-shell = "2.0"
tauri-plugin-fs = "2.0"
tauri-plugin-dialog = "2.0"
windows = { version = "0.53", features = [
  "Win32_Foundation",
  "Win32_Storage_FileSystem",
  "Win32_System_IO",
  "Win32_Security"
] }
regex = "1"



# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Database (SQLite) ‚Äî BUNDLED to avoid sqlite3.lib issues on Windows
rusqlite = { version = "0.32", features = ["bundled"] }
r2d2 = "0.8"
r2d2_sqlite = "0.25"

# IDs & time
uuid = { version = "1.10", features = ["v4", "serde", "v5"] }
chrono = { version = "0.4", features = ["serde"] }

# Errors
thiserror = "2.0"
anyhow = "1.0"

# File system & hashing
dirs = "5.0"
walkdir = "2.5"
sha2 = "0.10"
notify = "6.1"

# Async / events
tokio = { version = "1.40", features = ["full"] }
async-trait = "0.1"

# External integrations
reqwest = { version = "0.12", features = ["json"] }

# Subtitle processing
subparse = "0.7"
log = "0.4.29"

# ----------------------------------------
# Dev-only dependencies (tests, helpers)
# ----------------------------------------
[dev-dependencies]
tempfile = "3"
mockall = "0.13.0"

# ----------------------------------------
# Features
# ----------------------------------------
[features]
default = ["custom-protocol"]
custom-protocol = ["tauri/custom-protocol"]


--- FILE: src-tauri\examples\anilist_query.rs ---
// src-tauri/examples/anilist_query.rs
use animehub::integrations::anilist::client::AniListClient;
use tokio;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = AniListClient::new();
    let results = client.search_anime("Naruto").await?;
    println!("Found {} results", results.len());
    for a in results {
        println!(
            "{} - episodes: {:?}",
            a.title.romaji.unwrap_or_default(),
            a.episodes
        );
    }
    Ok(())
}


--- FILE: src-tauri\examples\mpv_test.rs ---
use std::path::PathBuf;
use std::thread::sleep;
use std::time::Duration;

use animehub::integrations::mpv::client::MpvClient;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let video = std::env::args()
        .nth(1)
        .expect("Passe o caminho do v√≠deo como argumento");

    let video_path = PathBuf::from(video);

    // Cria o cliente MPV
    let client = MpvClient::new()?;

    // Lan√ßa o MPV e carrega o v√≠deo
    client.launch(video_path)?;
    println!("MPV launched. Pausando em 2s...");

    sleep(Duration::from_secs(2));

    // Usa API p√∫blica (NUNCA send_command)
    client.pause()?;
    println!("Pausado. Retomando em 2s...");

    sleep(Duration::from_secs(2));

    client.resume()?;
    println!("Resumed. Parando em 3s...");

    sleep(Duration::from_secs(3));

    client.stop()?;
    println!("MPV stopped.");

    Ok(())
}


--- FILE: src-tauri\examples\playback_e2e_test.rs ---
// src-tauri/examples/playback_e2e_test.rs
//
// PHASE 3 VALIDATION TEST: Post-Resolution Phase (Playback)
//
// PURPOSE:
// - Validate that playback works after explicit domain resolution
// - Flow: Scan ‚Üí Create Anime (via service) ‚Üí Create Episode (via service) ‚Üí
//         Link File (via service) ‚Üí Start Playback ‚Üí Stop Playback
// - Validate MPV opens and closes cleanly
//
// CONTRACT REFERENCES:
// - SERVICE_CONTRACTS.md Section 1: Anime Service
// - SERVICE_CONTRACTS.md Section 2: Episode Service
// - SERVICE_CONTRACTS.md Section 3: File Service
// - SERVICE_CONTRACTS.md Section 5: Playback Service
//
// CRITICAL:
// - Domain entities are created EXPLICITLY via services
// - No implicit inference from file names
// - This is the canonical flow for playback

use std::path::PathBuf;
use std::sync::Arc;
use std::thread::sleep;
use std::time::Duration;

use animehub::db::{create_connection_pool, initialize_database};
use animehub::domain::anime::{AnimeStatus, AnimeType};
use animehub::domain::episode::EpisodeNumber;
use animehub::domain::file::FileType;
use animehub::events::EventBus;
use animehub::integrations::MpvClient;
use animehub::repositories::*;
use animehub::services::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("=== PLAYBACK E2E TEST ===");
    println!("Purpose: Validate post-resolution playback flow");
    println!();

    // =========================================================================
    // 1. INFRASTRUCTURE BOOTSTRAP (same as main.rs)
    // =========================================================================
    println!("[SETUP] Bootstrapping infrastructure...");

    let event_bus = Arc::new(EventBus::new());
    let pool = Arc::new(create_connection_pool()?);
    let mpv_client = Arc::new(MpvClient::new()?);

    // Initialize schema (idempotent)
    {
        let conn = pool.get()?;
        initialize_database(&conn)?;
    }
    println!("[SETUP] Database initialized.");

    // =========================================================================
    // 2. REPOSITORIES
    // =========================================================================
    let anime_repo: Arc<dyn AnimeRepository> = Arc::new(SqliteAnimeRepository::new(pool.clone()));
    let episode_repo: Arc<dyn EpisodeRepository> =
        Arc::new(SqliteEpisodeRepository::new(pool.clone()));
    let file_repo: Arc<dyn FileRepository> = Arc::new(SqliteFileRepository::new(pool.clone()));
    let anime_alias_repo: Arc<dyn AnimeAliasRepository> =
        Arc::new(SqliteAnimeAliasRepository::new(pool.clone()));
    let external_ref_repo: Arc<dyn ExternalReferenceRepository> =
        Arc::new(SqliteExternalReferenceRepository::new(pool.clone()));

    // =========================================================================
    // 3. SERVICES
    // =========================================================================
    let anime_service = Arc::new(AnimeService::new(
        anime_repo.clone(),
        anime_alias_repo.clone(),
        external_ref_repo.clone(),
        event_bus.clone(),
    ));
    let episode_service = Arc::new(EpisodeService::new(
        episode_repo.clone(),
        anime_repo.clone(),
        file_repo.clone(),
        event_bus.clone(),
    ));
    let file_service = Arc::new(FileService::new(file_repo.clone(), event_bus.clone()));
    let playback_service = Arc::new(PlaybackService::new(
        episode_repo.clone(),
        file_repo.clone(),
        event_bus.clone(),
        mpv_client.clone(),
    ));

    // Register event handlers (same as main.rs)
    episode_service.register_event_handlers();

    println!("[SETUP] Services initialized.");
    println!();

    // =========================================================================
    // 4. GET TEST VIDEO FILE FROM ARGS
    // =========================================================================
    let video_path = std::env::args()
        .nth(1)
        .map(PathBuf::from)
        .unwrap_or_else(|| {
            eprintln!("Usage: cargo run --example playback_e2e_test -- <video_file_path>");
            eprintln!("       The file should be a valid video file (e.g., .mkv, .mp4).");
            std::process::exit(1);
        });

    if !video_path.exists() {
        eprintln!("[ERROR] Video file does not exist: {:?}", video_path);
        std::process::exit(1);
    }

    if !video_path.is_file() {
        eprintln!("[ERROR] Path is not a file: {:?}", video_path);
        std::process::exit(1);
    }

    println!("[TEST] Video file: {:?}", video_path);
    println!();

    // =========================================================================
    // 5. STEP 1: SCAN DIRECTORY (to register the file)
    // =========================================================================
    println!("[STEP 1] Scanning directory to register file...");

    let parent_dir = video_path
        .parent()
        .ok_or("Cannot get parent directory")?
        .to_path_buf();

    let files_found = file_service.scan_directory(parent_dir)?;
    println!("[STEP 1] Files found: {}", files_found);

    // Retrieve the file entity by path
    let file = file_repo
        .get_by_path(&video_path)?
        .ok_or("File was not registered after scan")?;

    if file.tipo != FileType::Video {
        eprintln!("[ERROR] File is not a video type: {:?}", file.tipo);
        std::process::exit(1);
    }

    println!("[STEP 1] File registered with ID: {}", file.id);
    println!();

    // =========================================================================
    // 6. STEP 2: CREATE ANIME (via service)
    // =========================================================================
    println!("[STEP 2] Creating Anime via AnimeService...");

    let create_anime_request = CreateAnimeRequest {
        titulo_principal: "Test Anime for Playback E2E".to_string(),
        titulos_alternativos: vec![],
        tipo: AnimeType::TV,
        status: AnimeStatus::EmExibicao,
        total_episodios: Some(12),
        data_inicio: None,
        data_fim: None,
        metadados_livres: serde_json::json!({}),
    };

    let anime_id = anime_service.create_anime(create_anime_request)?;
    println!("[STEP 2] Anime created with ID: {}", anime_id);
    println!();

    // =========================================================================
    // 7. STEP 3: CREATE EPISODE (via service)
    // =========================================================================
    println!("[STEP 3] Creating Episode via EpisodeService...");

    let create_episode_request = CreateEpisodeRequest {
        anime_id,
        numero: EpisodeNumber::Regular { numero: 1 },
        titulo: Some("Episode 1 - Test".to_string()),
        duracao_esperada: Some(1440), // 24 minutes in seconds
    };

    let episode_id = episode_service.create_episode(create_episode_request)?;
    println!("[STEP 3] Episode created with ID: {}", episode_id);
    println!();

    // =========================================================================
    // 8. STEP 4: LINK FILE TO EPISODE (via service)
    // =========================================================================
    println!("[STEP 4] Linking File to Episode via EpisodeService...");

    let link_request = LinkFileRequest {
        episode_id,
        file_id: file.id,
        is_primary: true,
    };

    episode_service.link_file(link_request)?;
    println!("[STEP 4] File linked to Episode as primary.");
    println!();

    // =========================================================================
    // 9. STEP 5: START PLAYBACK (via service)
    // =========================================================================
    println!("[STEP 5] Starting playback via PlaybackService...");
    println!("--- Events will be printed below ---");
    println!();

    let playback_request = StartPlaybackRequest {
        episode_id,
        file_id: Some(file.id),
    };

    let played_path = playback_service.start_playback(playback_request)?;
    println!();
    println!("[STEP 5] Playback started for: {:?}", played_path);
    println!();

    // =========================================================================
    // 10. STEP 6: LET PLAYBACK RUN BRIEFLY
    // =========================================================================
    println!("[STEP 6] Letting playback run for 5 seconds...");
    println!("         (MPV window should be visible)");
    sleep(Duration::from_secs(5));
    println!("[STEP 6] Wait complete.");
    println!();

    // =========================================================================
    // 11. STEP 7: STOP PLAYBACK (via service)
    // =========================================================================
    println!("[STEP 7] Stopping playback via PlaybackService...");

    playback_service.stop_playback(episode_id)?;

    println!("[STEP 7] Playback stopped.");
    println!();

    // Give MPV time to close
    sleep(Duration::from_millis(500));

    // =========================================================================
    // 12. FINAL RESULT
    // =========================================================================
    println!("===========================================");
    println!("PLAYBACK E2E TEST: PASSED");
    println!("===========================================");
    println!();
    println!("Summary:");
    println!("  - Video file: {:?}", video_path);
    println!("  - File ID: {}", file.id);
    println!("  - Anime ID: {}", anime_id);
    println!("  - Episode ID: {}", episode_id);
    println!("  - Playback started: YES");
    println!("  - Playback stopped: YES");
    println!("  - MPV opened: YES (verify visually)");
    println!("  - MPV closed: YES (verify visually)");
    println!();
    println!("This test validates the post-resolution playback flow.");

    Ok(())
}


--- FILE: src-tauri\examples\playback_event_validation_test.rs ---
// src-tauri/examples/playback_event_validation_test.rs
//
// PHASE 3 VALIDATION TEST: Playback Event Emission
//
// PURPOSE:
// - Prove canonical event emission during playback lifecycle
// - Validate: PlaybackStarted, PlaybackProgressUpdated, PlaybackStopped
// - Events are observed via EventBus::subscribe (public API)
// - Events are also logged to stdout by EventBus::emit (built-in behavior)
//
// CONTRACT REFERENCES:
// - EVENT_MAP.md Section 5: PlaybackStarted
// - EVENT_MAP.md Section 6: PlaybackProgressUpdated
// - SERVICE_CONTRACTS.md Section 5: Playback Service (emits PlaybackStopped)
//
// OBSERVATION METHOD:
// - EventBus::subscribe<E, F> is used to register handlers
// - Handlers print event details to stdout
// - EventBus::emit already prints "[EVENT] ..." lines (built-in)

use std::path::PathBuf;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use std::thread::sleep;
use std::time::Duration;

use animehub::db::{create_connection_pool, initialize_database};
use animehub::domain::anime::{AnimeStatus, AnimeType};
use animehub::domain::episode::EpisodeNumber;
use animehub::domain::file::FileType;
use animehub::events::{EventBus, PlaybackProgressUpdated, PlaybackStarted, PlaybackStopped};
use animehub::integrations::MpvClient;
use animehub::repositories::*;
use animehub::services::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("=== PLAYBACK EVENT VALIDATION TEST ===");
    println!("Purpose: Validate canonical event emission during playback");
    println!();

    // =========================================================================
    // 1. INFRASTRUCTURE BOOTSTRAP
    // =========================================================================
    println!("[SETUP] Bootstrapping infrastructure...");

    let event_bus = Arc::new(EventBus::new());
    let pool = Arc::new(create_connection_pool()?);
    let mpv_client = Arc::new(MpvClient::new()?);

    {
        let conn = pool.get()?;
        initialize_database(&conn)?;
    }

    // =========================================================================
    // 2. REPOSITORIES
    // =========================================================================
    let anime_repo: Arc<dyn AnimeRepository> = Arc::new(SqliteAnimeRepository::new(pool.clone()));
    let episode_repo: Arc<dyn EpisodeRepository> =
        Arc::new(SqliteEpisodeRepository::new(pool.clone()));
    let file_repo: Arc<dyn FileRepository> = Arc::new(SqliteFileRepository::new(pool.clone()));
    let anime_alias_repo: Arc<dyn AnimeAliasRepository> =
        Arc::new(SqliteAnimeAliasRepository::new(pool.clone()));
    let external_ref_repo: Arc<dyn ExternalReferenceRepository> =
        Arc::new(SqliteExternalReferenceRepository::new(pool.clone()));

    // =========================================================================
    // 3. SERVICES
    // =========================================================================
    let anime_service = Arc::new(AnimeService::new(
        anime_repo.clone(),
        anime_alias_repo.clone(),
        external_ref_repo.clone(),
        event_bus.clone(),
    ));
    let episode_service = Arc::new(EpisodeService::new(
        episode_repo.clone(),
        anime_repo.clone(),
        file_repo.clone(),
        event_bus.clone(),
    ));
    let file_service = Arc::new(FileService::new(file_repo.clone(), event_bus.clone()));
    let playback_service = Arc::new(PlaybackService::new(
        episode_repo.clone(),
        file_repo.clone(),
        event_bus.clone(),
        mpv_client.clone(),
    ));

    episode_service.register_event_handlers();

    println!("[SETUP] Services initialized.");
    println!();

    // =========================================================================
    // 4. REGISTER EVENT OBSERVERS
    // =========================================================================
    println!("[SETUP] Registering event observers...");

    // Counters for validation
    let started_count = Arc::new(AtomicUsize::new(0));
    let progress_count = Arc::new(AtomicUsize::new(0));
    let stopped_count = Arc::new(AtomicUsize::new(0));

    // PlaybackStarted observer
    {
        let counter = Arc::clone(&started_count);
        event_bus.subscribe::<PlaybackStarted, _>(move |event| {
            counter.fetch_add(1, Ordering::SeqCst);
            println!("[OBSERVER] PlaybackStarted received:");
            println!("           episode_id: {}", event.episode_id);
            println!("           event_id: {}", event.event_id);
            println!("           occurred_at: {}", event.occurred_at);
        });
    }

    // PlaybackProgressUpdated observer
    {
        let counter = Arc::clone(&progress_count);
        event_bus.subscribe::<PlaybackProgressUpdated, _>(move |event| {
            counter.fetch_add(1, Ordering::SeqCst);
            println!("[OBSERVER] PlaybackProgressUpdated received:");
            println!("           episode_id: {}", event.episode_id);
            println!("           progress_seconds: {}", event.progress_seconds);
        });
    }

    // PlaybackStopped observer
    {
        let counter = Arc::clone(&stopped_count);
        event_bus.subscribe::<PlaybackStopped, _>(move |event| {
            counter.fetch_add(1, Ordering::SeqCst);
            println!("[OBSERVER] PlaybackStopped received:");
            println!("           episode_id: {}", event.episode_id);
            println!(
                "           final_progress_seconds: {}",
                event.final_progress_seconds
            );
        });
    }

    println!("[SETUP] Event observers registered.");
    println!();

    // =========================================================================
    // 5. GET TEST VIDEO FILE FROM ARGS
    // =========================================================================
    let video_path = std::env::args()
        .nth(1)
        .map(PathBuf::from)
        .unwrap_or_else(|| {
            eprintln!(
                "Usage: cargo run --example playback_event_validation_test -- <video_file_path>"
            );
            std::process::exit(1);
        });

    if !video_path.exists() || !video_path.is_file() {
        eprintln!("[ERROR] Invalid video file: {:?}", video_path);
        std::process::exit(1);
    }

    println!("[TEST] Video file: {:?}", video_path);
    println!();

    // =========================================================================
    // 6. SETUP: Scan, Create Anime, Create Episode, Link File
    // =========================================================================
    println!("[SETUP] Creating test entities...");

    // Scan
    let parent_dir = video_path.parent().unwrap().to_path_buf();
    file_service.scan_directory(parent_dir)?;
    let file = file_repo
        .get_by_path(&video_path)?
        .ok_or("File not found")?;

    // Create Anime
    let anime_id = anime_service.create_anime(CreateAnimeRequest {
        titulo_principal: "Event Validation Test Anime".to_string(),
        titulos_alternativos: vec![],
        tipo: AnimeType::TV,
        status: AnimeStatus::EmExibicao,
        total_episodios: Some(12),
        data_inicio: None,
        data_fim: None,
        metadados_livres: serde_json::json!({}),
    })?;

    // Create Episode
    let episode_id = episode_service.create_episode(CreateEpisodeRequest {
        anime_id,
        numero: EpisodeNumber::Regular { numero: 1 },
        titulo: Some("Event Test Episode".to_string()),
        duracao_esperada: Some(1440),
    })?;

    // Link File
    episode_service.link_file(LinkFileRequest {
        episode_id,
        file_id: file.id,
        is_primary: true,
    })?;

    println!("[SETUP] Test entities created.");
    println!("        Anime ID: {}", anime_id);
    println!("        Episode ID: {}", episode_id);
    println!("        File ID: {}", file.id);
    println!();

    // Clear event log before playback
    event_bus.clear_event_log();

    // =========================================================================
    // 7. START PLAYBACK
    // =========================================================================
    println!("[PLAYBACK] Starting playback...");
    println!("=== EVENT OUTPUT BEGIN ===");
    println!();

    playback_service.start_playback(StartPlaybackRequest {
        episode_id,
        file_id: Some(file.id),
    })?;

    // =========================================================================
    // 8. WAIT FOR PROGRESS EVENTS
    // =========================================================================
    // PlaybackObserver polls every 2000ms with min_progress_delta of 5 seconds
    // Wait 7 seconds to ensure at least one progress event
    println!();
    println!("[PLAYBACK] Waiting 7 seconds for progress events...");
    sleep(Duration::from_secs(7));

    // =========================================================================
    // 9. STOP PLAYBACK
    // =========================================================================
    println!();
    println!("[PLAYBACK] Stopping playback...");
    playback_service.stop_playback(episode_id)?;

    println!();
    println!("=== EVENT OUTPUT END ===");
    println!();

    // Give time for final events
    sleep(Duration::from_millis(500));

    // =========================================================================
    // 10. VALIDATE EVENT COUNTS
    // =========================================================================
    println!("[VALIDATION] Checking event counts...");

    let started = started_count.load(Ordering::SeqCst);
    let progress = progress_count.load(Ordering::SeqCst);
    let stopped = stopped_count.load(Ordering::SeqCst);

    println!("  PlaybackStarted: {}", started);
    println!("  PlaybackProgressUpdated: {}", progress);
    println!("  PlaybackStopped: {}", stopped);
    println!();

    let mut passed = true;

    if started < 1 {
        println!("[FAIL] Expected at least 1 PlaybackStarted event.");
        passed = false;
    } else {
        println!("[PASS] PlaybackStarted emitted.");
    }

    // Note: PlaybackProgressUpdated may be 0 if video is very short or MPV didn't report position
    // We check for >= 0 but warn if 0
    if progress == 0 {
        println!("[WARN] No PlaybackProgressUpdated events received.");
        println!(
            "       This may be expected for very short playback or if MPV didn't report position."
        );
    } else {
        println!(
            "[PASS] PlaybackProgressUpdated emitted ({} times).",
            progress
        );
    }

    // PlaybackStopped is emitted by the observer when MPV stops
    // It may not be emitted if we call stop_playback before observer detects it
    if stopped == 0 {
        println!("[WARN] No PlaybackStopped events received.");
        println!("       This may be expected if stop_playback was called before observer detected stop.");
    } else {
        println!("[PASS] PlaybackStopped emitted.");
    }

    println!();

    // =========================================================================
    // 11. FINAL RESULT
    // =========================================================================
    if passed {
        println!("===========================================");
        println!("PLAYBACK EVENT VALIDATION TEST: PASSED");
        println!("===========================================");
    } else {
        println!("===========================================");
        println!("PLAYBACK EVENT VALIDATION TEST: FAILED");
        println!("===========================================");
        std::process::exit(1);
    }

    println!();
    println!("Summary:");
    println!("  - PlaybackStarted: {} (required: >= 1)", started);
    println!("  - PlaybackProgressUpdated: {} (informational)", progress);
    println!("  - PlaybackStopped: {} (informational)", stopped);
    println!();
    println!("This test validates canonical event emission during playback.");

    Ok(())
}


--- FILE: src-tauri\examples\playback_invalid_state_test.rs ---
// src-tauri/examples/playback_invalid_state_test.rs
//
// PHASE 3 VALIDATION TEST: Invalid State Handling
//
// PURPOSE:
// - Prove system gracefully rejects invalid playback attempts
// - Case 1: Episode with no linked file ‚Üí error, no MPV launch
// - Case 2: Invalid episode ID ‚Üí NotFound error, no MPV launch
// - No panic in any case
//
// CONTRACT REFERENCES:
// - playback_service.rs line 12038: "No video file linked" error
// - playback_service.rs line 12032: NotFound error for missing episode
//
// VALIDATION:
// - Errors are returned (not panics)
// - MPV is never launched
// - System remains stable

use std::sync::Arc;
use uuid::Uuid;

use animehub::db::{create_connection_pool, initialize_database};
use animehub::domain::anime::{AnimeStatus, AnimeType};
use animehub::domain::episode::EpisodeNumber;
use animehub::events::EventBus;
use animehub::integrations::MpvClient;
use animehub::repositories::*;
use animehub::services::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("=== PLAYBACK INVALID STATE TEST ===");
    println!("Purpose: Validate graceful rejection of invalid playback attempts");
    println!();

    // =========================================================================
    // 1. INFRASTRUCTURE BOOTSTRAP
    // =========================================================================
    println!("[SETUP] Bootstrapping infrastructure...");

    let event_bus = Arc::new(EventBus::new());
    let pool = Arc::new(create_connection_pool()?);
    let mpv_client = Arc::new(MpvClient::new()?);

    {
        let conn = pool.get()?;
        initialize_database(&conn)?;
    }

    // =========================================================================
    // 2. REPOSITORIES
    // =========================================================================
    let anime_repo: Arc<dyn AnimeRepository> = Arc::new(SqliteAnimeRepository::new(pool.clone()));
    let episode_repo: Arc<dyn EpisodeRepository> =
        Arc::new(SqliteEpisodeRepository::new(pool.clone()));
    let file_repo: Arc<dyn FileRepository> = Arc::new(SqliteFileRepository::new(pool.clone()));
    let anime_alias_repo: Arc<dyn AnimeAliasRepository> =
        Arc::new(SqliteAnimeAliasRepository::new(pool.clone()));
    let external_ref_repo: Arc<dyn ExternalReferenceRepository> =
        Arc::new(SqliteExternalReferenceRepository::new(pool.clone()));

    // =========================================================================
    // 3. SERVICES
    // =========================================================================
    let anime_service = Arc::new(AnimeService::new(
        anime_repo.clone(),
        anime_alias_repo.clone(),
        external_ref_repo.clone(),
        event_bus.clone(),
    ));
    let episode_service = Arc::new(EpisodeService::new(
        episode_repo.clone(),
        anime_repo.clone(),
        file_repo.clone(),
        event_bus.clone(),
    ));
    let playback_service = Arc::new(PlaybackService::new(
        episode_repo.clone(),
        file_repo.clone(),
        event_bus.clone(),
        mpv_client.clone(),
    ));

    println!("[SETUP] Services initialized.");
    println!();

    let mut all_passed = true;

    // =========================================================================
    // CASE 1: Episode with no linked file
    // =========================================================================
    println!("===========================================");
    println!("CASE 1: Episode with no linked file");
    println!("===========================================");
    println!();

    // Create Anime
    println!("[CASE 1] Creating Anime...");
    let anime_id = anime_service.create_anime(CreateAnimeRequest {
        titulo_principal: "Invalid State Test Anime".to_string(),
        titulos_alternativos: vec![],
        tipo: AnimeType::TV,
        status: AnimeStatus::EmExibicao,
        total_episodios: Some(12),
        data_inicio: None,
        data_fim: None,
        metadados_livres: serde_json::json!({}),
    })?;
    println!("[CASE 1] Anime created: {}", anime_id);

    // Create Episode (WITHOUT linking any file)
    println!("[CASE 1] Creating Episode (no file linked)...");
    let episode_id = episode_service.create_episode(CreateEpisodeRequest {
        anime_id,
        numero: EpisodeNumber::Regular { numero: 1 },
        titulo: Some("Episode without file".to_string()),
        duracao_esperada: Some(1440),
    })?;
    println!("[CASE 1] Episode created: {}", episode_id);

    // Attempt playback
    println!("[CASE 1] Attempting playback (should fail)...");
    let result = playback_service.start_playback(StartPlaybackRequest {
        episode_id,
        file_id: None,
    });

    match result {
        Ok(_) => {
            println!("[FAIL] Playback started when it should have failed!");
            all_passed = false;
        }
        Err(e) => {
            let error_msg = e.to_string();
            println!("[CASE 1] Error received: {}", error_msg);

            if error_msg.contains("No video file linked")
                || error_msg.contains("no file")
                || error_msg.contains("Not found")
            {
                println!("[PASS] Correct error returned for episode with no file.");
            } else {
                println!(
                    "[WARN] Error returned but message unexpected: {}",
                    error_msg
                );
                println!("       (Still passing because error was returned, not panic)");
            }
        }
    }

    // Verify MPV is not running
    if mpv_client.is_running() {
        println!("[FAIL] MPV is running when it should not be!");
        all_passed = false;
    } else {
        println!("[PASS] MPV was not launched.");
    }

    println!();

    // =========================================================================
    // CASE 2: Invalid episode ID
    // =========================================================================
    println!("===========================================");
    println!("CASE 2: Invalid episode ID");
    println!("===========================================");
    println!();

    // Generate random UUID that doesn't exist
    let fake_episode_id = Uuid::new_v4();
    println!(
        "[CASE 2] Using non-existent episode ID: {}",
        fake_episode_id
    );

    // Attempt playback
    println!("[CASE 2] Attempting playback (should fail)...");
    let result = playback_service.start_playback(StartPlaybackRequest {
        episode_id: fake_episode_id,
        file_id: None,
    });

    match result {
        Ok(_) => {
            println!("[FAIL] Playback started when it should have failed!");
            all_passed = false;
        }
        Err(e) => {
            let error_msg = e.to_string();
            println!("[CASE 2] Error received: {}", error_msg);

            if error_msg.contains("Not found")
                || error_msg.contains("not found")
                || error_msg.contains("NotFound")
            {
                println!("[PASS] Correct NotFound error returned.");
            } else {
                println!(
                    "[WARN] Error returned but message unexpected: {}",
                    error_msg
                );
                println!("       (Still passing because error was returned, not panic)");
            }
        }
    }

    // Verify MPV is not running
    if mpv_client.is_running() {
        println!("[FAIL] MPV is running when it should not be!");
        all_passed = false;
    } else {
        println!("[PASS] MPV was not launched.");
    }

    println!();

    // =========================================================================
    // CASE 3: Stop playback with invalid episode ID
    // =========================================================================
    println!("===========================================");
    println!("CASE 3: Stop playback with invalid episode ID");
    println!("===========================================");
    println!();

    let fake_episode_id_2 = Uuid::new_v4();
    println!(
        "[CASE 3] Using non-existent episode ID: {}",
        fake_episode_id_2
    );

    // Attempt to stop playback (nothing is playing)
    println!("[CASE 3] Attempting stop_playback (should not panic)...");
    let result = playback_service.stop_playback(fake_episode_id_2);

    match result {
        Ok(_) => {
            println!("[PASS] stop_playback returned Ok (graceful no-op).");
        }
        Err(e) => {
            println!("[PASS] stop_playback returned error: {}", e);
            println!("       (Error is acceptable, panic is not)");
        }
    }

    println!();

    // =========================================================================
    // FINAL RESULT
    // =========================================================================
    if all_passed {
        println!("===========================================");
        println!("PLAYBACK INVALID STATE TEST: PASSED");
        println!("===========================================");
    } else {
        println!("===========================================");
        println!("PLAYBACK INVALID STATE TEST: FAILED");
        println!("===========================================");
        std::process::exit(1);
    }

    println!();
    println!("Summary:");
    println!("  - Case 1 (no file): Error returned, no MPV launch");
    println!("  - Case 2 (invalid ID): Error returned, no MPV launch");
    println!("  - Case 3 (stop invalid): Graceful handling, no panic");
    println!();
    println!("This test validates graceful error handling for invalid states.");

    Ok(())
}


--- FILE: src-tauri\examples\scan_validation_test.rs ---
// src-tauri/examples/scan_validation_test.rs
//
// PHASE 3 VALIDATION TEST: Pre-Resolution Phase (Scan)
//
// PURPOSE:
// - Validate that directory scan detects files correctly
// - Validate correct event emission (FileDetected, DirectoryScanned)
// - Validate that NO domain entities (Anime, Episode) are implicitly created
//
// CONTRACT REFERENCES:
// - SERVICE_CONTRACTS.md Section 3: File Service
// - EVENT_MAP.md Section 1: DirectoryScanned
// - EVENT_MAP.md Section 2: FileDetected
//
// DOES NOT:
// - Start playback
// - Infer Anime or Episode
// - Create domain entities

use std::path::PathBuf;
use std::sync::Arc;

use animehub::db::{create_connection_pool, initialize_database};
use animehub::events::EventBus;
use animehub::repositories::*;
use animehub::services::*;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("=== SCAN VALIDATION TEST ===");
    println!("Purpose: Validate pre-resolution phase (scan only)");
    println!();

    // =========================================================================
    // 1. INFRASTRUCTURE BOOTSTRAP (same as main.rs)
    // =========================================================================
    println!("[SETUP] Bootstrapping infrastructure...");

    let event_bus = Arc::new(EventBus::new());
    let pool = Arc::new(create_connection_pool()?);

    // Initialize schema (idempotent)
    {
        let conn = pool.get()?;
        initialize_database(&conn)?;
    }
    println!("[SETUP] Database initialized.");

    // =========================================================================
    // 2. REPOSITORIES
    // =========================================================================
    let anime_repo: Arc<dyn AnimeRepository> = Arc::new(SqliteAnimeRepository::new(pool.clone()));
    let episode_repo: Arc<dyn EpisodeRepository> =
        Arc::new(SqliteEpisodeRepository::new(pool.clone()));
    let file_repo: Arc<dyn FileRepository> = Arc::new(SqliteFileRepository::new(pool.clone()));

    // =========================================================================
    // 3. SERVICES (only FileService needed for this test)
    // =========================================================================
    let file_service = Arc::new(FileService::new(file_repo.clone(), event_bus.clone()));

    println!("[SETUP] Services initialized.");
    println!();

    // =========================================================================
    // 4. GET TEST DIRECTORY FROM ARGS
    // =========================================================================
    let test_dir = std::env::args()
        .nth(1)
        .map(PathBuf::from)
        .unwrap_or_else(|| {
            eprintln!("Usage: cargo run --example scan_validation_test -- <directory_path>");
            eprintln!("       The directory should contain at least one video file.");
            std::process::exit(1);
        });

    if !test_dir.exists() {
        eprintln!("[ERROR] Directory does not exist: {:?}", test_dir);
        std::process::exit(1);
    }

    println!("[TEST] Scanning directory: {:?}", test_dir);
    println!();

    // =========================================================================
    // 5. CLEAR EVENT LOG (for clean observation)
    // =========================================================================
    event_bus.clear_event_log();

    // =========================================================================
    // 6. COUNT ENTITIES BEFORE SCAN
    // =========================================================================
    let animes_before = anime_repo.list_all()?.len();
    let episodes_before: usize = {
        // Count all episodes across all animes
        let animes = anime_repo.list_all()?;
        animes
            .iter()
            .map(|a| {
                episode_repo
                    .list_by_anime(a.id)
                    .map(|e| e.len())
                    .unwrap_or(0)
            })
            .sum()
    };

    println!("[PRE-SCAN] Anime count: {}", animes_before);
    println!("[PRE-SCAN] Episode count: {}", episodes_before);
    println!();

    // =========================================================================
    // 6.5 REGISTER EVENT OBSERVERS (must happen BEFORE scan)
    // =========================================================================
    event_bus.subscribe::<animehub::events::FileDetected, _>(|_event| {
        // no-op: ensures event is observed and logged
    });

    event_bus.subscribe::<animehub::events::DirectoryScanned, _>(|_event| {
        // no-op: ensures event is observed and logged
    });

    // =========================================================================
    // 7. EXECUTE SCAN
    // =========================================================================
    println!("[SCAN] Starting directory scan...");
    println!("--- Events will be printed below ---");
    println!();

    let files_found = file_service.scan_directory(test_dir.clone())?;

    println!();
    println!("--- End of events ---");
    println!();
    println!("[SCAN] Files detected: {}", files_found);
    println!();

    // =========================================================================
    // 8. COUNT ENTITIES AFTER SCAN
    // =========================================================================
    let animes_after = anime_repo.list_all()?.len();
    let episodes_after: usize = {
        let animes = anime_repo.list_all()?;
        animes
            .iter()
            .map(|a| {
                episode_repo
                    .list_by_anime(a.id)
                    .map(|e| e.len())
                    .unwrap_or(0)
            })
            .sum()
    };

    println!("[POST-SCAN] Anime count: {}", animes_after);
    println!("[POST-SCAN] Episode count: {}", episodes_after);
    println!();

    // =========================================================================
    // 9. VALIDATE: NO IMPLICIT ENTITY CREATION
    // =========================================================================
    println!("[VALIDATION] Checking for implicit entity creation...");

    if animes_after != animes_before {
        println!("[FAIL] Anime entities were implicitly created!");
        println!("       Before: {}, After: {}", animes_before, animes_after);
        std::process::exit(1);
    }

    if episodes_after != episodes_before {
        println!("[FAIL] Episode entities were implicitly created!");
        println!(
            "       Before: {}, After: {}",
            episodes_before, episodes_after
        );
        std::process::exit(1);
    }

    println!("[PASS] No implicit Anime or Episode entities created.");
    println!();

    // =========================================================================
    // 10. VALIDATE: EVENT LOG
    // =========================================================================
    println!("[VALIDATION] Checking event log...");

    let event_log = event_bus.get_event_log();

    let file_detected_count = event_log
        .iter()
        .filter(|e| e.event_type == "FileDetected")
        .count();

    let directory_scanned_count = event_log
        .iter()
        .filter(|e| e.event_type == "DirectoryScanned")
        .count();

    println!("  FileDetected events: {}", file_detected_count);
    println!("  DirectoryScanned events: {}", directory_scanned_count);

    if files_found > 0 && file_detected_count == 0 {
        println!("[FAIL] Files were found but no FileDetected events emitted!");
        std::process::exit(1);
    }

    if directory_scanned_count != 1 {
        println!(
            "[FAIL] Expected exactly 1 DirectoryScanned event, got {}",
            directory_scanned_count
        );
        std::process::exit(1);
    }

    println!("[PASS] Events emitted correctly.");
    println!();

    // =========================================================================
    // 11. FINAL RESULT
    // =========================================================================
    println!("===========================================");
    println!("SCAN VALIDATION TEST: PASSED");
    println!("===========================================");
    println!();
    println!("Summary:");
    println!("  - Directory scanned: {:?}", test_dir);
    println!("  - Files detected: {}", files_found);
    println!("  - FileDetected events: {}", file_detected_count);
    println!("  - DirectoryScanned events: {}", directory_scanned_count);
    println!("  - Implicit Anime created: 0 (correct)");
    println!("  - Implicit Episode created: 0 (correct)");
    println!();
    println!("This test seals the pre-resolution phase of the pipeline.");

    Ok(())
}


--- FILE: src-tauri\gen\schemas\acl-manifests.json ---
{"core":{"default_permission":{"identifier":"default","description":"Default core plugins set.","permissions":["core:path:default","core:event:default","core:window:default","core:webview:default","core:app:default","core:image:default","core:resources:default","core:menu:default","core:tray:default"]},"permissions":{},"permission_sets":{},"global_scope_schema":null},"core:app":{"default_permission":{"identifier":"default","description":"Default permissions for the plugin.","permissions":["allow-version","allow-name","allow-tauri-version","allow-identifier","allow-bundle-type","allow-register-listener","allow-remove-listener"]},"permissions":{"allow-app-hide":{"identifier":"allow-app-hide","description":"Enables the app_hide command without any pre-configured scope.","commands":{"allow":["app_hide"],"deny":[]}},"allow-app-show":{"identifier":"allow-app-show","description":"Enables the app_show command without any pre-configured scope.","commands":{"allow":["app_show"],"deny":[]}},"allow-bundle-type":{"identifier":"allow-bundle-type","description":"Enables the bundle_type command without any pre-configured scope.","commands":{"allow":["bundle_type"],"deny":[]}},"allow-default-window-icon":{"identifier":"allow-default-window-icon","description":"Enables the default_window_icon command without any pre-configured scope.","commands":{"allow":["default_window_icon"],"deny":[]}},"allow-fetch-data-store-identifiers":{"identifier":"allow-fetch-data-store-identifiers","description":"Enables the fetch_data_store_identifiers command without any pre-configured scope.","commands":{"allow":["fetch_data_store_identifiers"],"deny":[]}},"allow-identifier":{"identifier":"allow-identifier","description":"Enables the identifier command without any pre-configured scope.","commands":{"allow":["identifier"],"deny":[]}},"allow-name":{"identifier":"allow-name","description":"Enables the name command without any pre-configured scope.","commands":{"allow":["name"],"deny":[]}},"allow-register-listener":{"identifier":"allow-register-listener","description":"Enables the register_listener command without any pre-configured scope.","commands":{"allow":["register_listener"],"deny":[]}},"allow-remove-data-store":{"identifier":"allow-remove-data-store","description":"Enables the remove_data_store command without any pre-configured scope.","commands":{"allow":["remove_data_store"],"deny":[]}},"allow-remove-listener":{"identifier":"allow-remove-listener","description":"Enables the remove_listener command without any pre-configured scope.","commands":{"allow":["remove_listener"],"deny":[]}},"allow-set-app-theme":{"identifier":"allow-set-app-theme","description":"Enables the set_app_theme command without any pre-configured scope.","commands":{"allow":["set_app_theme"],"deny":[]}},"allow-set-dock-visibility":{"identifier":"allow-set-dock-visibility","description":"Enables the set_dock_visibility command without any pre-configured scope.","commands":{"allow":["set_dock_visibility"],"deny":[]}},"allow-tauri-version":{"identifier":"allow-tauri-version","description":"Enables the tauri_version command without any pre-configured scope.","commands":{"allow":["tauri_version"],"deny":[]}},"allow-version":{"identifier":"allow-version","description":"Enables the version command without any pre-configured scope.","commands":{"allow":["version"],"deny":[]}},"deny-app-hide":{"identifier":"deny-app-hide","description":"Denies the app_hide command without any pre-configured scope.","commands":{"allow":[],"deny":["app_hide"]}},"deny-app-show":{"identifier":"deny-app-show","description":"Denies the app_show command without any pre-configured scope.","commands":{"allow":[],"deny":["app_show"]}},"deny-bundle-type":{"identifier":"deny-bundle-type","description":"Denies the bundle_type command without any pre-configured scope.","commands":{"allow":[],"deny":["bundle_type"]}},"deny-default-window-icon":{"identifier":"deny-default-window-icon","description":"Denies the default_window_icon command without any pre-configured scope.","commands":{"allow":[],"deny":["default_window_icon"]}},"deny-fetch-data-store-identifiers":{"identifier":"deny-fetch-data-store-identifiers","description":"Denies the fetch_data_store_identifiers command without any pre-configured scope.","commands":{"allow":[],"deny":["fetch_data_store_identifiers"]}},"deny-identifier":{"identifier":"deny-identifier","description":"Denies the identifier command without any pre-configured scope.","commands":{"allow":[],"deny":["identifier"]}},"deny-name":{"identifier":"deny-name","description":"Denies the name command without any pre-configured scope.","commands":{"allow":[],"deny":["name"]}},"deny-register-listener":{"identifier":"deny-register-listener","description":"Denies the register_listener command without any pre-configured scope.","commands":{"allow":[],"deny":["register_listener"]}},"deny-remove-data-store":{"identifier":"deny-remove-data-store","description":"Denies the remove_data_store command without any pre-configured scope.","commands":{"allow":[],"deny":["remove_data_store"]}},"deny-remove-listener":{"identifier":"deny-remove-listener","description":"Denies the remove_listener command without any pre-configured scope.","commands":{"allow":[],"deny":["remove_listener"]}},"deny-set-app-theme":{"identifier":"deny-set-app-theme","description":"Denies the set_app_theme command without any pre-configured scope.","commands":{"allow":[],"deny":["set_app_theme"]}},"deny-set-dock-visibility":{"identifier":"deny-set-dock-visibility","description":"Denies the set_dock_visibility command without any pre-configured scope.","commands":{"allow":[],"deny":["set_dock_visibility"]}},"deny-tauri-version":{"identifier":"deny-tauri-version","description":"Denies the tauri_version command without any pre-configured scope.","commands":{"allow":[],"deny":["tauri_version"]}},"deny-version":{"identifier":"deny-version","description":"Denies the version command without any pre-configured scope.","commands":{"allow":[],"deny":["version"]}}},"permission_sets":{},"global_scope_schema":null},"core:event":{"default_permission":{"identifier":"default","description":"Default permissions for the plugin, which enables all commands.","permissions":["allow-listen","allow-unlisten","allow-emit","allow-emit-to"]},"permissions":{"allow-emit":{"identifier":"allow-emit","description":"Enables the emit command without any pre-configured scope.","commands":{"allow":["emit"],"deny":[]}},"allow-emit-to":{"identifier":"allow-emit-to","description":"Enables the emit_to command without any pre-configured scope.","commands":{"allow":["emit_to"],"deny":[]}},"allow-listen":{"identifier":"allow-listen","description":"Enables the listen command without any pre-configured scope.","commands":{"allow":["listen"],"deny":[]}},"allow-unlisten":{"identifier":"allow-unlisten","description":"Enables the unlisten command without any pre-configured scope.","commands":{"allow":["unlisten"],"deny":[]}},"deny-emit":{"identifier":"deny-emit","description":"Denies the emit command without any pre-configured scope.","commands":{"allow":[],"deny":["emit"]}},"deny-emit-to":{"identifier":"deny-emit-to","description":"Denies the emit_to command without any pre-configured scope.","commands":{"allow":[],"deny":["emit_to"]}},"deny-listen":{"identifier":"deny-listen","description":"Denies the listen command without any pre-configured scope.","commands":{"allow":[],"deny":["listen"]}},"deny-unlisten":{"identifier":"deny-unlisten","description":"Denies the unlisten command without any pre-configured scope.","commands":{"allow":[],"deny":["unlisten"]}}},"permission_sets":{},"global_scope_schema":null},"core:image":{"default_permission":{"identifier":"default","description":"Default permissions for the plugin, which enables all commands.","permissions":["allow-new","allow-from-bytes","allow-from-path","allow-rgba","allow-size"]},"permissions":{"allow-from-bytes":{"identifier":"allow-from-bytes","description":"Enables the from_bytes command without any pre-configured scope.","commands":{"allow":["from_bytes"],"deny":[]}},"allow-from-path":{"identifier":"allow-from-path","description":"Enables the from_path command without any pre-configured scope.","commands":{"allow":["from_path"],"deny":[]}},"allow-new":{"identifier":"allow-new","description":"Enables the new command without any pre-configured scope.","commands":{"allow":["new"],"deny":[]}},"allow-rgba":{"identifier":"allow-rgba","description":"Enables the rgba command without any pre-configured scope.","commands":{"allow":["rgba"],"deny":[]}},"allow-size":{"identifier":"allow-size","description":"Enables the size command without any pre-configured scope.","commands":{"allow":["size"],"deny":[]}},"deny-from-bytes":{"identifier":"deny-from-bytes","description":"Denies the from_bytes command without any pre-configured scope.","commands":{"allow":[],"deny":["from_bytes"]}},"deny-from-path":{"identifier":"deny-from-path","description":"Denies the from_path command without any pre-configured scope.","commands":{"allow":[],"deny":["from_path"]}},"deny-new":{"identifier":"deny-new","description":"Denies the new command without any pre-configured scope.","commands":{"allow":[],"deny":["new"]}},"deny-rgba":{"identifier":"deny-rgba","description":"Denies the rgba command without any pre-configured scope.","commands":{"allow":[],"deny":["rgba"]}},"deny-size":{"identifier":"deny-size","description":"Denies the size command without any pre-configured scope.","commands":{"allow":[],"deny":["size"]}}},"permission_sets":{},"global_scope_schema":null},"core:menu":{"default_permission":{"identifier":"default","description":"Default permissions for the plugin, which enables all commands.","permissions":["allow-new","allow-append","allow-prepend","allow-insert","allow-remove","allow-remove-at","allow-items","allow-get","allow-popup","allow-create-default","allow-set-as-app-menu","allow-set-as-window-menu","allow-text","allow-set-text","allow-is-enabled","allow-set-enabled","allow-set-accelerator","allow-set-as-windows-menu-for-nsapp","allow-set-as-help-menu-for-nsapp","allow-is-checked","allow-set-checked","allow-set-icon"]},"permissions":{"allow-append":{"identifier":"allow-append","description":"Enables the append command without any pre-configured scope.","commands":{"allow":["append"],"deny":[]}},"allow-create-default":{"identifier":"allow-create-default","description":"Enables the create_default command without any pre-configured scope.","commands":{"allow":["create_default"],"deny":[]}},"allow-get":{"identifier":"allow-get","description":"Enables the get command without any pre-configured scope.","commands":{"allow":["get"],"deny":[]}},"allow-insert":{"identifier":"allow-insert","description":"Enables the insert command without any pre-configured scope.","commands":{"allow":["insert"],"deny":[]}},"allow-is-checked":{"identifier":"allow-is-checked","description":"Enables the is_checked command without any pre-configured scope.","commands":{"allow":["is_checked"],"deny":[]}},"allow-is-enabled":{"identifier":"allow-is-enabled","description":"Enables the is_enabled command without any pre-configured scope.","commands":{"allow":["is_enabled"],"deny":[]}},"allow-items":{"identifier":"allow-items","description":"Enables the items command without any pre-configured scope.","commands":{"allow":["items"],"deny":[]}},"allow-new":{"identifier":"allow-new","description":"Enables the new command without any pre-configured scope.","commands":{"allow":["new"],"deny":[]}},"allow-popup":{"identifier":"allow-popup","description":"Enables the popup command without any pre-configured scope.","commands":{"allow":["popup"],"deny":[]}},"allow-prepend":{"identifier":"allow-prepend","description":"Enables the prepend command without any pre-configured scope.","commands":{"allow":["prepend"],"deny":[]}},"allow-remove":{"identifier":"allow-remove","description":"Enables the remove command without any pre-configured scope.","commands":{"allow":["remove"],"deny":[]}},"allow-remove-at":{"identifier":"allow-remove-at","description":"Enables the remove_at command without any pre-configured scope.","commands":{"allow":["remove_at"],"deny":[]}},"allow-set-accelerator":{"identifier":"allow-set-accelerator","description":"Enables the set_accelerator command without any pre-configured scope.","commands":{"allow":["set_accelerator"],"deny":[]}},"allow-set-as-app-menu":{"identifier":"allow-set-as-app-menu","description":"Enables the set_as_app_menu command without any pre-configured scope.","commands":{"allow":["set_as_app_menu"],"deny":[]}},"allow-set-as-help-menu-for-nsapp":{"identifier":"allow-set-as-help-menu-for-nsapp","description":"Enables the set_as_help_menu_for_nsapp command without any pre-configured scope.","commands":{"allow":["set_as_help_menu_for_nsapp"],"deny":[]}},"allow-set-as-window-menu":{"identifier":"allow-set-as-window-menu","description":"Enables the set_as_window_menu command without any pre-configured scope.","commands":{"allow":["set_as_window_menu"],"deny":[]}},"allow-set-as-windows-menu-for-nsapp":{"identifier":"allow-set-as-windows-menu-for-nsapp","description":"Enables the set_as_windows_menu_for_nsapp command without any pre-configured scope.","commands":{"allow":["set_as_windows_menu_for_nsapp"],"deny":[]}},"allow-set-checked":{"identifier":"allow-set-checked","description":"Enables the set_checked command without any pre-configured scope.","commands":{"allow":["set_checked"],"deny":[]}},"allow-set-enabled":{"identifier":"allow-set-enabled","description":"Enables the set_enabled command without any pre-configured scope.","commands":{"allow":["set_enabled"],"deny":[]}},"allow-set-icon":{"identifier":"allow-set-icon","description":"Enables the set_icon command without any pre-configured scope.","commands":{"allow":["set_icon"],"deny":[]}},"allow-set-text":{"identifier":"allow-set-text","description":"Enables the set_text command without any pre-configured scope.","commands":{"allow":["set_text"],"deny":[]}},"allow-text":{"identifier":"allow-text","description":"Enables the text command without any pre-configured scope.","commands":{"allow":["text"],"deny":[]}},"deny-append":{"identifier":"deny-append","description":"Denies the append command without any pre-configured scope.","commands":{"allow":[],"deny":["append"]}},"deny-create-default":{"identifier":"deny-create-default","description":"Denies the create_default command without any pre-configured scope.","commands":{"allow":[],"deny":["create_default"]}},"deny-get":{"identifier":"deny-get","description":"Denies the get command without any pre-configured scope.","commands":{"allow":[],"deny":["get"]}},"deny-insert":{"identifier":"deny-insert","description":"Denies the insert command without any pre-configured scope.","commands":{"allow":[],"deny":["insert"]}},"deny-is-checked":{"identifier":"deny-is-checked","description":"Denies the is_checked command without any pre-configured scope.","commands":{"allow":[],"deny":["is_checked"]}},"deny-is-enabled":{"identifier":"deny-is-enabled","description":"Denies the is_enabled command without any pre-configured scope.","commands":{"allow":[],"deny":["is_enabled"]}},"deny-items":{"identifier":"deny-items","description":"Denies the items command without any pre-configured scope.","commands":{"allow":[],"deny":["items"]}},"deny-new":{"identifier":"deny-new","description":"Denies the new command without any pre-configured scope.","commands":{"allow":[],"deny":["new"]}},"deny-popup":{"identifier":"deny-popup","description":"Denies the popup command without any pre-configured scope.","commands":{"allow":[],"deny":["popup"]}},"deny-prepend":{"identifier":"deny-prepend","description":"Denies the prepend command without any pre-configured scope.","commands":{"allow":[],"deny":["prepend"]}},"deny-remove":{"identifier":"deny-remove","description":"Denies the remove command without any pre-configured scope.","commands":{"allow":[],"deny":["remove"]}},"deny-remove-at":{"identifier":"deny-remove-at","description":"Denies the remove_at command without any pre-configured scope.","commands":{"allow":[],"deny":["remove_at"]}},"deny-set-accelerator":{"identifier":"deny-set-accelerator","description":"Denies the set_accelerator command without any pre-configured scope.","commands":{"allow":[],"deny":["set_accelerator"]}},"deny-set-as-app-menu":{"identifier":"deny-set-as-app-menu","description":"Denies the set_as_app_menu command without any pre-configured scope.","commands":{"allow":[],"deny":["set_as_app_menu"]}},"deny-set-as-help-menu-for-nsapp":{"identifier":"deny-set-as-help-menu-for-nsapp","description":"Denies the set_as_help_menu_for_nsapp command without any pre-configured scope.","commands":{"allow":[],"deny":["set_as_help_menu_for_nsapp"]}},"deny-set-as-window-menu":{"identifier":"deny-set-as-window-menu","description":"Denies the set_as_window_menu command without any pre-configured scope.","commands":{"allow":[],"deny":["set_as_window_menu"]}},"deny-set-as-windows-menu-for-nsapp":{"identifier":"deny-set-as-windows-menu-for-nsapp","description":"Denies the set_as_windows_menu_for_nsapp command without any pre-configured scope.","commands":{"allow":[],"deny":["set_as_windows_menu_for_nsapp"]}},"deny-set-checked":{"identifier":"deny-set-checked","description":"Denies the set_checked command without any pre-configured scope.","commands":{"allow":[],"deny":["set_checked"]}},"deny-set-enabled":{"identifier":"deny-set-enabled","description":"Denies the set_enabled command without any pre-configured scope.","commands":{"allow":[],"deny":["set_enabled"]}},"deny-set-icon":{"identifier":"deny-set-icon","description":"Denies the set_icon command without any pre-configured scope.","commands":{"allow":[],"deny":["set_icon"]}},"deny-set-text":{"identifier":"deny-set-text","description":"Denies the set_text command without any pre-configured scope.","commands":{"allow":[],"deny":["set_text"]}},"deny-text":{"identifier":"deny-text","description":"Denies the text command without any pre-configured scope.","commands":{"allow":[],"deny":["text"]}}},"permission_sets":{},"global_scope_schema":null},"core:path":{"default_permission":{"identifier":"default","description":"Default permissions for the plugin, which enables all commands.","permissions":["allow-resolve-directory","allow-resolve","allow-normalize","allow-join","allow-dirname","allow-extname","allow-basename","allow-is-absolute"]},"permissions":{"allow-basename":{"identifier":"allow-basename","description":"Enables the basename command without any pre-configured scope.","commands":{"allow":["basename"],"deny":[]}},"allow-dirname":{"identifier":"allow-dirname","description":"Enables the dirname command without any pre-configured scope.","commands":{"allow":["dirname"],"deny":[]}},"allow-extname":{"identifier":"allow-extname","description":"Enables the extname command without any pre-configured scope.","commands":{"allow":["extname"],"deny":[]}},"allow-is-absolute":{"identifier":"allow-is-absolute","description":"Enables the is_absolute command without any pre-configured scope.","commands":{"allow":["is_absolute"],"deny":[]}},"allow-join":{"identifier":"allow-join","description":"Enables the join command without any pre-configured scope.","commands":{"allow":["join"],"deny":[]}},"allow-normalize":{"identifier":"allow-normalize","description":"Enables the normalize command without any pre-configured scope.","commands":{"allow":["normalize"],"deny":[]}},"allow-resolve":{"identifier":"allow-resolve","description":"Enables the resolve command without any pre-configured scope.","commands":{"allow":["resolve"],"deny":[]}},"allow-resolve-directory":{"identifier":"allow-resolve-directory","description":"Enables the resolve_directory command without any pre-configured scope.","commands":{"allow":["resolve_directory"],"deny":[]}},"deny-basename":{"identifier":"deny-basename","description":"Denies the basename command without any pre-configured scope.","commands":{"allow":[],"deny":["basename"]}},"deny-dirname":{"identifier":"deny-dirname","description":"Denies the dirname command without any pre-configured scope.","commands":{"allow":[],"deny":["dirname"]}},"deny-extname":{"identifier":"deny-extname","description":"Denies the extname command without any pre-configured scope.","commands":{"allow":[],"deny":["extname"]}},"deny-is-absolute":{"identifier":"deny-is-absolute","description":"Denies the is_absolute command without any pre-configured scope.","commands":{"allow":[],"deny":["is_absolute"]}},"deny-join":{"identifier":"deny-join","description":"Denies the join command without any pre-configured scope.","commands":{"allow":[],"deny":["join"]}},"deny-normalize":{"identifier":"deny-normalize","description":"Denies the normalize command without any pre-configured scope.","commands":{"allow":[],"deny":["normalize"]}},"deny-resolve":{"identifier":"deny-resolve","description":"Denies the resolve command without any pre-configured scope.","commands":{"allow":[],"deny":["resolve"]}},"deny-resolve-directory":{"identifier":"deny-resolve-directory","description":"Denies the resolve_directory command without any pre-configured scope.","commands":{"allow":[],"deny":["resolve_directory"]}}},"permission_sets":{},"global_scope_schema":null},"core:resources":{"default_permission":{"identifier":"default","description":"Default permissions for the plugin, which enables all commands.","permissions":["allow-close"]},"permissions":{"allow-close":{"identifier":"allow-close","description":"Enables the close command without any pre-configured scope.","commands":{"allow":["close"],"deny":[]}},"deny-close":{"identifier":"deny-close","description":"Denies the close command without any pre-configured scope.","commands":{"allow":[],"deny":["close"]}}},"permission_sets":{},"global_scope_schema":null},"core:tray":{"default_permission":{"identifier":"default","description":"Default permissions for the plugin, which enables all commands.","permissions":["allow-new","allow-get-by-id","allow-remove-by-id","allow-set-icon","allow-set-menu","allow-set-tooltip","allow-set-title","allow-set-visible","allow-set-temp-dir-path","allow-set-icon-as-template","allow-set-show-menu-on-left-click"]},"permissions":{"allow-get-by-id":{"identifier":"allow-get-by-id","description":"Enables the get_by_id command without any pre-configured scope.","commands":{"allow":["get_by_id"],"deny":[]}},"allow-new":{"identifier":"allow-new","description":"Enables the new command without any pre-configured scope.","commands":{"allow":["new"],"deny":[]}},"allow-remove-by-id":{"identifier":"allow-remove-by-id","description":"Enables the remove_by_id command without any pre-configured scope.","commands":{"allow":["remove_by_id"],"deny":[]}},"allow-set-icon":{"identifier":"allow-set-icon","description":"Enables the set_icon command without any pre-configured scope.","commands":{"allow":["set_icon"],"deny":[]}},"allow-set-icon-as-template":{"identifier":"allow-set-icon-as-template","description":"Enables the set_icon_as_template command without any pre-configured scope.","commands":{"allow":["set_icon_as_template"],"deny":[]}},"allow-set-menu":{"identifier":"allow-set-menu","description":"Enables the set_menu command without any pre-configured scope.","commands":{"allow":["set_menu"],"deny":[]}},"allow-set-show-menu-on-left-click":{"identifier":"allow-set-show-menu-on-left-click","description":"Enables the set_show_menu_on_left_click command without any pre-configured scope.","commands":{"allow":["set_show_menu_on_left_click"],"deny":[]}},"allow-set-temp-dir-path":{"identifier":"allow-set-temp-dir-path","description":"Enables the set_temp_dir_path command without any pre-configured scope.","commands":{"allow":["set_temp_dir_path"],"deny":[]}},"allow-set-title":{"identifier":"allow-set-title","description":"Enables the set_title command without any pre-configured scope.","commands":{"allow":["set_title"],"deny":[]}},"allow-set-tooltip":{"identifier":"allow-set-tooltip","description":"Enables the set_tooltip command without any pre-configured scope.","commands":{"allow":["set_tooltip"],"deny":[]}},"allow-set-visible":{"identifier":"allow-set-visible","description":"Enables the set_visible command without any pre-configured scope.","commands":{"allow":["set_visible"],"deny":[]}},"deny-get-by-id":{"identifier":"deny-get-by-id","description":"Denies the get_by_id command without any pre-configured scope.","commands":{"allow":[],"deny":["get_by_id"]}},"deny-new":{"identifier":"deny-new","description":"Denies the new command without any pre-configured scope.","commands":{"allow":[],"deny":["new"]}},"deny-remove-by-id":{"identifier":"deny-remove-by-id","description":"Denies the remove_by_id command without any pre-configured scope.","commands":{"allow":[],"deny":["remove_by_id"]}},"deny-set-icon":{"identifier":"deny-set-icon","description":"Denies the set_icon command without any pre-configured scope.","commands":{"allow":[],"deny":["set_icon"]}},"deny-set-icon-as-template":{"identifier":"deny-set-icon-as-template","description":"Denies the set_icon_as_template command without any pre-configured scope.","commands":{"allow":[],"deny":["set_icon_as_template"]}},"deny-set-menu":{"identifier":"deny-set-menu","description":"Denies the set_menu command without any pre-configured scope.","commands":{"allow":[],"deny":["set_menu"]}},"deny-set-show-menu-on-left-click":{"identifier":"deny-set-show-menu-on-left-click","description":"Denies the set_show_menu_on_left_click command without any pre-configured scope.","commands":{"allow":[],"deny":["set_show_menu_on_left_click"]}},"deny-set-temp-dir-path":{"identifier":"deny-set-temp-dir-path","description":"Denies the set_temp_dir_path command without any pre-configured scope.","commands":{"allow":[],"deny":["set_temp_dir_path"]}},"deny-set-title":{"identifier":"deny-set-title","description":"Denies the set_title command without any pre-configured scope.","commands":{"allow":[],"deny":["set_title"]}},"deny-set-tooltip":{"identifier":"deny-set-tooltip","description":"Denies the set_tooltip command without any pre-configured scope.","commands":{"allow":[],"deny":["set_tooltip"]}},"deny-set-visible":{"identifier":"deny-set-visible","description":"Denies the set_visible command without any pre-configured scope.","commands":{"allow":[],"deny":["set_visible"]}}},"permission_sets":{},"global_scope_schema":null},"core:webview":{"default_permission":{"identifier":"default","description":"Default permissions for the plugin.","permissions":["allow-get-all-webviews","allow-webview-position","allow-webview-size","allow-internal-toggle-devtools"]},"permissions":{"allow-clear-all-browsing-data":{"identifier":"allow-clear-all-browsing-data","description":"Enables the clear_all_browsing_data command without any pre-configured scope.","commands":{"allow":["clear_all_browsing_data"],"deny":[]}},"allow-create-webview":{"identifier":"allow-create-webview","description":"Enables the create_webview command without any pre-configured scope.","commands":{"allow":["create_webview"],"deny":[]}},"allow-create-webview-window":{"identifier":"allow-create-webview-window","description":"Enables the create_webview_window command without any pre-configured scope.","commands":{"allow":["create_webview_window"],"deny":[]}},"allow-get-all-webviews":{"identifier":"allow-get-all-webviews","description":"Enables the get_all_webviews command without any pre-configured scope.","commands":{"allow":["get_all_webviews"],"deny":[]}},"allow-internal-toggle-devtools":{"identifier":"allow-internal-toggle-devtools","description":"Enables the internal_toggle_devtools command without any pre-configured scope.","commands":{"allow":["internal_toggle_devtools"],"deny":[]}},"allow-print":{"identifier":"allow-print","description":"Enables the print command without any pre-configured scope.","commands":{"allow":["print"],"deny":[]}},"allow-reparent":{"identifier":"allow-reparent","description":"Enables the reparent command without any pre-configured scope.","commands":{"allow":["reparent"],"deny":[]}},"allow-set-webview-auto-resize":{"identifier":"allow-set-webview-auto-resize","description":"Enables the set_webview_auto_resize command without any pre-configured scope.","commands":{"allow":["set_webview_auto_resize"],"deny":[]}},"allow-set-webview-background-color":{"identifier":"allow-set-webview-background-color","description":"Enables the set_webview_background_color command without any pre-configured scope.","commands":{"allow":["set_webview_background_color"],"deny":[]}},"allow-set-webview-focus":{"identifier":"allow-set-webview-focus","description":"Enables the set_webview_focus command without any pre-configured scope.","commands":{"allow":["set_webview_focus"],"deny":[]}},"allow-set-webview-position":{"identifier":"allow-set-webview-position","description":"Enables the set_webview_position command without any pre-configured scope.","commands":{"allow":["set_webview_position"],"deny":[]}},"allow-set-webview-size":{"identifier":"allow-set-webview-size","description":"Enables the set_webview_size command without any pre-configured scope.","commands":{"allow":["set_webview_size"],"deny":[]}},"allow-set-webview-zoom":{"identifier":"allow-set-webview-zoom","description":"Enables the set_webview_zoom command without any pre-configured scope.","commands":{"allow":["set_webview_zoom"],"deny":[]}},"allow-webview-close":{"identifier":"allow-webview-close","description":"Enables the webview_close command without any pre-configured scope.","commands":{"allow":["webview_close"],"deny":[]}},"allow-webview-hide":{"identifier":"allow-webview-hide","description":"Enables the webview_hide command without any pre-configured scope.","commands":{"allow":["webview_hide"],"deny":[]}},"allow-webview-position":{"identifier":"allow-webview-position","description":"Enables the webview_position command without any pre-configured scope.","commands":{"allow":["webview_position"],"deny":[]}},"allow-webview-show":{"identifier":"allow-webview-show","description":"Enables the webview_show command without any pre-configured scope.","commands":{"allow":["webview_show"],"deny":[]}},"allow-webview-size":{"identifier":"allow-webview-size","description":"Enables the webview_size command without any pre-configured scope.","commands":{"allow":["webview_size"],"deny":[]}},"deny-clear-all-browsing-data":{"identifier":"deny-clear-all-browsing-data","description":"Denies the clear_all_browsing_data command without any pre-configured scope.","commands":{"allow":[],"deny":["clear_all_browsing_data"]}},"deny-create-webview":{"identifier":"deny-create-webview","description":"Denies the create_webview command without any pre-configured scope.","commands":{"allow":[],"deny":["create_webview"]}},"deny-create-webview-window":{"identifier":"deny-create-webview-window","description":"Denies the create_webview_window command without any pre-configured scope.","commands":{"allow":[],"deny":["create_webview_window"]}},"deny-get-all-webviews":{"identifier":"deny-get-all-webviews","description":"Denies the get_all_webviews command without any pre-configured scope.","commands":{"allow":[],"deny":["get_all_webviews"]}},"deny-internal-toggle-devtools":{"identifier":"deny-internal-toggle-devtools","description":"Denies the internal_toggle_devtools command without any pre-configured scope.","commands":{"allow":[],"deny":["internal_toggle_devtools"]}},"deny-print":{"identifier":"deny-print","description":"Denies the print command without any pre-configured scope.","commands":{"allow":[],"deny":["print"]}},"deny-reparent":{"identifier":"deny-reparent","description":"Denies the reparent command without any pre-configured scope.","commands":{"allow":[],"deny":["reparent"]}},"deny-set-webview-auto-resize":{"identifier":"deny-set-webview-auto-resize","description":"Denies the set_webview_auto_resize command without any pre-configured scope.","commands":{"allow":[],"deny":["set_webview_auto_resize"]}},"deny-set-webview-background-color":{"identifier":"deny-set-webview-background-color","description":"Denies the set_webview_background_color command without any pre-configured scope.","commands":{"allow":[],"deny":["set_webview_background_color"]}},"deny-set-webview-focus":{"identifier":"deny-set-webview-focus","description":"Denies the set_webview_focus command without any pre-configured scope.","commands":{"allow":[],"deny":["set_webview_focus"]}},"deny-set-webview-position":{"identifier":"deny-set-webview-position","description":"Denies the set_webview_position command without any pre-configured scope.","commands":{"allow":[],"deny":["set_webview_position"]}},"deny-set-webview-size":{"identifier":"deny-set-webview-size","description":"Denies the set_webview_size command without any pre-configured scope.","commands":{"allow":[],"deny":["set_webview_size"]}},"deny-set-webview-zoom":{"identifier":"deny-set-webview-zoom","description":"Denies the set_webview_zoom command without any pre-configured scope.","commands":{"allow":[],"deny":["set_webview_zoom"]}},"deny-webview-close":{"identifier":"deny-webview-close","description":"Denies the webview_close command without any pre-configured scope.","commands":{"allow":[],"deny":["webview_close"]}},"deny-webview-hide":{"identifier":"deny-webview-hide","description":"Denies the webview_hide command without any pre-configured scope.","commands":{"allow":[],"deny":["webview_hide"]}},"deny-webview-position":{"identifier":"deny-webview-position","description":"Denies the webview_position command without any pre-configured scope.","commands":{"allow":[],"deny":["webview_position"]}},"deny-webview-show":{"identifier":"deny-webview-show","description":"Denies the webview_show command without any pre-configured scope.","commands":{"allow":[],"deny":["webview_show"]}},"deny-webview-size":{"identifier":"deny-webview-size","description":"Denies the webview_size command without any pre-configured scope.","commands":{"allow":[],"deny":["webview_size"]}}},"permission_sets":{},"global_scope_schema":null},"core:window":{"default_permission":{"identifier":"default","description":"Default permissions for the plugin.","permissions":["allow-get-all-windows","allow-scale-factor","allow-inner-position","allow-outer-position","allow-inner-size","allow-outer-size","allow-is-fullscreen","allow-is-minimized","allow-is-maximized","allow-is-focused","allow-is-decorated","allow-is-resizable","allow-is-maximizable","allow-is-minimizable","allow-is-closable","allow-is-visible","allow-is-enabled","allow-title","allow-current-monitor","allow-primary-monitor","allow-monitor-from-point","allow-available-monitors","allow-cursor-position","allow-theme","allow-is-always-on-top","allow-internal-toggle-maximize"]},"permissions":{"allow-available-monitors":{"identifier":"allow-available-monitors","description":"Enables the available_monitors command without any pre-configured scope.","commands":{"allow":["available_monitors"],"deny":[]}},"allow-center":{"identifier":"allow-center","description":"Enables the center command without any pre-configured scope.","commands":{"allow":["center"],"deny":[]}},"allow-close":{"identifier":"allow-close","description":"Enables the close command without any pre-configured scope.","commands":{"allow":["close"],"deny":[]}},"allow-create":{"identifier":"allow-create","description":"Enables the create command without any pre-configured scope.","commands":{"allow":["create"],"deny":[]}},"allow-current-monitor":{"identifier":"allow-current-monitor","description":"Enables the current_monitor command without any pre-configured scope.","commands":{"allow":["current_monitor"],"deny":[]}},"allow-cursor-position":{"identifier":"allow-cursor-position","description":"Enables the cursor_position command without any pre-configured scope.","commands":{"allow":["cursor_position"],"deny":[]}},"allow-destroy":{"identifier":"allow-destroy","description":"Enables the destroy command without any pre-configured scope.","commands":{"allow":["destroy"],"deny":[]}},"allow-get-all-windows":{"identifier":"allow-get-all-windows","description":"Enables the get_all_windows command without any pre-configured scope.","commands":{"allow":["get_all_windows"],"deny":[]}},"allow-hide":{"identifier":"allow-hide","description":"Enables the hide command without any pre-configured scope.","commands":{"allow":["hide"],"deny":[]}},"allow-inner-position":{"identifier":"allow-inner-position","description":"Enables the inner_position command without any pre-configured scope.","commands":{"allow":["inner_position"],"deny":[]}},"allow-inner-size":{"identifier":"allow-inner-size","description":"Enables the inner_size command without any pre-configured scope.","commands":{"allow":["inner_size"],"deny":[]}},"allow-internal-toggle-maximize":{"identifier":"allow-internal-toggle-maximize","description":"Enables the internal_toggle_maximize command without any pre-configured scope.","commands":{"allow":["internal_toggle_maximize"],"deny":[]}},"allow-is-always-on-top":{"identifier":"allow-is-always-on-top","description":"Enables the is_always_on_top command without any pre-configured scope.","commands":{"allow":["is_always_on_top"],"deny":[]}},"allow-is-closable":{"identifier":"allow-is-closable","description":"Enables the is_closable command without any pre-configured scope.","commands":{"allow":["is_closable"],"deny":[]}},"allow-is-decorated":{"identifier":"allow-is-decorated","description":"Enables the is_decorated command without any pre-configured scope.","commands":{"allow":["is_decorated"],"deny":[]}},"allow-is-enabled":{"identifier":"allow-is-enabled","description":"Enables the is_enabled command without any pre-configured scope.","commands":{"allow":["is_enabled"],"deny":[]}},"allow-is-focused":{"identifier":"allow-is-focused","description":"Enables the is_focused command without any pre-configured scope.","commands":{"allow":["is_focused"],"deny":[]}},"allow-is-fullscreen":{"identifier":"allow-is-fullscreen","description":"Enables the is_fullscreen command without any pre-configured scope.","commands":{"allow":["is_fullscreen"],"deny":[]}},"allow-is-maximizable":{"identifier":"allow-is-maximizable","description":"Enables the is_maximizable command without any pre-configured scope.","commands":{"allow":["is_maximizable"],"deny":[]}},"allow-is-maximized":{"identifier":"allow-is-maximized","description":"Enables the is_maximized command without any pre-configured scope.","commands":{"allow":["is_maximized"],"deny":[]}},"allow-is-minimizable":{"identifier":"allow-is-minimizable","description":"Enables the is_minimizable command without any pre-configured scope.","commands":{"allow":["is_minimizable"],"deny":[]}},"allow-is-minimized":{"identifier":"allow-is-minimized","description":"Enables the is_minimized command without any pre-configured scope.","commands":{"allow":["is_minimized"],"deny":[]}},"allow-is-resizable":{"identifier":"allow-is-resizable","description":"Enables the is_resizable command without any pre-configured scope.","commands":{"allow":["is_resizable"],"deny":[]}},"allow-is-visible":{"identifier":"allow-is-visible","description":"Enables the is_visible command without any pre-configured scope.","commands":{"allow":["is_visible"],"deny":[]}},"allow-maximize":{"identifier":"allow-maximize","description":"Enables the maximize command without any pre-configured scope.","commands":{"allow":["maximize"],"deny":[]}},"allow-minimize":{"identifier":"allow-minimize","description":"Enables the minimize command without any pre-configured scope.","commands":{"allow":["minimize"],"deny":[]}},"allow-monitor-from-point":{"identifier":"allow-monitor-from-point","description":"Enables the monitor_from_point command without any pre-configured scope.","commands":{"allow":["monitor_from_point"],"deny":[]}},"allow-outer-position":{"identifier":"allow-outer-position","description":"Enables the outer_position command without any pre-configured scope.","commands":{"allow":["outer_position"],"deny":[]}},"allow-outer-size":{"identifier":"allow-outer-size","description":"Enables the outer_size command without any pre-configured scope.","commands":{"allow":["outer_size"],"deny":[]}},"allow-primary-monitor":{"identifier":"allow-primary-monitor","description":"Enables the primary_monitor command without any pre-configured scope.","commands":{"allow":["primary_monitor"],"deny":[]}},"allow-request-user-attention":{"identifier":"allow-request-user-attention","description":"Enables the request_user_attention command without any pre-configured scope.","commands":{"allow":["request_user_attention"],"deny":[]}},"allow-scale-factor":{"identifier":"allow-scale-factor","description":"Enables the scale_factor command without any pre-configured scope.","commands":{"allow":["scale_factor"],"deny":[]}},"allow-set-always-on-bottom":{"identifier":"allow-set-always-on-bottom","description":"Enables the set_always_on_bottom command without any pre-configured scope.","commands":{"allow":["set_always_on_bottom"],"deny":[]}},"allow-set-always-on-top":{"identifier":"allow-set-always-on-top","description":"Enables the set_always_on_top command without any pre-configured scope.","commands":{"allow":["set_always_on_top"],"deny":[]}},"allow-set-background-color":{"identifier":"allow-set-background-color","description":"Enables the set_background_color command without any pre-configured scope.","commands":{"allow":["set_background_color"],"deny":[]}},"allow-set-badge-count":{"identifier":"allow-set-badge-count","description":"Enables the set_badge_count command without any pre-configured scope.","commands":{"allow":["set_badge_count"],"deny":[]}},"allow-set-badge-label":{"identifier":"allow-set-badge-label","description":"Enables the set_badge_label command without any pre-configured scope.","commands":{"allow":["set_badge_label"],"deny":[]}},"allow-set-closable":{"identifier":"allow-set-closable","description":"Enables the set_closable command without any pre-configured scope.","commands":{"allow":["set_closable"],"deny":[]}},"allow-set-content-protected":{"identifier":"allow-set-content-protected","description":"Enables the set_content_protected command without any pre-configured scope.","commands":{"allow":["set_content_protected"],"deny":[]}},"allow-set-cursor-grab":{"identifier":"allow-set-cursor-grab","description":"Enables the set_cursor_grab command without any pre-configured scope.","commands":{"allow":["set_cursor_grab"],"deny":[]}},"allow-set-cursor-icon":{"identifier":"allow-set-cursor-icon","description":"Enables the set_cursor_icon command without any pre-configured scope.","commands":{"allow":["set_cursor_icon"],"deny":[]}},"allow-set-cursor-position":{"identifier":"allow-set-cursor-position","description":"Enables the set_cursor_position command without any pre-configured scope.","commands":{"allow":["set_cursor_position"],"deny":[]}},"allow-set-cursor-visible":{"identifier":"allow-set-cursor-visible","description":"Enables the set_cursor_visible command without any pre-configured scope.","commands":{"allow":["set_cursor_visible"],"deny":[]}},"allow-set-decorations":{"identifier":"allow-set-decorations","description":"Enables the set_decorations command without any pre-configured scope.","commands":{"allow":["set_decorations"],"deny":[]}},"allow-set-effects":{"identifier":"allow-set-effects","description":"Enables the set_effects command without any pre-configured scope.","commands":{"allow":["set_effects"],"deny":[]}},"allow-set-enabled":{"identifier":"allow-set-enabled","description":"Enables the set_enabled command without any pre-configured scope.","commands":{"allow":["set_enabled"],"deny":[]}},"allow-set-focus":{"identifier":"allow-set-focus","description":"Enables the set_focus command without any pre-configured scope.","commands":{"allow":["set_focus"],"deny":[]}},"allow-set-focusable":{"identifier":"allow-set-focusable","description":"Enables the set_focusable command without any pre-configured scope.","commands":{"allow":["set_focusable"],"deny":[]}},"allow-set-fullscreen":{"identifier":"allow-set-fullscreen","description":"Enables the set_fullscreen command without any pre-configured scope.","commands":{"allow":["set_fullscreen"],"deny":[]}},"allow-set-icon":{"identifier":"allow-set-icon","description":"Enables the set_icon command without any pre-configured scope.","commands":{"allow":["set_icon"],"deny":[]}},"allow-set-ignore-cursor-events":{"identifier":"allow-set-ignore-cursor-events","description":"Enables the set_ignore_cursor_events command without any pre-configured scope.","commands":{"allow":["set_ignore_cursor_events"],"deny":[]}},"allow-set-max-size":{"identifier":"allow-set-max-size","description":"Enables the set_max_size command without any pre-configured scope.","commands":{"allow":["set_max_size"],"deny":[]}},"allow-set-maximizable":{"identifier":"allow-set-maximizable","description":"Enables the set_maximizable command without any pre-configured scope.","commands":{"allow":["set_maximizable"],"deny":[]}},"allow-set-min-size":{"identifier":"allow-set-min-size","description":"Enables the set_min_size command without any pre-configured scope.","commands":{"allow":["set_min_size"],"deny":[]}},"allow-set-minimizable":{"identifier":"allow-set-minimizable","description":"Enables the set_minimizable command without any pre-configured scope.","commands":{"allow":["set_minimizable"],"deny":[]}},"allow-set-overlay-icon":{"identifier":"allow-set-overlay-icon","description":"Enables the set_overlay_icon command without any pre-configured scope.","commands":{"allow":["set_overlay_icon"],"deny":[]}},"allow-set-position":{"identifier":"allow-set-position","description":"Enables the set_position command without any pre-configured scope.","commands":{"allow":["set_position"],"deny":[]}},"allow-set-progress-bar":{"identifier":"allow-set-progress-bar","description":"Enables the set_progress_bar command without any pre-configured scope.","commands":{"allow":["set_progress_bar"],"deny":[]}},"allow-set-resizable":{"identifier":"allow-set-resizable","description":"Enables the set_resizable command without any pre-configured scope.","commands":{"allow":["set_resizable"],"deny":[]}},"allow-set-shadow":{"identifier":"allow-set-shadow","description":"Enables the set_shadow command without any pre-configured scope.","commands":{"allow":["set_shadow"],"deny":[]}},"allow-set-simple-fullscreen":{"identifier":"allow-set-simple-fullscreen","description":"Enables the set_simple_fullscreen command without any pre-configured scope.","commands":{"allow":["set_simple_fullscreen"],"deny":[]}},"allow-set-size":{"identifier":"allow-set-size","description":"Enables the set_size command without any pre-configured scope.","commands":{"allow":["set_size"],"deny":[]}},"allow-set-size-constraints":{"identifier":"allow-set-size-constraints","description":"Enables the set_size_constraints command without any pre-configured scope.","commands":{"allow":["set_size_constraints"],"deny":[]}},"allow-set-skip-taskbar":{"identifier":"allow-set-skip-taskbar","description":"Enables the set_skip_taskbar command without any pre-configured scope.","commands":{"allow":["set_skip_taskbar"],"deny":[]}},"allow-set-theme":{"identifier":"allow-set-theme","description":"Enables the set_theme command without any pre-configured scope.","commands":{"allow":["set_theme"],"deny":[]}},"allow-set-title":{"identifier":"allow-set-title","description":"Enables the set_title command without any pre-configured scope.","commands":{"allow":["set_title"],"deny":[]}},"allow-set-title-bar-style":{"identifier":"allow-set-title-bar-style","description":"Enables the set_title_bar_style command without any pre-configured scope.","commands":{"allow":["set_title_bar_style"],"deny":[]}},"allow-set-visible-on-all-workspaces":{"identifier":"allow-set-visible-on-all-workspaces","description":"Enables the set_visible_on_all_workspaces command without any pre-configured scope.","commands":{"allow":["set_visible_on_all_workspaces"],"deny":[]}},"allow-show":{"identifier":"allow-show","description":"Enables the show command without any pre-configured scope.","commands":{"allow":["show"],"deny":[]}},"allow-start-dragging":{"identifier":"allow-start-dragging","description":"Enables the start_dragging command without any pre-configured scope.","commands":{"allow":["start_dragging"],"deny":[]}},"allow-start-resize-dragging":{"identifier":"allow-start-resize-dragging","description":"Enables the start_resize_dragging command without any pre-configured scope.","commands":{"allow":["start_resize_dragging"],"deny":[]}},"allow-theme":{"identifier":"allow-theme","description":"Enables the theme command without any pre-configured scope.","commands":{"allow":["theme"],"deny":[]}},"allow-title":{"identifier":"allow-title","description":"Enables the title command without any pre-configured scope.","commands":{"allow":["title"],"deny":[]}},"allow-toggle-maximize":{"identifier":"allow-toggle-maximize","description":"Enables the toggle_maximize command without any pre-configured scope.","commands":{"allow":["toggle_maximize"],"deny":[]}},"allow-unmaximize":{"identifier":"allow-unmaximize","description":"Enables the unmaximize command without any pre-configured scope.","commands":{"allow":["unmaximize"],"deny":[]}},"allow-unminimize":{"identifier":"allow-unminimize","description":"Enables the unminimize command without any pre-configured scope.","commands":{"allow":["unminimize"],"deny":[]}},"deny-available-monitors":{"identifier":"deny-available-monitors","description":"Denies the available_monitors command without any pre-configured scope.","commands":{"allow":[],"deny":["available_monitors"]}},"deny-center":{"identifier":"deny-center","description":"Denies the center command without any pre-configured scope.","commands":{"allow":[],"deny":["center"]}},"deny-close":{"identifier":"deny-close","description":"Denies the close command without any pre-configured scope.","commands":{"allow":[],"deny":["close"]}},"deny-create":{"identifier":"deny-create","description":"Denies the create command without any pre-configured scope.","commands":{"allow":[],"deny":["create"]}},"deny-current-monitor":{"identifier":"deny-current-monitor","description":"Denies the current_monitor command without any pre-configured scope.","commands":{"allow":[],"deny":["current_monitor"]}},"deny-cursor-position":{"identifier":"deny-cursor-position","description":"Denies the cursor_position command without any pre-configured scope.","commands":{"allow":[],"deny":["cursor_position"]}},"deny-destroy":{"identifier":"deny-destroy","description":"Denies the destroy command without any pre-configured scope.","commands":{"allow":[],"deny":["destroy"]}},"deny-get-all-windows":{"identifier":"deny-get-all-windows","description":"Denies the get_all_windows command without any pre-configured scope.","commands":{"allow":[],"deny":["get_all_windows"]}},"deny-hide":{"identifier":"deny-hide","description":"Denies the hide command without any pre-configured scope.","commands":{"allow":[],"deny":["hide"]}},"deny-inner-position":{"identifier":"deny-inner-position","description":"Denies the inner_position command without any pre-configured scope.","commands":{"allow":[],"deny":["inner_position"]}},"deny-inner-size":{"identifier":"deny-inner-size","description":"Denies the inner_size command without any pre-configured scope.","commands":{"allow":[],"deny":["inner_size"]}},"deny-internal-toggle-maximize":{"identifier":"deny-internal-toggle-maximize","description":"Denies the internal_toggle_maximize command without any pre-configured scope.","commands":{"allow":[],"deny":["internal_toggle_maximize"]}},"deny-is-always-on-top":{"identifier":"deny-is-always-on-top","description":"Denies the is_always_on_top command without any pre-configured scope.","commands":{"allow":[],"deny":["is_always_on_top"]}},"deny-is-closable":{"identifier":"deny-is-closable","description":"Denies the is_closable command without any pre-configured scope.","commands":{"allow":[],"deny":["is_closable"]}},"deny-is-decorated":{"identifier":"deny-is-decorated","description":"Denies the is_decorated command without any pre-configured scope.","commands":{"allow":[],"deny":["is_decorated"]}},"deny-is-enabled":{"identifier":"deny-is-enabled","description":"Denies the is_enabled command without any pre-configured scope.","commands":{"allow":[],"deny":["is_enabled"]}},"deny-is-focused":{"identifier":"deny-is-focused","description":"Denies the is_focused command without any pre-configured scope.","commands":{"allow":[],"deny":["is_focused"]}},"deny-is-fullscreen":{"identifier":"deny-is-fullscreen","description":"Denies the is_fullscreen command without any pre-configured scope.","commands":{"allow":[],"deny":["is_fullscreen"]}},"deny-is-maximizable":{"identifier":"deny-is-maximizable","description":"Denies the is_maximizable command without any pre-configured scope.","commands":{"allow":[],"deny":["is_maximizable"]}},"deny-is-maximized":{"identifier":"deny-is-maximized","description":"Denies the is_maximized command without any pre-configured scope.","commands":{"allow":[],"deny":["is_maximized"]}},"deny-is-minimizable":{"identifier":"deny-is-minimizable","description":"Denies the is_minimizable command without any pre-configured scope.","commands":{"allow":[],"deny":["is_minimizable"]}},"deny-is-minimized":{"identifier":"deny-is-minimized","description":"Denies the is_minimized command without any pre-configured scope.","commands":{"allow":[],"deny":["is_minimized"]}},"deny-is-resizable":{"identifier":"deny-is-resizable","description":"Denies the is_resizable command without any pre-configured scope.","commands":{"allow":[],"deny":["is_resizable"]}},"deny-is-visible":{"identifier":"deny-is-visible","description":"Denies the is_visible command without any pre-configured scope.","commands":{"allow":[],"deny":["is_visible"]}},"deny-maximize":{"identifier":"deny-maximize","description":"Denies the maximize command without any pre-configured scope.","commands":{"allow":[],"deny":["maximize"]}},"deny-minimize":{"identifier":"deny-minimize","description":"Denies the minimize command without any pre-configured scope.","commands":{"allow":[],"deny":["minimize"]}},"deny-monitor-from-point":{"identifier":"deny-monitor-from-point","description":"Denies the monitor_from_point command without any pre-configured scope.","commands":{"allow":[],"deny":["monitor_from_point"]}},"deny-outer-position":{"identifier":"deny-outer-position","description":"Denies the outer_position command without any pre-configured scope.","commands":{"allow":[],"deny":["outer_position"]}},"deny-outer-size":{"identifier":"deny-outer-size","description":"Denies the outer_size command without any pre-configured scope.","commands":{"allow":[],"deny":["outer_size"]}},"deny-primary-monitor":{"identifier":"deny-primary-monitor","description":"Denies the primary_monitor command without any pre-configured scope.","commands":{"allow":[],"deny":["primary_monitor"]}},"deny-request-user-attention":{"identifier":"deny-request-user-attention","description":"Denies the request_user_attention command without any pre-configured scope.","commands":{"allow":[],"deny":["request_user_attention"]}},"deny-scale-factor":{"identifier":"deny-scale-factor","description":"Denies the scale_factor command without any pre-configured scope.","commands":{"allow":[],"deny":["scale_factor"]}},"deny-set-always-on-bottom":{"identifier":"deny-set-always-on-bottom","description":"Denies the set_always_on_bottom command without any pre-configured scope.","commands":{"allow":[],"deny":["set_always_on_bottom"]}},"deny-set-always-on-top":{"identifier":"deny-set-always-on-top","description":"Denies the set_always_on_top command without any pre-configured scope.","commands":{"allow":[],"deny":["set_always_on_top"]}},"deny-set-background-color":{"identifier":"deny-set-background-color","description":"Denies the set_background_color command without any pre-configured scope.","commands":{"allow":[],"deny":["set_background_color"]}},"deny-set-badge-count":{"identifier":"deny-set-badge-count","description":"Denies the set_badge_count command without any pre-configured scope.","commands":{"allow":[],"deny":["set_badge_count"]}},"deny-set-badge-label":{"identifier":"deny-set-badge-label","description":"Denies the set_badge_label command without any pre-configured scope.","commands":{"allow":[],"deny":["set_badge_label"]}},"deny-set-closable":{"identifier":"deny-set-closable","description":"Denies the set_closable command without any pre-configured scope.","commands":{"allow":[],"deny":["set_closable"]}},"deny-set-content-protected":{"identifier":"deny-set-content-protected","description":"Denies the set_content_protected command without any pre-configured scope.","commands":{"allow":[],"deny":["set_content_protected"]}},"deny-set-cursor-grab":{"identifier":"deny-set-cursor-grab","description":"Denies the set_cursor_grab command without any pre-configured scope.","commands":{"allow":[],"deny":["set_cursor_grab"]}},"deny-set-cursor-icon":{"identifier":"deny-set-cursor-icon","description":"Denies the set_cursor_icon command without any pre-configured scope.","commands":{"allow":[],"deny":["set_cursor_icon"]}},"deny-set-cursor-position":{"identifier":"deny-set-cursor-position","description":"Denies the set_cursor_position command without any pre-configured scope.","commands":{"allow":[],"deny":["set_cursor_position"]}},"deny-set-cursor-visible":{"identifier":"deny-set-cursor-visible","description":"Denies the set_cursor_visible command without any pre-configured scope.","commands":{"allow":[],"deny":["set_cursor_visible"]}},"deny-set-decorations":{"identifier":"deny-set-decorations","description":"Denies the set_decorations command without any pre-configured scope.","commands":{"allow":[],"deny":["set_decorations"]}},"deny-set-effects":{"identifier":"deny-set-effects","description":"Denies the set_effects command without any pre-configured scope.","commands":{"allow":[],"deny":["set_effects"]}},"deny-set-enabled":{"identifier":"deny-set-enabled","description":"Denies the set_enabled command without any pre-configured scope.","commands":{"allow":[],"deny":["set_enabled"]}},"deny-set-focus":{"identifier":"deny-set-focus","description":"Denies the set_focus command without any pre-configured scope.","commands":{"allow":[],"deny":["set_focus"]}},"deny-set-focusable":{"identifier":"deny-set-focusable","description":"Denies the set_focusable command without any pre-configured scope.","commands":{"allow":[],"deny":["set_focusable"]}},"deny-set-fullscreen":{"identifier":"deny-set-fullscreen","description":"Denies the set_fullscreen command without any pre-configured scope.","commands":{"allow":[],"deny":["set_fullscreen"]}},"deny-set-icon":{"identifier":"deny-set-icon","description":"Denies the set_icon command without any pre-configured scope.","commands":{"allow":[],"deny":["set_icon"]}},"deny-set-ignore-cursor-events":{"identifier":"deny-set-ignore-cursor-events","description":"Denies the set_ignore_cursor_events command without any pre-configured scope.","commands":{"allow":[],"deny":["set_ignore_cursor_events"]}},"deny-set-max-size":{"identifier":"deny-set-max-size","description":"Denies the set_max_size command without any pre-configured scope.","commands":{"allow":[],"deny":["set_max_size"]}},"deny-set-maximizable":{"identifier":"deny-set-maximizable","description":"Denies the set_maximizable command without any pre-configured scope.","commands":{"allow":[],"deny":["set_maximizable"]}},"deny-set-min-size":{"identifier":"deny-set-min-size","description":"Denies the set_min_size command without any pre-configured scope.","commands":{"allow":[],"deny":["set_min_size"]}},"deny-set-minimizable":{"identifier":"deny-set-minimizable","description":"Denies the set_minimizable command without any pre-configured scope.","commands":{"allow":[],"deny":["set_minimizable"]}},"deny-set-overlay-icon":{"identifier":"deny-set-overlay-icon","description":"Denies the set_overlay_icon command without any pre-configured scope.","commands":{"allow":[],"deny":["set_overlay_icon"]}},"deny-set-position":{"identifier":"deny-set-position","description":"Denies the set_position command without any pre-configured scope.","commands":{"allow":[],"deny":["set_position"]}},"deny-set-progress-bar":{"identifier":"deny-set-progress-bar","description":"Denies the set_progress_bar command without any pre-configured scope.","commands":{"allow":[],"deny":["set_progress_bar"]}},"deny-set-resizable":{"identifier":"deny-set-resizable","description":"Denies the set_resizable command without any pre-configured scope.","commands":{"allow":[],"deny":["set_resizable"]}},"deny-set-shadow":{"identifier":"deny-set-shadow","description":"Denies the set_shadow command without any pre-configured scope.","commands":{"allow":[],"deny":["set_shadow"]}},"deny-set-simple-fullscreen":{"identifier":"deny-set-simple-fullscreen","description":"Denies the set_simple_fullscreen command without any pre-configured scope.","commands":{"allow":[],"deny":["set_simple_fullscreen"]}},"deny-set-size":{"identifier":"deny-set-size","description":"Denies the set_size command without any pre-configured scope.","commands":{"allow":[],"deny":["set_size"]}},"deny-set-size-constraints":{"identifier":"deny-set-size-constraints","description":"Denies the set_size_constraints command without any pre-configured scope.","commands":{"allow":[],"deny":["set_size_constraints"]}},"deny-set-skip-taskbar":{"identifier":"deny-set-skip-taskbar","description":"Denies the set_skip_taskbar command without any pre-configured scope.","commands":{"allow":[],"deny":["set_skip_taskbar"]}},"deny-set-theme":{"identifier":"deny-set-theme","description":"Denies the set_theme command without any pre-configured scope.","commands":{"allow":[],"deny":["set_theme"]}},"deny-set-title":{"identifier":"deny-set-title","description":"Denies the set_title command without any pre-configured scope.","commands":{"allow":[],"deny":["set_title"]}},"deny-set-title-bar-style":{"identifier":"deny-set-title-bar-style","description":"Denies the set_title_bar_style command without any pre-configured scope.","commands":{"allow":[],"deny":["set_title_bar_style"]}},"deny-set-visible-on-all-workspaces":{"identifier":"deny-set-visible-on-all-workspaces","description":"Denies the set_visible_on_all_workspaces command without any pre-configured scope.","commands":{"allow":[],"deny":["set_visible_on_all_workspaces"]}},"deny-show":{"identifier":"deny-show","description":"Denies the show command without any pre-configured scope.","commands":{"allow":[],"deny":["show"]}},"deny-start-dragging":{"identifier":"deny-start-dragging","description":"Denies the start_dragging command without any pre-configured scope.","commands":{"allow":[],"deny":["start_dragging"]}},"deny-start-resize-dragging":{"identifier":"deny-start-resize-dragging","description":"Denies the start_resize_dragging command without any pre-configured scope.","commands":{"allow":[],"deny":["start_resize_dragging"]}},"deny-theme":{"identifier":"deny-theme","description":"Denies the theme command without any pre-configured scope.","commands":{"allow":[],"deny":["theme"]}},"deny-title":{"identifier":"deny-title","description":"Denies the title command without any pre-configured scope.","commands":{"allow":[],"deny":["title"]}},"deny-toggle-maximize":{"identifier":"deny-toggle-maximize","description":"Denies the toggle_maximize command without any pre-configured scope.","commands":{"allow":[],"deny":["toggle_maximize"]}},"deny-unmaximize":{"identifier":"deny-unmaximize","description":"Denies the unmaximize command without any pre-configured scope.","commands":{"allow":[],"deny":["unmaximize"]}},"deny-unminimize":{"identifier":"deny-unminimize","description":"Denies the unminimize command without any pre-configured scope.","commands":{"allow":[],"deny":["unminimize"]}}},"permission_sets":{},"global_scope_schema":null},"dialog":{"default_permission":{"identifier":"default","description":"This permission set configures the types of dialogs\navailable from the dialog plugin.\n\n#### Granted Permissions\n\nAll dialog types are enabled.\n\n\n","permissions":["allow-ask","allow-confirm","allow-message","allow-save","allow-open"]},"permissions":{"allow-ask":{"identifier":"allow-ask","description":"Enables the ask command without any pre-configured scope.","commands":{"allow":["ask"],"deny":[]}},"allow-confirm":{"identifier":"allow-confirm","description":"Enables the confirm command without any pre-configured scope.","commands":{"allow":["confirm"],"deny":[]}},"allow-message":{"identifier":"allow-message","description":"Enables the message command without any pre-configured scope.","commands":{"allow":["message"],"deny":[]}},"allow-open":{"identifier":"allow-open","description":"Enables the open command without any pre-configured scope.","commands":{"allow":["open"],"deny":[]}},"allow-save":{"identifier":"allow-save","description":"Enables the save command without any pre-configured scope.","commands":{"allow":["save"],"deny":[]}},"deny-ask":{"identifier":"deny-ask","description":"Denies the ask command without any pre-configured scope.","commands":{"allow":[],"deny":["ask"]}},"deny-confirm":{"identifier":"deny-confirm","description":"Denies the confirm command without any pre-configured scope.","commands":{"allow":[],"deny":["confirm"]}},"deny-message":{"identifier":"deny-message","description":"Denies the message command without any pre-configured scope.","commands":{"allow":[],"deny":["message"]}},"deny-open":{"identifier":"deny-open","description":"Denies the open command without any pre-configured scope.","commands":{"allow":[],"deny":["open"]}},"deny-save":{"identifier":"deny-save","description":"Denies the save command without any pre-configured scope.","commands":{"allow":[],"deny":["save"]}}},"permission_sets":{},"global_scope_schema":null},"fs":{"default_permission":{"identifier":"default","description":"This set of permissions describes the what kind of\nfile system access the `fs` plugin has enabled or denied by default.\n\n#### Granted Permissions\n\nThis default permission set enables read access to the\napplication specific directories (AppConfig, AppData, AppLocalData, AppCache,\nAppLog) and all files and sub directories created in it.\nThe location of these directories depends on the operating system,\nwhere the application is run.\n\nIn general these directories need to be manually created\nby the application at runtime, before accessing files or folders\nin it is possible.\n\nTherefore, it is also allowed to create all of these folders via\nthe `mkdir` command.\n\n#### Denied Permissions\n\nThis default permission set prevents access to critical components\nof the Tauri application by default.\nOn Windows the webview data folder access is denied.\n","permissions":["create-app-specific-dirs","read-app-specific-dirs-recursive","deny-default"]},"permissions":{"allow-copy-file":{"identifier":"allow-copy-file","description":"Enables the copy_file command without any pre-configured scope.","commands":{"allow":["copy_file"],"deny":[]}},"allow-create":{"identifier":"allow-create","description":"Enables the create command without any pre-configured scope.","commands":{"allow":["create"],"deny":[]}},"allow-exists":{"identifier":"allow-exists","description":"Enables the exists command without any pre-configured scope.","commands":{"allow":["exists"],"deny":[]}},"allow-fstat":{"identifier":"allow-fstat","description":"Enables the fstat command without any pre-configured scope.","commands":{"allow":["fstat"],"deny":[]}},"allow-ftruncate":{"identifier":"allow-ftruncate","description":"Enables the ftruncate command without any pre-configured scope.","commands":{"allow":["ftruncate"],"deny":[]}},"allow-lstat":{"identifier":"allow-lstat","description":"Enables the lstat command without any pre-configured scope.","commands":{"allow":["lstat"],"deny":[]}},"allow-mkdir":{"identifier":"allow-mkdir","description":"Enables the mkdir command without any pre-configured scope.","commands":{"allow":["mkdir"],"deny":[]}},"allow-open":{"identifier":"allow-open","description":"Enables the open command without any pre-configured scope.","commands":{"allow":["open"],"deny":[]}},"allow-read":{"identifier":"allow-read","description":"Enables the read command without any pre-configured scope.","commands":{"allow":["read"],"deny":[]}},"allow-read-dir":{"identifier":"allow-read-dir","description":"Enables the read_dir command without any pre-configured scope.","commands":{"allow":["read_dir"],"deny":[]}},"allow-read-file":{"identifier":"allow-read-file","description":"Enables the read_file command without any pre-configured scope.","commands":{"allow":["read_file"],"deny":[]}},"allow-read-text-file":{"identifier":"allow-read-text-file","description":"Enables the read_text_file command without any pre-configured scope.","commands":{"allow":["read_text_file"],"deny":[]}},"allow-read-text-file-lines":{"identifier":"allow-read-text-file-lines","description":"Enables the read_text_file_lines command without any pre-configured scope.","commands":{"allow":["read_text_file_lines","read_text_file_lines_next"],"deny":[]}},"allow-read-text-file-lines-next":{"identifier":"allow-read-text-file-lines-next","description":"Enables the read_text_file_lines_next command without any pre-configured scope.","commands":{"allow":["read_text_file_lines_next"],"deny":[]}},"allow-remove":{"identifier":"allow-remove","description":"Enables the remove command without any pre-configured scope.","commands":{"allow":["remove"],"deny":[]}},"allow-rename":{"identifier":"allow-rename","description":"Enables the rename command without any pre-configured scope.","commands":{"allow":["rename"],"deny":[]}},"allow-seek":{"identifier":"allow-seek","description":"Enables the seek command without any pre-configured scope.","commands":{"allow":["seek"],"deny":[]}},"allow-size":{"identifier":"allow-size","description":"Enables the size command without any pre-configured scope.","commands":{"allow":["size"],"deny":[]}},"allow-stat":{"identifier":"allow-stat","description":"Enables the stat command without any pre-configured scope.","commands":{"allow":["stat"],"deny":[]}},"allow-truncate":{"identifier":"allow-truncate","description":"Enables the truncate command without any pre-configured scope.","commands":{"allow":["truncate"],"deny":[]}},"allow-unwatch":{"identifier":"allow-unwatch","description":"Enables the unwatch command without any pre-configured scope.","commands":{"allow":["unwatch"],"deny":[]}},"allow-watch":{"identifier":"allow-watch","description":"Enables the watch command without any pre-configured scope.","commands":{"allow":["watch"],"deny":[]}},"allow-write":{"identifier":"allow-write","description":"Enables the write command without any pre-configured scope.","commands":{"allow":["write"],"deny":[]}},"allow-write-file":{"identifier":"allow-write-file","description":"Enables the write_file command without any pre-configured scope.","commands":{"allow":["write_file","open","write"],"deny":[]}},"allow-write-text-file":{"identifier":"allow-write-text-file","description":"Enables the write_text_file command without any pre-configured scope.","commands":{"allow":["write_text_file"],"deny":[]}},"create-app-specific-dirs":{"identifier":"create-app-specific-dirs","description":"This permissions allows to create the application specific directories.\n","commands":{"allow":["mkdir","scope-app-index"],"deny":[]}},"deny-copy-file":{"identifier":"deny-copy-file","description":"Denies the copy_file command without any pre-configured scope.","commands":{"allow":[],"deny":["copy_file"]}},"deny-create":{"identifier":"deny-create","description":"Denies the create command without any pre-configured scope.","commands":{"allow":[],"deny":["create"]}},"deny-exists":{"identifier":"deny-exists","description":"Denies the exists command without any pre-configured scope.","commands":{"allow":[],"deny":["exists"]}},"deny-fstat":{"identifier":"deny-fstat","description":"Denies the fstat command without any pre-configured scope.","commands":{"allow":[],"deny":["fstat"]}},"deny-ftruncate":{"identifier":"deny-ftruncate","description":"Denies the ftruncate command without any pre-configured scope.","commands":{"allow":[],"deny":["ftruncate"]}},"deny-lstat":{"identifier":"deny-lstat","description":"Denies the lstat command without any pre-configured scope.","commands":{"allow":[],"deny":["lstat"]}},"deny-mkdir":{"identifier":"deny-mkdir","description":"Denies the mkdir command without any pre-configured scope.","commands":{"allow":[],"deny":["mkdir"]}},"deny-open":{"identifier":"deny-open","description":"Denies the open command without any pre-configured scope.","commands":{"allow":[],"deny":["open"]}},"deny-read":{"identifier":"deny-read","description":"Denies the read command without any pre-configured scope.","commands":{"allow":[],"deny":["read"]}},"deny-read-dir":{"identifier":"deny-read-dir","description":"Denies the read_dir command without any pre-configured scope.","commands":{"allow":[],"deny":["read_dir"]}},"deny-read-file":{"identifier":"deny-read-file","description":"Denies the read_file command without any pre-configured scope.","commands":{"allow":[],"deny":["read_file"]}},"deny-read-text-file":{"identifier":"deny-read-text-file","description":"Denies the read_text_file command without any pre-configured scope.","commands":{"allow":[],"deny":["read_text_file"]}},"deny-read-text-file-lines":{"identifier":"deny-read-text-file-lines","description":"Denies the read_text_file_lines command without any pre-configured scope.","commands":{"allow":[],"deny":["read_text_file_lines"]}},"deny-read-text-file-lines-next":{"identifier":"deny-read-text-file-lines-next","description":"Denies the read_text_file_lines_next command without any pre-configured scope.","commands":{"allow":[],"deny":["read_text_file_lines_next"]}},"deny-remove":{"identifier":"deny-remove","description":"Denies the remove command without any pre-configured scope.","commands":{"allow":[],"deny":["remove"]}},"deny-rename":{"identifier":"deny-rename","description":"Denies the rename command without any pre-configured scope.","commands":{"allow":[],"deny":["rename"]}},"deny-seek":{"identifier":"deny-seek","description":"Denies the seek command without any pre-configured scope.","commands":{"allow":[],"deny":["seek"]}},"deny-size":{"identifier":"deny-size","description":"Denies the size command without any pre-configured scope.","commands":{"allow":[],"deny":["size"]}},"deny-stat":{"identifier":"deny-stat","description":"Denies the stat command without any pre-configured scope.","commands":{"allow":[],"deny":["stat"]}},"deny-truncate":{"identifier":"deny-truncate","description":"Denies the truncate command without any pre-configured scope.","commands":{"allow":[],"deny":["truncate"]}},"deny-unwatch":{"identifier":"deny-unwatch","description":"Denies the unwatch command without any pre-configured scope.","commands":{"allow":[],"deny":["unwatch"]}},"deny-watch":{"identifier":"deny-watch","description":"Denies the watch command without any pre-configured scope.","commands":{"allow":[],"deny":["watch"]}},"deny-webview-data-linux":{"identifier":"deny-webview-data-linux","description":"This denies read access to the\n`$APPLOCALDATA` folder on linux as the webview data and configuration values are stored here.\nAllowing access can lead to sensitive information disclosure and should be well considered.","commands":{"allow":[],"deny":[]}},"deny-webview-data-windows":{"identifier":"deny-webview-data-windows","description":"This denies read access to the\n`$APPLOCALDATA/EBWebView` folder on windows as the webview data and configuration values are stored here.\nAllowing access can lead to sensitive information disclosure and should be well considered.","commands":{"allow":[],"deny":[]}},"deny-write":{"identifier":"deny-write","description":"Denies the write command without any pre-configured scope.","commands":{"allow":[],"deny":["write"]}},"deny-write-file":{"identifier":"deny-write-file","description":"Denies the write_file command without any pre-configured scope.","commands":{"allow":[],"deny":["write_file"]}},"deny-write-text-file":{"identifier":"deny-write-text-file","description":"Denies the write_text_file command without any pre-configured scope.","commands":{"allow":[],"deny":["write_text_file"]}},"read-all":{"identifier":"read-all","description":"This enables all read related commands without any pre-configured accessible paths.","commands":{"allow":["read_dir","read_file","read","open","read_text_file","read_text_file_lines","read_text_file_lines_next","seek","stat","lstat","fstat","exists","watch","unwatch"],"deny":[]}},"read-app-specific-dirs-recursive":{"identifier":"read-app-specific-dirs-recursive","description":"This permission allows recursive read functionality on the application\nspecific base directories. \n","commands":{"allow":["read_dir","read_file","read_text_file","read_text_file_lines","read_text_file_lines_next","exists","scope-app-recursive"],"deny":[]}},"read-dirs":{"identifier":"read-dirs","description":"This enables directory read and file metadata related commands without any pre-configured accessible paths.","commands":{"allow":["read_dir","stat","lstat","fstat","exists"],"deny":[]}},"read-files":{"identifier":"read-files","description":"This enables file read related commands without any pre-configured accessible paths.","commands":{"allow":["read_file","read","open","read_text_file","read_text_file_lines","read_text_file_lines_next","seek","stat","lstat","fstat","exists"],"deny":[]}},"read-meta":{"identifier":"read-meta","description":"This enables all index or metadata related commands without any pre-configured accessible paths.","commands":{"allow":["read_dir","stat","lstat","fstat","exists","size"],"deny":[]}},"scope":{"identifier":"scope","description":"An empty permission you can use to modify the global scope.\n\n## Example\n\n```json\n{\n  \"identifier\": \"read-documents\",\n  \"windows\": [\"main\"],\n  \"permissions\": [\n    \"fs:allow-read\",\n    {\n      \"identifier\": \"fs:scope\",\n      \"allow\": [\n        \"$APPDATA/documents/**/*\"\n      ],\n      \"deny\": [\n        \"$APPDATA/documents/secret.txt\"\n      ]\n    }\n  ]\n}\n```\n","commands":{"allow":[],"deny":[]}},"scope-app":{"identifier":"scope-app","description":"This scope permits access to all files and list content of top level directories in the application folders.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPCONFIG"},{"path":"$APPCONFIG/*"},{"path":"$APPDATA"},{"path":"$APPDATA/*"},{"path":"$APPLOCALDATA"},{"path":"$APPLOCALDATA/*"},{"path":"$APPCACHE"},{"path":"$APPCACHE/*"},{"path":"$APPLOG"},{"path":"$APPLOG/*"}]}},"scope-app-index":{"identifier":"scope-app-index","description":"This scope permits to list all files and folders in the application directories.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPCONFIG"},{"path":"$APPDATA"},{"path":"$APPLOCALDATA"},{"path":"$APPCACHE"},{"path":"$APPLOG"}]}},"scope-app-recursive":{"identifier":"scope-app-recursive","description":"This scope permits recursive access to the complete application folders, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPCONFIG"},{"path":"$APPCONFIG/**"},{"path":"$APPDATA"},{"path":"$APPDATA/**"},{"path":"$APPLOCALDATA"},{"path":"$APPLOCALDATA/**"},{"path":"$APPCACHE"},{"path":"$APPCACHE/**"},{"path":"$APPLOG"},{"path":"$APPLOG/**"}]}},"scope-appcache":{"identifier":"scope-appcache","description":"This scope permits access to all files and list content of top level directories in the `$APPCACHE` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPCACHE"},{"path":"$APPCACHE/*"}]}},"scope-appcache-index":{"identifier":"scope-appcache-index","description":"This scope permits to list all files and folders in the `$APPCACHE`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPCACHE"}]}},"scope-appcache-recursive":{"identifier":"scope-appcache-recursive","description":"This scope permits recursive access to the complete `$APPCACHE` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPCACHE"},{"path":"$APPCACHE/**"}]}},"scope-appconfig":{"identifier":"scope-appconfig","description":"This scope permits access to all files and list content of top level directories in the `$APPCONFIG` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPCONFIG"},{"path":"$APPCONFIG/*"}]}},"scope-appconfig-index":{"identifier":"scope-appconfig-index","description":"This scope permits to list all files and folders in the `$APPCONFIG`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPCONFIG"}]}},"scope-appconfig-recursive":{"identifier":"scope-appconfig-recursive","description":"This scope permits recursive access to the complete `$APPCONFIG` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPCONFIG"},{"path":"$APPCONFIG/**"}]}},"scope-appdata":{"identifier":"scope-appdata","description":"This scope permits access to all files and list content of top level directories in the `$APPDATA` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPDATA"},{"path":"$APPDATA/*"}]}},"scope-appdata-index":{"identifier":"scope-appdata-index","description":"This scope permits to list all files and folders in the `$APPDATA`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPDATA"}]}},"scope-appdata-recursive":{"identifier":"scope-appdata-recursive","description":"This scope permits recursive access to the complete `$APPDATA` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPDATA"},{"path":"$APPDATA/**"}]}},"scope-applocaldata":{"identifier":"scope-applocaldata","description":"This scope permits access to all files and list content of top level directories in the `$APPLOCALDATA` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPLOCALDATA"},{"path":"$APPLOCALDATA/*"}]}},"scope-applocaldata-index":{"identifier":"scope-applocaldata-index","description":"This scope permits to list all files and folders in the `$APPLOCALDATA`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPLOCALDATA"}]}},"scope-applocaldata-recursive":{"identifier":"scope-applocaldata-recursive","description":"This scope permits recursive access to the complete `$APPLOCALDATA` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPLOCALDATA"},{"path":"$APPLOCALDATA/**"}]}},"scope-applog":{"identifier":"scope-applog","description":"This scope permits access to all files and list content of top level directories in the `$APPLOG` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPLOG"},{"path":"$APPLOG/*"}]}},"scope-applog-index":{"identifier":"scope-applog-index","description":"This scope permits to list all files and folders in the `$APPLOG`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPLOG"}]}},"scope-applog-recursive":{"identifier":"scope-applog-recursive","description":"This scope permits recursive access to the complete `$APPLOG` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$APPLOG"},{"path":"$APPLOG/**"}]}},"scope-audio":{"identifier":"scope-audio","description":"This scope permits access to all files and list content of top level directories in the `$AUDIO` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$AUDIO"},{"path":"$AUDIO/*"}]}},"scope-audio-index":{"identifier":"scope-audio-index","description":"This scope permits to list all files and folders in the `$AUDIO`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$AUDIO"}]}},"scope-audio-recursive":{"identifier":"scope-audio-recursive","description":"This scope permits recursive access to the complete `$AUDIO` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$AUDIO"},{"path":"$AUDIO/**"}]}},"scope-cache":{"identifier":"scope-cache","description":"This scope permits access to all files and list content of top level directories in the `$CACHE` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$CACHE"},{"path":"$CACHE/*"}]}},"scope-cache-index":{"identifier":"scope-cache-index","description":"This scope permits to list all files and folders in the `$CACHE`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$CACHE"}]}},"scope-cache-recursive":{"identifier":"scope-cache-recursive","description":"This scope permits recursive access to the complete `$CACHE` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$CACHE"},{"path":"$CACHE/**"}]}},"scope-config":{"identifier":"scope-config","description":"This scope permits access to all files and list content of top level directories in the `$CONFIG` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$CONFIG"},{"path":"$CONFIG/*"}]}},"scope-config-index":{"identifier":"scope-config-index","description":"This scope permits to list all files and folders in the `$CONFIG`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$CONFIG"}]}},"scope-config-recursive":{"identifier":"scope-config-recursive","description":"This scope permits recursive access to the complete `$CONFIG` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$CONFIG"},{"path":"$CONFIG/**"}]}},"scope-data":{"identifier":"scope-data","description":"This scope permits access to all files and list content of top level directories in the `$DATA` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DATA"},{"path":"$DATA/*"}]}},"scope-data-index":{"identifier":"scope-data-index","description":"This scope permits to list all files and folders in the `$DATA`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DATA"}]}},"scope-data-recursive":{"identifier":"scope-data-recursive","description":"This scope permits recursive access to the complete `$DATA` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DATA"},{"path":"$DATA/**"}]}},"scope-desktop":{"identifier":"scope-desktop","description":"This scope permits access to all files and list content of top level directories in the `$DESKTOP` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DESKTOP"},{"path":"$DESKTOP/*"}]}},"scope-desktop-index":{"identifier":"scope-desktop-index","description":"This scope permits to list all files and folders in the `$DESKTOP`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DESKTOP"}]}},"scope-desktop-recursive":{"identifier":"scope-desktop-recursive","description":"This scope permits recursive access to the complete `$DESKTOP` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DESKTOP"},{"path":"$DESKTOP/**"}]}},"scope-document":{"identifier":"scope-document","description":"This scope permits access to all files and list content of top level directories in the `$DOCUMENT` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DOCUMENT"},{"path":"$DOCUMENT/*"}]}},"scope-document-index":{"identifier":"scope-document-index","description":"This scope permits to list all files and folders in the `$DOCUMENT`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DOCUMENT"}]}},"scope-document-recursive":{"identifier":"scope-document-recursive","description":"This scope permits recursive access to the complete `$DOCUMENT` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DOCUMENT"},{"path":"$DOCUMENT/**"}]}},"scope-download":{"identifier":"scope-download","description":"This scope permits access to all files and list content of top level directories in the `$DOWNLOAD` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DOWNLOAD"},{"path":"$DOWNLOAD/*"}]}},"scope-download-index":{"identifier":"scope-download-index","description":"This scope permits to list all files and folders in the `$DOWNLOAD`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DOWNLOAD"}]}},"scope-download-recursive":{"identifier":"scope-download-recursive","description":"This scope permits recursive access to the complete `$DOWNLOAD` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$DOWNLOAD"},{"path":"$DOWNLOAD/**"}]}},"scope-exe":{"identifier":"scope-exe","description":"This scope permits access to all files and list content of top level directories in the `$EXE` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$EXE"},{"path":"$EXE/*"}]}},"scope-exe-index":{"identifier":"scope-exe-index","description":"This scope permits to list all files and folders in the `$EXE`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$EXE"}]}},"scope-exe-recursive":{"identifier":"scope-exe-recursive","description":"This scope permits recursive access to the complete `$EXE` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$EXE"},{"path":"$EXE/**"}]}},"scope-font":{"identifier":"scope-font","description":"This scope permits access to all files and list content of top level directories in the `$FONT` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$FONT"},{"path":"$FONT/*"}]}},"scope-font-index":{"identifier":"scope-font-index","description":"This scope permits to list all files and folders in the `$FONT`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$FONT"}]}},"scope-font-recursive":{"identifier":"scope-font-recursive","description":"This scope permits recursive access to the complete `$FONT` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$FONT"},{"path":"$FONT/**"}]}},"scope-home":{"identifier":"scope-home","description":"This scope permits access to all files and list content of top level directories in the `$HOME` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$HOME"},{"path":"$HOME/*"}]}},"scope-home-index":{"identifier":"scope-home-index","description":"This scope permits to list all files and folders in the `$HOME`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$HOME"}]}},"scope-home-recursive":{"identifier":"scope-home-recursive","description":"This scope permits recursive access to the complete `$HOME` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$HOME"},{"path":"$HOME/**"}]}},"scope-localdata":{"identifier":"scope-localdata","description":"This scope permits access to all files and list content of top level directories in the `$LOCALDATA` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$LOCALDATA"},{"path":"$LOCALDATA/*"}]}},"scope-localdata-index":{"identifier":"scope-localdata-index","description":"This scope permits to list all files and folders in the `$LOCALDATA`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$LOCALDATA"}]}},"scope-localdata-recursive":{"identifier":"scope-localdata-recursive","description":"This scope permits recursive access to the complete `$LOCALDATA` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$LOCALDATA"},{"path":"$LOCALDATA/**"}]}},"scope-log":{"identifier":"scope-log","description":"This scope permits access to all files and list content of top level directories in the `$LOG` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$LOG"},{"path":"$LOG/*"}]}},"scope-log-index":{"identifier":"scope-log-index","description":"This scope permits to list all files and folders in the `$LOG`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$LOG"}]}},"scope-log-recursive":{"identifier":"scope-log-recursive","description":"This scope permits recursive access to the complete `$LOG` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$LOG"},{"path":"$LOG/**"}]}},"scope-picture":{"identifier":"scope-picture","description":"This scope permits access to all files and list content of top level directories in the `$PICTURE` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$PICTURE"},{"path":"$PICTURE/*"}]}},"scope-picture-index":{"identifier":"scope-picture-index","description":"This scope permits to list all files and folders in the `$PICTURE`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$PICTURE"}]}},"scope-picture-recursive":{"identifier":"scope-picture-recursive","description":"This scope permits recursive access to the complete `$PICTURE` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$PICTURE"},{"path":"$PICTURE/**"}]}},"scope-public":{"identifier":"scope-public","description":"This scope permits access to all files and list content of top level directories in the `$PUBLIC` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$PUBLIC"},{"path":"$PUBLIC/*"}]}},"scope-public-index":{"identifier":"scope-public-index","description":"This scope permits to list all files and folders in the `$PUBLIC`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$PUBLIC"}]}},"scope-public-recursive":{"identifier":"scope-public-recursive","description":"This scope permits recursive access to the complete `$PUBLIC` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$PUBLIC"},{"path":"$PUBLIC/**"}]}},"scope-resource":{"identifier":"scope-resource","description":"This scope permits access to all files and list content of top level directories in the `$RESOURCE` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$RESOURCE"},{"path":"$RESOURCE/*"}]}},"scope-resource-index":{"identifier":"scope-resource-index","description":"This scope permits to list all files and folders in the `$RESOURCE`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$RESOURCE"}]}},"scope-resource-recursive":{"identifier":"scope-resource-recursive","description":"This scope permits recursive access to the complete `$RESOURCE` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$RESOURCE"},{"path":"$RESOURCE/**"}]}},"scope-runtime":{"identifier":"scope-runtime","description":"This scope permits access to all files and list content of top level directories in the `$RUNTIME` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$RUNTIME"},{"path":"$RUNTIME/*"}]}},"scope-runtime-index":{"identifier":"scope-runtime-index","description":"This scope permits to list all files and folders in the `$RUNTIME`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$RUNTIME"}]}},"scope-runtime-recursive":{"identifier":"scope-runtime-recursive","description":"This scope permits recursive access to the complete `$RUNTIME` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$RUNTIME"},{"path":"$RUNTIME/**"}]}},"scope-temp":{"identifier":"scope-temp","description":"This scope permits access to all files and list content of top level directories in the `$TEMP` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$TEMP"},{"path":"$TEMP/*"}]}},"scope-temp-index":{"identifier":"scope-temp-index","description":"This scope permits to list all files and folders in the `$TEMP`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$TEMP"}]}},"scope-temp-recursive":{"identifier":"scope-temp-recursive","description":"This scope permits recursive access to the complete `$TEMP` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$TEMP"},{"path":"$TEMP/**"}]}},"scope-template":{"identifier":"scope-template","description":"This scope permits access to all files and list content of top level directories in the `$TEMPLATE` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$TEMPLATE"},{"path":"$TEMPLATE/*"}]}},"scope-template-index":{"identifier":"scope-template-index","description":"This scope permits to list all files and folders in the `$TEMPLATE`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$TEMPLATE"}]}},"scope-template-recursive":{"identifier":"scope-template-recursive","description":"This scope permits recursive access to the complete `$TEMPLATE` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$TEMPLATE"},{"path":"$TEMPLATE/**"}]}},"scope-video":{"identifier":"scope-video","description":"This scope permits access to all files and list content of top level directories in the `$VIDEO` folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$VIDEO"},{"path":"$VIDEO/*"}]}},"scope-video-index":{"identifier":"scope-video-index","description":"This scope permits to list all files and folders in the `$VIDEO`folder.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$VIDEO"}]}},"scope-video-recursive":{"identifier":"scope-video-recursive","description":"This scope permits recursive access to the complete `$VIDEO` folder, including sub directories and files.","commands":{"allow":[],"deny":[]},"scope":{"allow":[{"path":"$VIDEO"},{"path":"$VIDEO/**"}]}},"write-all":{"identifier":"write-all","description":"This enables all write related commands without any pre-configured accessible paths.","commands":{"allow":["mkdir","create","copy_file","remove","rename","truncate","ftruncate","write","write_file","write_text_file"],"deny":[]}},"write-files":{"identifier":"write-files","description":"This enables all file write related commands without any pre-configured accessible paths.","commands":{"allow":["create","copy_file","remove","rename","truncate","ftruncate","write","write_file","write_text_file"],"deny":[]}}},"permission_sets":{"allow-app-meta":{"identifier":"allow-app-meta","description":"This allows non-recursive read access to metadata of the application folders, including file listing and statistics.","permissions":["read-meta","scope-app-index"]},"allow-app-meta-recursive":{"identifier":"allow-app-meta-recursive","description":"This allows full recursive read access to metadata of the application folders, including file listing and statistics.","permissions":["read-meta","scope-app-recursive"]},"allow-app-read":{"identifier":"allow-app-read","description":"This allows non-recursive read access to the application folders.","permissions":["read-all","scope-app"]},"allow-app-read-recursive":{"identifier":"allow-app-read-recursive","description":"This allows full recursive read access to the complete application folders, files and subdirectories.","permissions":["read-all","scope-app-recursive"]},"allow-app-write":{"identifier":"allow-app-write","description":"This allows non-recursive write access to the application folders.","permissions":["write-all","scope-app"]},"allow-app-write-recursive":{"identifier":"allow-app-write-recursive","description":"This allows full recursive write access to the complete application folders, files and subdirectories.","permissions":["write-all","scope-app-recursive"]},"allow-appcache-meta":{"identifier":"allow-appcache-meta","description":"This allows non-recursive read access to metadata of the `$APPCACHE` folder, including file listing and statistics.","permissions":["read-meta","scope-appcache-index"]},"allow-appcache-meta-recursive":{"identifier":"allow-appcache-meta-recursive","description":"This allows full recursive read access to metadata of the `$APPCACHE` folder, including file listing and statistics.","permissions":["read-meta","scope-appcache-recursive"]},"allow-appcache-read":{"identifier":"allow-appcache-read","description":"This allows non-recursive read access to the `$APPCACHE` folder.","permissions":["read-all","scope-appcache"]},"allow-appcache-read-recursive":{"identifier":"allow-appcache-read-recursive","description":"This allows full recursive read access to the complete `$APPCACHE` folder, files and subdirectories.","permissions":["read-all","scope-appcache-recursive"]},"allow-appcache-write":{"identifier":"allow-appcache-write","description":"This allows non-recursive write access to the `$APPCACHE` folder.","permissions":["write-all","scope-appcache"]},"allow-appcache-write-recursive":{"identifier":"allow-appcache-write-recursive","description":"This allows full recursive write access to the complete `$APPCACHE` folder, files and subdirectories.","permissions":["write-all","scope-appcache-recursive"]},"allow-appconfig-meta":{"identifier":"allow-appconfig-meta","description":"This allows non-recursive read access to metadata of the `$APPCONFIG` folder, including file listing and statistics.","permissions":["read-meta","scope-appconfig-index"]},"allow-appconfig-meta-recursive":{"identifier":"allow-appconfig-meta-recursive","description":"This allows full recursive read access to metadata of the `$APPCONFIG` folder, including file listing and statistics.","permissions":["read-meta","scope-appconfig-recursive"]},"allow-appconfig-read":{"identifier":"allow-appconfig-read","description":"This allows non-recursive read access to the `$APPCONFIG` folder.","permissions":["read-all","scope-appconfig"]},"allow-appconfig-read-recursive":{"identifier":"allow-appconfig-read-recursive","description":"This allows full recursive read access to the complete `$APPCONFIG` folder, files and subdirectories.","permissions":["read-all","scope-appconfig-recursive"]},"allow-appconfig-write":{"identifier":"allow-appconfig-write","description":"This allows non-recursive write access to the `$APPCONFIG` folder.","permissions":["write-all","scope-appconfig"]},"allow-appconfig-write-recursive":{"identifier":"allow-appconfig-write-recursive","description":"This allows full recursive write access to the complete `$APPCONFIG` folder, files and subdirectories.","permissions":["write-all","scope-appconfig-recursive"]},"allow-appdata-meta":{"identifier":"allow-appdata-meta","description":"This allows non-recursive read access to metadata of the `$APPDATA` folder, including file listing and statistics.","permissions":["read-meta","scope-appdata-index"]},"allow-appdata-meta-recursive":{"identifier":"allow-appdata-meta-recursive","description":"This allows full recursive read access to metadata of the `$APPDATA` folder, including file listing and statistics.","permissions":["read-meta","scope-appdata-recursive"]},"allow-appdata-read":{"identifier":"allow-appdata-read","description":"This allows non-recursive read access to the `$APPDATA` folder.","permissions":["read-all","scope-appdata"]},"allow-appdata-read-recursive":{"identifier":"allow-appdata-read-recursive","description":"This allows full recursive read access to the complete `$APPDATA` folder, files and subdirectories.","permissions":["read-all","scope-appdata-recursive"]},"allow-appdata-write":{"identifier":"allow-appdata-write","description":"This allows non-recursive write access to the `$APPDATA` folder.","permissions":["write-all","scope-appdata"]},"allow-appdata-write-recursive":{"identifier":"allow-appdata-write-recursive","description":"This allows full recursive write access to the complete `$APPDATA` folder, files and subdirectories.","permissions":["write-all","scope-appdata-recursive"]},"allow-applocaldata-meta":{"identifier":"allow-applocaldata-meta","description":"This allows non-recursive read access to metadata of the `$APPLOCALDATA` folder, including file listing and statistics.","permissions":["read-meta","scope-applocaldata-index"]},"allow-applocaldata-meta-recursive":{"identifier":"allow-applocaldata-meta-recursive","description":"This allows full recursive read access to metadata of the `$APPLOCALDATA` folder, including file listing and statistics.","permissions":["read-meta","scope-applocaldata-recursive"]},"allow-applocaldata-read":{"identifier":"allow-applocaldata-read","description":"This allows non-recursive read access to the `$APPLOCALDATA` folder.","permissions":["read-all","scope-applocaldata"]},"allow-applocaldata-read-recursive":{"identifier":"allow-applocaldata-read-recursive","description":"This allows full recursive read access to the complete `$APPLOCALDATA` folder, files and subdirectories.","permissions":["read-all","scope-applocaldata-recursive"]},"allow-applocaldata-write":{"identifier":"allow-applocaldata-write","description":"This allows non-recursive write access to the `$APPLOCALDATA` folder.","permissions":["write-all","scope-applocaldata"]},"allow-applocaldata-write-recursive":{"identifier":"allow-applocaldata-write-recursive","description":"This allows full recursive write access to the complete `$APPLOCALDATA` folder, files and subdirectories.","permissions":["write-all","scope-applocaldata-recursive"]},"allow-applog-meta":{"identifier":"allow-applog-meta","description":"This allows non-recursive read access to metadata of the `$APPLOG` folder, including file listing and statistics.","permissions":["read-meta","scope-applog-index"]},"allow-applog-meta-recursive":{"identifier":"allow-applog-meta-recursive","description":"This allows full recursive read access to metadata of the `$APPLOG` folder, including file listing and statistics.","permissions":["read-meta","scope-applog-recursive"]},"allow-applog-read":{"identifier":"allow-applog-read","description":"This allows non-recursive read access to the `$APPLOG` folder.","permissions":["read-all","scope-applog"]},"allow-applog-read-recursive":{"identifier":"allow-applog-read-recursive","description":"This allows full recursive read access to the complete `$APPLOG` folder, files and subdirectories.","permissions":["read-all","scope-applog-recursive"]},"allow-applog-write":{"identifier":"allow-applog-write","description":"This allows non-recursive write access to the `$APPLOG` folder.","permissions":["write-all","scope-applog"]},"allow-applog-write-recursive":{"identifier":"allow-applog-write-recursive","description":"This allows full recursive write access to the complete `$APPLOG` folder, files and subdirectories.","permissions":["write-all","scope-applog-recursive"]},"allow-audio-meta":{"identifier":"allow-audio-meta","description":"This allows non-recursive read access to metadata of the `$AUDIO` folder, including file listing and statistics.","permissions":["read-meta","scope-audio-index"]},"allow-audio-meta-recursive":{"identifier":"allow-audio-meta-recursive","description":"This allows full recursive read access to metadata of the `$AUDIO` folder, including file listing and statistics.","permissions":["read-meta","scope-audio-recursive"]},"allow-audio-read":{"identifier":"allow-audio-read","description":"This allows non-recursive read access to the `$AUDIO` folder.","permissions":["read-all","scope-audio"]},"allow-audio-read-recursive":{"identifier":"allow-audio-read-recursive","description":"This allows full recursive read access to the complete `$AUDIO` folder, files and subdirectories.","permissions":["read-all","scope-audio-recursive"]},"allow-audio-write":{"identifier":"allow-audio-write","description":"This allows non-recursive write access to the `$AUDIO` folder.","permissions":["write-all","scope-audio"]},"allow-audio-write-recursive":{"identifier":"allow-audio-write-recursive","description":"This allows full recursive write access to the complete `$AUDIO` folder, files and subdirectories.","permissions":["write-all","scope-audio-recursive"]},"allow-cache-meta":{"identifier":"allow-cache-meta","description":"This allows non-recursive read access to metadata of the `$CACHE` folder, including file listing and statistics.","permissions":["read-meta","scope-cache-index"]},"allow-cache-meta-recursive":{"identifier":"allow-cache-meta-recursive","description":"This allows full recursive read access to metadata of the `$CACHE` folder, including file listing and statistics.","permissions":["read-meta","scope-cache-recursive"]},"allow-cache-read":{"identifier":"allow-cache-read","description":"This allows non-recursive read access to the `$CACHE` folder.","permissions":["read-all","scope-cache"]},"allow-cache-read-recursive":{"identifier":"allow-cache-read-recursive","description":"This allows full recursive read access to the complete `$CACHE` folder, files and subdirectories.","permissions":["read-all","scope-cache-recursive"]},"allow-cache-write":{"identifier":"allow-cache-write","description":"This allows non-recursive write access to the `$CACHE` folder.","permissions":["write-all","scope-cache"]},"allow-cache-write-recursive":{"identifier":"allow-cache-write-recursive","description":"This allows full recursive write access to the complete `$CACHE` folder, files and subdirectories.","permissions":["write-all","scope-cache-recursive"]},"allow-config-meta":{"identifier":"allow-config-meta","description":"This allows non-recursive read access to metadata of the `$CONFIG` folder, including file listing and statistics.","permissions":["read-meta","scope-config-index"]},"allow-config-meta-recursive":{"identifier":"allow-config-meta-recursive","description":"This allows full recursive read access to metadata of the `$CONFIG` folder, including file listing and statistics.","permissions":["read-meta","scope-config-recursive"]},"allow-config-read":{"identifier":"allow-config-read","description":"This allows non-recursive read access to the `$CONFIG` folder.","permissions":["read-all","scope-config"]},"allow-config-read-recursive":{"identifier":"allow-config-read-recursive","description":"This allows full recursive read access to the complete `$CONFIG` folder, files and subdirectories.","permissions":["read-all","scope-config-recursive"]},"allow-config-write":{"identifier":"allow-config-write","description":"This allows non-recursive write access to the `$CONFIG` folder.","permissions":["write-all","scope-config"]},"allow-config-write-recursive":{"identifier":"allow-config-write-recursive","description":"This allows full recursive write access to the complete `$CONFIG` folder, files and subdirectories.","permissions":["write-all","scope-config-recursive"]},"allow-data-meta":{"identifier":"allow-data-meta","description":"This allows non-recursive read access to metadata of the `$DATA` folder, including file listing and statistics.","permissions":["read-meta","scope-data-index"]},"allow-data-meta-recursive":{"identifier":"allow-data-meta-recursive","description":"This allows full recursive read access to metadata of the `$DATA` folder, including file listing and statistics.","permissions":["read-meta","scope-data-recursive"]},"allow-data-read":{"identifier":"allow-data-read","description":"This allows non-recursive read access to the `$DATA` folder.","permissions":["read-all","scope-data"]},"allow-data-read-recursive":{"identifier":"allow-data-read-recursive","description":"This allows full recursive read access to the complete `$DATA` folder, files and subdirectories.","permissions":["read-all","scope-data-recursive"]},"allow-data-write":{"identifier":"allow-data-write","description":"This allows non-recursive write access to the `$DATA` folder.","permissions":["write-all","scope-data"]},"allow-data-write-recursive":{"identifier":"allow-data-write-recursive","description":"This allows full recursive write access to the complete `$DATA` folder, files and subdirectories.","permissions":["write-all","scope-data-recursive"]},"allow-desktop-meta":{"identifier":"allow-desktop-meta","description":"This allows non-recursive read access to metadata of the `$DESKTOP` folder, including file listing and statistics.","permissions":["read-meta","scope-desktop-index"]},"allow-desktop-meta-recursive":{"identifier":"allow-desktop-meta-recursive","description":"This allows full recursive read access to metadata of the `$DESKTOP` folder, including file listing and statistics.","permissions":["read-meta","scope-desktop-recursive"]},"allow-desktop-read":{"identifier":"allow-desktop-read","description":"This allows non-recursive read access to the `$DESKTOP` folder.","permissions":["read-all","scope-desktop"]},"allow-desktop-read-recursive":{"identifier":"allow-desktop-read-recursive","description":"This allows full recursive read access to the complete `$DESKTOP` folder, files and subdirectories.","permissions":["read-all","scope-desktop-recursive"]},"allow-desktop-write":{"identifier":"allow-desktop-write","description":"This allows non-recursive write access to the `$DESKTOP` folder.","permissions":["write-all","scope-desktop"]},"allow-desktop-write-recursive":{"identifier":"allow-desktop-write-recursive","description":"This allows full recursive write access to the complete `$DESKTOP` folder, files and subdirectories.","permissions":["write-all","scope-desktop-recursive"]},"allow-document-meta":{"identifier":"allow-document-meta","description":"This allows non-recursive read access to metadata of the `$DOCUMENT` folder, including file listing and statistics.","permissions":["read-meta","scope-document-index"]},"allow-document-meta-recursive":{"identifier":"allow-document-meta-recursive","description":"This allows full recursive read access to metadata of the `$DOCUMENT` folder, including file listing and statistics.","permissions":["read-meta","scope-document-recursive"]},"allow-document-read":{"identifier":"allow-document-read","description":"This allows non-recursive read access to the `$DOCUMENT` folder.","permissions":["read-all","scope-document"]},"allow-document-read-recursive":{"identifier":"allow-document-read-recursive","description":"This allows full recursive read access to the complete `$DOCUMENT` folder, files and subdirectories.","permissions":["read-all","scope-document-recursive"]},"allow-document-write":{"identifier":"allow-document-write","description":"This allows non-recursive write access to the `$DOCUMENT` folder.","permissions":["write-all","scope-document"]},"allow-document-write-recursive":{"identifier":"allow-document-write-recursive","description":"This allows full recursive write access to the complete `$DOCUMENT` folder, files and subdirectories.","permissions":["write-all","scope-document-recursive"]},"allow-download-meta":{"identifier":"allow-download-meta","description":"This allows non-recursive read access to metadata of the `$DOWNLOAD` folder, including file listing and statistics.","permissions":["read-meta","scope-download-index"]},"allow-download-meta-recursive":{"identifier":"allow-download-meta-recursive","description":"This allows full recursive read access to metadata of the `$DOWNLOAD` folder, including file listing and statistics.","permissions":["read-meta","scope-download-recursive"]},"allow-download-read":{"identifier":"allow-download-read","description":"This allows non-recursive read access to the `$DOWNLOAD` folder.","permissions":["read-all","scope-download"]},"allow-download-read-recursive":{"identifier":"allow-download-read-recursive","description":"This allows full recursive read access to the complete `$DOWNLOAD` folder, files and subdirectories.","permissions":["read-all","scope-download-recursive"]},"allow-download-write":{"identifier":"allow-download-write","description":"This allows non-recursive write access to the `$DOWNLOAD` folder.","permissions":["write-all","scope-download"]},"allow-download-write-recursive":{"identifier":"allow-download-write-recursive","description":"This allows full recursive write access to the complete `$DOWNLOAD` folder, files and subdirectories.","permissions":["write-all","scope-download-recursive"]},"allow-exe-meta":{"identifier":"allow-exe-meta","description":"This allows non-recursive read access to metadata of the `$EXE` folder, including file listing and statistics.","permissions":["read-meta","scope-exe-index"]},"allow-exe-meta-recursive":{"identifier":"allow-exe-meta-recursive","description":"This allows full recursive read access to metadata of the `$EXE` folder, including file listing and statistics.","permissions":["read-meta","scope-exe-recursive"]},"allow-exe-read":{"identifier":"allow-exe-read","description":"This allows non-recursive read access to the `$EXE` folder.","permissions":["read-all","scope-exe"]},"allow-exe-read-recursive":{"identifier":"allow-exe-read-recursive","description":"This allows full recursive read access to the complete `$EXE` folder, files and subdirectories.","permissions":["read-all","scope-exe-recursive"]},"allow-exe-write":{"identifier":"allow-exe-write","description":"This allows non-recursive write access to the `$EXE` folder.","permissions":["write-all","scope-exe"]},"allow-exe-write-recursive":{"identifier":"allow-exe-write-recursive","description":"This allows full recursive write access to the complete `$EXE` folder, files and subdirectories.","permissions":["write-all","scope-exe-recursive"]},"allow-font-meta":{"identifier":"allow-font-meta","description":"This allows non-recursive read access to metadata of the `$FONT` folder, including file listing and statistics.","permissions":["read-meta","scope-font-index"]},"allow-font-meta-recursive":{"identifier":"allow-font-meta-recursive","description":"This allows full recursive read access to metadata of the `$FONT` folder, including file listing and statistics.","permissions":["read-meta","scope-font-recursive"]},"allow-font-read":{"identifier":"allow-font-read","description":"This allows non-recursive read access to the `$FONT` folder.","permissions":["read-all","scope-font"]},"allow-font-read-recursive":{"identifier":"allow-font-read-recursive","description":"This allows full recursive read access to the complete `$FONT` folder, files and subdirectories.","permissions":["read-all","scope-font-recursive"]},"allow-font-write":{"identifier":"allow-font-write","description":"This allows non-recursive write access to the `$FONT` folder.","permissions":["write-all","scope-font"]},"allow-font-write-recursive":{"identifier":"allow-font-write-recursive","description":"This allows full recursive write access to the complete `$FONT` folder, files and subdirectories.","permissions":["write-all","scope-font-recursive"]},"allow-home-meta":{"identifier":"allow-home-meta","description":"This allows non-recursive read access to metadata of the `$HOME` folder, including file listing and statistics.","permissions":["read-meta","scope-home-index"]},"allow-home-meta-recursive":{"identifier":"allow-home-meta-recursive","description":"This allows full recursive read access to metadata of the `$HOME` folder, including file listing and statistics.","permissions":["read-meta","scope-home-recursive"]},"allow-home-read":{"identifier":"allow-home-read","description":"This allows non-recursive read access to the `$HOME` folder.","permissions":["read-all","scope-home"]},"allow-home-read-recursive":{"identifier":"allow-home-read-recursive","description":"This allows full recursive read access to the complete `$HOME` folder, files and subdirectories.","permissions":["read-all","scope-home-recursive"]},"allow-home-write":{"identifier":"allow-home-write","description":"This allows non-recursive write access to the `$HOME` folder.","permissions":["write-all","scope-home"]},"allow-home-write-recursive":{"identifier":"allow-home-write-recursive","description":"This allows full recursive write access to the complete `$HOME` folder, files and subdirectories.","permissions":["write-all","scope-home-recursive"]},"allow-localdata-meta":{"identifier":"allow-localdata-meta","description":"This allows non-recursive read access to metadata of the `$LOCALDATA` folder, including file listing and statistics.","permissions":["read-meta","scope-localdata-index"]},"allow-localdata-meta-recursive":{"identifier":"allow-localdata-meta-recursive","description":"This allows full recursive read access to metadata of the `$LOCALDATA` folder, including file listing and statistics.","permissions":["read-meta","scope-localdata-recursive"]},"allow-localdata-read":{"identifier":"allow-localdata-read","description":"This allows non-recursive read access to the `$LOCALDATA` folder.","permissions":["read-all","scope-localdata"]},"allow-localdata-read-recursive":{"identifier":"allow-localdata-read-recursive","description":"This allows full recursive read access to the complete `$LOCALDATA` folder, files and subdirectories.","permissions":["read-all","scope-localdata-recursive"]},"allow-localdata-write":{"identifier":"allow-localdata-write","description":"This allows non-recursive write access to the `$LOCALDATA` folder.","permissions":["write-all","scope-localdata"]},"allow-localdata-write-recursive":{"identifier":"allow-localdata-write-recursive","description":"This allows full recursive write access to the complete `$LOCALDATA` folder, files and subdirectories.","permissions":["write-all","scope-localdata-recursive"]},"allow-log-meta":{"identifier":"allow-log-meta","description":"This allows non-recursive read access to metadata of the `$LOG` folder, including file listing and statistics.","permissions":["read-meta","scope-log-index"]},"allow-log-meta-recursive":{"identifier":"allow-log-meta-recursive","description":"This allows full recursive read access to metadata of the `$LOG` folder, including file listing and statistics.","permissions":["read-meta","scope-log-recursive"]},"allow-log-read":{"identifier":"allow-log-read","description":"This allows non-recursive read access to the `$LOG` folder.","permissions":["read-all","scope-log"]},"allow-log-read-recursive":{"identifier":"allow-log-read-recursive","description":"This allows full recursive read access to the complete `$LOG` folder, files and subdirectories.","permissions":["read-all","scope-log-recursive"]},"allow-log-write":{"identifier":"allow-log-write","description":"This allows non-recursive write access to the `$LOG` folder.","permissions":["write-all","scope-log"]},"allow-log-write-recursive":{"identifier":"allow-log-write-recursive","description":"This allows full recursive write access to the complete `$LOG` folder, files and subdirectories.","permissions":["write-all","scope-log-recursive"]},"allow-picture-meta":{"identifier":"allow-picture-meta","description":"This allows non-recursive read access to metadata of the `$PICTURE` folder, including file listing and statistics.","permissions":["read-meta","scope-picture-index"]},"allow-picture-meta-recursive":{"identifier":"allow-picture-meta-recursive","description":"This allows full recursive read access to metadata of the `$PICTURE` folder, including file listing and statistics.","permissions":["read-meta","scope-picture-recursive"]},"allow-picture-read":{"identifier":"allow-picture-read","description":"This allows non-recursive read access to the `$PICTURE` folder.","permissions":["read-all","scope-picture"]},"allow-picture-read-recursive":{"identifier":"allow-picture-read-recursive","description":"This allows full recursive read access to the complete `$PICTURE` folder, files and subdirectories.","permissions":["read-all","scope-picture-recursive"]},"allow-picture-write":{"identifier":"allow-picture-write","description":"This allows non-recursive write access to the `$PICTURE` folder.","permissions":["write-all","scope-picture"]},"allow-picture-write-recursive":{"identifier":"allow-picture-write-recursive","description":"This allows full recursive write access to the complete `$PICTURE` folder, files and subdirectories.","permissions":["write-all","scope-picture-recursive"]},"allow-public-meta":{"identifier":"allow-public-meta","description":"This allows non-recursive read access to metadata of the `$PUBLIC` folder, including file listing and statistics.","permissions":["read-meta","scope-public-index"]},"allow-public-meta-recursive":{"identifier":"allow-public-meta-recursive","description":"This allows full recursive read access to metadata of the `$PUBLIC` folder, including file listing and statistics.","permissions":["read-meta","scope-public-recursive"]},"allow-public-read":{"identifier":"allow-public-read","description":"This allows non-recursive read access to the `$PUBLIC` folder.","permissions":["read-all","scope-public"]},"allow-public-read-recursive":{"identifier":"allow-public-read-recursive","description":"This allows full recursive read access to the complete `$PUBLIC` folder, files and subdirectories.","permissions":["read-all","scope-public-recursive"]},"allow-public-write":{"identifier":"allow-public-write","description":"This allows non-recursive write access to the `$PUBLIC` folder.","permissions":["write-all","scope-public"]},"allow-public-write-recursive":{"identifier":"allow-public-write-recursive","description":"This allows full recursive write access to the complete `$PUBLIC` folder, files and subdirectories.","permissions":["write-all","scope-public-recursive"]},"allow-resource-meta":{"identifier":"allow-resource-meta","description":"This allows non-recursive read access to metadata of the `$RESOURCE` folder, including file listing and statistics.","permissions":["read-meta","scope-resource-index"]},"allow-resource-meta-recursive":{"identifier":"allow-resource-meta-recursive","description":"This allows full recursive read access to metadata of the `$RESOURCE` folder, including file listing and statistics.","permissions":["read-meta","scope-resource-recursive"]},"allow-resource-read":{"identifier":"allow-resource-read","description":"This allows non-recursive read access to the `$RESOURCE` folder.","permissions":["read-all","scope-resource"]},"allow-resource-read-recursive":{"identifier":"allow-resource-read-recursive","description":"This allows full recursive read access to the complete `$RESOURCE` folder, files and subdirectories.","permissions":["read-all","scope-resource-recursive"]},"allow-resource-write":{"identifier":"allow-resource-write","description":"This allows non-recursive write access to the `$RESOURCE` folder.","permissions":["write-all","scope-resource"]},"allow-resource-write-recursive":{"identifier":"allow-resource-write-recursive","description":"This allows full recursive write access to the complete `$RESOURCE` folder, files and subdirectories.","permissions":["write-all","scope-resource-recursive"]},"allow-runtime-meta":{"identifier":"allow-runtime-meta","description":"This allows non-recursive read access to metadata of the `$RUNTIME` folder, including file listing and statistics.","permissions":["read-meta","scope-runtime-index"]},"allow-runtime-meta-recursive":{"identifier":"allow-runtime-meta-recursive","description":"This allows full recursive read access to metadata of the `$RUNTIME` folder, including file listing and statistics.","permissions":["read-meta","scope-runtime-recursive"]},"allow-runtime-read":{"identifier":"allow-runtime-read","description":"This allows non-recursive read access to the `$RUNTIME` folder.","permissions":["read-all","scope-runtime"]},"allow-runtime-read-recursive":{"identifier":"allow-runtime-read-recursive","description":"This allows full recursive read access to the complete `$RUNTIME` folder, files and subdirectories.","permissions":["read-all","scope-runtime-recursive"]},"allow-runtime-write":{"identifier":"allow-runtime-write","description":"This allows non-recursive write access to the `$RUNTIME` folder.","permissions":["write-all","scope-runtime"]},"allow-runtime-write-recursive":{"identifier":"allow-runtime-write-recursive","description":"This allows full recursive write access to the complete `$RUNTIME` folder, files and subdirectories.","permissions":["write-all","scope-runtime-recursive"]},"allow-temp-meta":{"identifier":"allow-temp-meta","description":"This allows non-recursive read access to metadata of the `$TEMP` folder, including file listing and statistics.","permissions":["read-meta","scope-temp-index"]},"allow-temp-meta-recursive":{"identifier":"allow-temp-meta-recursive","description":"This allows full recursive read access to metadata of the `$TEMP` folder, including file listing and statistics.","permissions":["read-meta","scope-temp-recursive"]},"allow-temp-read":{"identifier":"allow-temp-read","description":"This allows non-recursive read access to the `$TEMP` folder.","permissions":["read-all","scope-temp"]},"allow-temp-read-recursive":{"identifier":"allow-temp-read-recursive","description":"This allows full recursive read access to the complete `$TEMP` folder, files and subdirectories.","permissions":["read-all","scope-temp-recursive"]},"allow-temp-write":{"identifier":"allow-temp-write","description":"This allows non-recursive write access to the `$TEMP` folder.","permissions":["write-all","scope-temp"]},"allow-temp-write-recursive":{"identifier":"allow-temp-write-recursive","description":"This allows full recursive write access to the complete `$TEMP` folder, files and subdirectories.","permissions":["write-all","scope-temp-recursive"]},"allow-template-meta":{"identifier":"allow-template-meta","description":"This allows non-recursive read access to metadata of the `$TEMPLATE` folder, including file listing and statistics.","permissions":["read-meta","scope-template-index"]},"allow-template-meta-recursive":{"identifier":"allow-template-meta-recursive","description":"This allows full recursive read access to metadata of the `$TEMPLATE` folder, including file listing and statistics.","permissions":["read-meta","scope-template-recursive"]},"allow-template-read":{"identifier":"allow-template-read","description":"This allows non-recursive read access to the `$TEMPLATE` folder.","permissions":["read-all","scope-template"]},"allow-template-read-recursive":{"identifier":"allow-template-read-recursive","description":"This allows full recursive read access to the complete `$TEMPLATE` folder, files and subdirectories.","permissions":["read-all","scope-template-recursive"]},"allow-template-write":{"identifier":"allow-template-write","description":"This allows non-recursive write access to the `$TEMPLATE` folder.","permissions":["write-all","scope-template"]},"allow-template-write-recursive":{"identifier":"allow-template-write-recursive","description":"This allows full recursive write access to the complete `$TEMPLATE` folder, files and subdirectories.","permissions":["write-all","scope-template-recursive"]},"allow-video-meta":{"identifier":"allow-video-meta","description":"This allows non-recursive read access to metadata of the `$VIDEO` folder, including file listing and statistics.","permissions":["read-meta","scope-video-index"]},"allow-video-meta-recursive":{"identifier":"allow-video-meta-recursive","description":"This allows full recursive read access to metadata of the `$VIDEO` folder, including file listing and statistics.","permissions":["read-meta","scope-video-recursive"]},"allow-video-read":{"identifier":"allow-video-read","description":"This allows non-recursive read access to the `$VIDEO` folder.","permissions":["read-all","scope-video"]},"allow-video-read-recursive":{"identifier":"allow-video-read-recursive","description":"This allows full recursive read access to the complete `$VIDEO` folder, files and subdirectories.","permissions":["read-all","scope-video-recursive"]},"allow-video-write":{"identifier":"allow-video-write","description":"This allows non-recursive write access to the `$VIDEO` folder.","permissions":["write-all","scope-video"]},"allow-video-write-recursive":{"identifier":"allow-video-write-recursive","description":"This allows full recursive write access to the complete `$VIDEO` folder, files and subdirectories.","permissions":["write-all","scope-video-recursive"]},"deny-default":{"identifier":"deny-default","description":"This denies access to dangerous Tauri relevant files and folders by default.","permissions":["deny-webview-data-linux","deny-webview-data-windows"]}},"global_scope_schema":{"$schema":"http://json-schema.org/draft-07/schema#","anyOf":[{"description":"A path that can be accessed by the webview when using the fs APIs. FS scope path pattern.\n\nThe pattern can start with a variable that resolves to a system base directory. The variables are: `$AUDIO`, `$CACHE`, `$CONFIG`, `$DATA`, `$LOCALDATA`, `$DESKTOP`, `$DOCUMENT`, `$DOWNLOAD`, `$EXE`, `$FONT`, `$HOME`, `$PICTURE`, `$PUBLIC`, `$RUNTIME`, `$TEMPLATE`, `$VIDEO`, `$RESOURCE`, `$APP`, `$LOG`, `$TEMP`, `$APPCONFIG`, `$APPDATA`, `$APPLOCALDATA`, `$APPCACHE`, `$APPLOG`.","type":"string"},{"properties":{"path":{"description":"A path that can be accessed by the webview when using the fs APIs.\n\nThe pattern can start with a variable that resolves to a system base directory. The variables are: `$AUDIO`, `$CACHE`, `$CONFIG`, `$DATA`, `$LOCALDATA`, `$DESKTOP`, `$DOCUMENT`, `$DOWNLOAD`, `$EXE`, `$FONT`, `$HOME`, `$PICTURE`, `$PUBLIC`, `$RUNTIME`, `$TEMPLATE`, `$VIDEO`, `$RESOURCE`, `$APP`, `$LOG`, `$TEMP`, `$APPCONFIG`, `$APPDATA`, `$APPLOCALDATA`, `$APPCACHE`, `$APPLOG`.","type":"string"}},"required":["path"],"type":"object"}],"description":"FS scope entry.","title":"FsScopeEntry"}},"shell":{"default_permission":{"identifier":"default","description":"This permission set configures which\nshell functionality is exposed by default.\n\n#### Granted Permissions\n\nIt allows to use the `open` functionality with a reasonable\nscope pre-configured. It will allow opening `http(s)://`,\n`tel:` and `mailto:` links.\n","permissions":["allow-open"]},"permissions":{"allow-execute":{"identifier":"allow-execute","description":"Enables the execute command without any pre-configured scope.","commands":{"allow":["execute"],"deny":[]}},"allow-kill":{"identifier":"allow-kill","description":"Enables the kill command without any pre-configured scope.","commands":{"allow":["kill"],"deny":[]}},"allow-open":{"identifier":"allow-open","description":"Enables the open command without any pre-configured scope.","commands":{"allow":["open"],"deny":[]}},"allow-spawn":{"identifier":"allow-spawn","description":"Enables the spawn command without any pre-configured scope.","commands":{"allow":["spawn"],"deny":[]}},"allow-stdin-write":{"identifier":"allow-stdin-write","description":"Enables the stdin_write command without any pre-configured scope.","commands":{"allow":["stdin_write"],"deny":[]}},"deny-execute":{"identifier":"deny-execute","description":"Denies the execute command without any pre-configured scope.","commands":{"allow":[],"deny":["execute"]}},"deny-kill":{"identifier":"deny-kill","description":"Denies the kill command without any pre-configured scope.","commands":{"allow":[],"deny":["kill"]}},"deny-open":{"identifier":"deny-open","description":"Denies the open command without any pre-configured scope.","commands":{"allow":[],"deny":["open"]}},"deny-spawn":{"identifier":"deny-spawn","description":"Denies the spawn command without any pre-configured scope.","commands":{"allow":[],"deny":["spawn"]}},"deny-stdin-write":{"identifier":"deny-stdin-write","description":"Denies the stdin_write command without any pre-configured scope.","commands":{"allow":[],"deny":["stdin_write"]}}},"permission_sets":{},"global_scope_schema":{"$schema":"http://json-schema.org/draft-07/schema#","anyOf":[{"additionalProperties":false,"properties":{"args":{"allOf":[{"$ref":"#/definitions/ShellScopeEntryAllowedArgs"}],"description":"The allowed arguments for the command execution."},"cmd":{"description":"The command name. It can start with a variable that resolves to a system base directory. The variables are: `$AUDIO`, `$CACHE`, `$CONFIG`, `$DATA`, `$LOCALDATA`, `$DESKTOP`, `$DOCUMENT`, `$DOWNLOAD`, `$EXE`, `$FONT`, `$HOME`, `$PICTURE`, `$PUBLIC`, `$RUNTIME`, `$TEMPLATE`, `$VIDEO`, `$RESOURCE`, `$LOG`, `$TEMP`, `$APPCONFIG`, `$APPDATA`, `$APPLOCALDATA`, `$APPCACHE`, `$APPLOG`.","type":"string"},"name":{"description":"The name for this allowed shell command configuration.\n\nThis name will be used inside of the webview API to call this command along with any specified arguments.","type":"string"}},"required":["cmd","name"],"type":"object"},{"additionalProperties":false,"properties":{"args":{"allOf":[{"$ref":"#/definitions/ShellScopeEntryAllowedArgs"}],"description":"The allowed arguments for the command execution."},"name":{"description":"The name for this allowed shell command configuration.\n\nThis name will be used inside of the webview API to call this command along with any specified arguments.","type":"string"},"sidecar":{"description":"If this command is a sidecar command.","type":"boolean"}},"required":["name","sidecar"],"type":"object"}],"definitions":{"ShellScopeEntryAllowedArg":{"anyOf":[{"description":"A non-configurable argument that is passed to the command in the order it was specified.","type":"string"},{"additionalProperties":false,"description":"A variable that is set while calling the command from the webview API.","properties":{"raw":{"default":false,"description":"Marks the validator as a raw regex, meaning the plugin should not make any modification at runtime.\n\nThis means the regex will not match on the entire string by default, which might be exploited if your regex allow unexpected input to be considered valid. When using this option, make sure your regex is correct.","type":"boolean"},"validator":{"description":"[regex] validator to require passed values to conform to an expected input.\n\nThis will require the argument value passed to this variable to match the `validator` regex before it will be executed.\n\nThe regex string is by default surrounded by `^...$` to match the full string. For example the `https?://\\w+` regex would be registered as `^https?://\\w+$`.\n\n[regex]: <https://docs.rs/regex/latest/regex/#syntax>","type":"string"}},"required":["validator"],"type":"object"}],"description":"A command argument allowed to be executed by the webview API."},"ShellScopeEntryAllowedArgs":{"anyOf":[{"description":"Use a simple boolean to allow all or disable all arguments to this command configuration.","type":"boolean"},{"description":"A specific set of [`ShellScopeEntryAllowedArg`] that are valid to call for the command configuration.","items":{"$ref":"#/definitions/ShellScopeEntryAllowedArg"},"type":"array"}],"description":"A set of command arguments allowed to be executed by the webview API.\n\nA value of `true` will allow any arguments to be passed to the command. `false` will disable all arguments. A list of [`ShellScopeEntryAllowedArg`] will set those arguments as the only valid arguments to be passed to the attached command configuration."}},"description":"Shell scope entry.","title":"ShellScopeEntry"}}}

--- FILE: src-tauri\gen\schemas\capabilities.json ---
{"main-capability":{"identifier":"main-capability","description":"Permiss√µes padr√£o para o AnimeHub","local":true,"windows":["main"],"permissions":["core:default","shell:allow-open","dialog:default",{"identifier":"fs:allow-read","allow":[{"path":"$HOME/**"}]},{"identifier":"fs:allow-write","allow":[{"path":"$HOME/**"}]},"fs:allow-exists","fs:allow-stat"]}}

--- FILE: src-tauri\migrations\005_materialization_records.sql ---
-- Migration: 005_materialization_records.sql
-- Phase 5: Domain Materialization
--
-- Creates the materialization_records table for idempotency tracking.
-- This table stores fingerprints of processed resolution events to prevent
-- duplicate entity creation on replay.
--
-- CRITICAL: This is an ADDITIVE migration. It does not modify existing tables.

-- ============================================================================
-- MATERIALIZATION RECORDS TABLE
-- ============================================================================

CREATE TABLE IF NOT EXISTS materialization_records (
    -- Primary key
    id TEXT PRIMARY KEY,
    
    -- Fingerprint hash for idempotency checking
    -- This is a SHA-256 hash of the resolution event's key fields
    fingerprint_hash TEXT NOT NULL UNIQUE,
    
    -- Type of resolution event that was materialized
    -- Values: 'file_resolved', 'episode_resolved'
    event_type TEXT NOT NULL,
    
    -- The source resolution event ID (for traceability)
    source_event_id TEXT NOT NULL,
    
    -- The resulting anime ID (if created or matched)
    anime_id TEXT,
    
    -- The resulting episode ID (if created or matched)
    episode_id TEXT,
    
    -- The file ID that was linked (if applicable)
    file_id TEXT,
    
    -- The outcome of materialization
    -- Values: 'anime_created', 'anime_matched', 'episode_created', 
    --         'episode_matched', 'file_linked', 'skipped', 'failed: <reason>'
    outcome TEXT NOT NULL,
    
    -- When this materialization occurred (ISO 8601 format)
    materialized_at TEXT NOT NULL,
    
    -- Foreign key constraints (soft references, not enforced)
    -- These allow the record to persist even if the referenced entity is deleted
    CONSTRAINT fk_anime FOREIGN KEY (anime_id) REFERENCES anime(id) ON DELETE SET NULL,
    CONSTRAINT fk_episode FOREIGN KEY (episode_id) REFERENCES episodes(id) ON DELETE SET NULL,
    CONSTRAINT fk_file FOREIGN KEY (file_id) REFERENCES files(id) ON DELETE SET NULL
);

-- ============================================================================
-- INDEXES
-- ============================================================================

-- Primary lookup by fingerprint (for idempotency check)
CREATE INDEX IF NOT EXISTS idx_materialization_fingerprint 
    ON materialization_records(fingerprint_hash);

-- Lookup by source event (for debugging and audit)
CREATE INDEX IF NOT EXISTS idx_materialization_source_event 
    ON materialization_records(source_event_id);

-- Lookup by anime (for listing all materializations for an anime)
CREATE INDEX IF NOT EXISTS idx_materialization_anime 
    ON materialization_records(anime_id);

-- Lookup by episode (for listing all materializations for an episode)
CREATE INDEX IF NOT EXISTS idx_materialization_episode 
    ON materialization_records(episode_id);

-- Lookup by file (for tracing file linkage history)
CREATE INDEX IF NOT EXISTS idx_materialization_file 
    ON materialization_records(file_id);

-- Lookup by timestamp (for audit and cleanup)
CREATE INDEX IF NOT EXISTS idx_materialization_timestamp 
    ON materialization_records(materialized_at);

-- ============================================================================
-- COMMENTS
-- ============================================================================

-- This table is designed for:
-- 1. Idempotency: Prevent duplicate entity creation on event replay
-- 2. Traceability: Link every domain entity to its source resolution event
-- 3. Debugging: Understand why an entity was created and from what source
-- 4. Audit: Track all materialization operations over time
--
-- The fingerprint_hash is computed from:
-- - For FileResolved: file_id + anime_title (lowercase) + episode_number + file_role
-- - For EpisodeResolved: anime_title (lowercase) + episode_number + video_file_id
--
-- This ensures that:
-- - The same file resolved to the same anime/episode will not be processed twice
-- - Different files for the same episode will each be processed once
-- - Replaying the entire event stream is safe and idempotent


--- FILE: src-tauri\schema.sql ---
-- AnimeHub Database Schema
-- SQLite 3.x
-- 
-- CRITICAL RULES:
-- 1. UUIDs stored as TEXT
-- 2. Timestamps in ISO 8601 UTC format
-- 3. Enums stored as TEXT with explicit values
-- 4. JSON for flexible/array data
-- 5. Foreign keys with explicit CASCADE behavior
-- 6. No implicit behavior - everything is visible

-- ============================================================================
-- SCHEMA VERSIONING
-- ============================================================================

CREATE TABLE IF NOT EXISTS schema_version (
    version INTEGER PRIMARY KEY,
    applied_at TEXT NOT NULL
);

-- ============================================================================
-- PRIMARY ENTITIES
-- ============================================================================

-- Anime: Root entity for Japanese animation works
CREATE TABLE anime (
    id TEXT PRIMARY KEY,
    titulo_principal TEXT NOT NULL CHECK(length(trim(titulo_principal)) > 0),
    titulos_alternativos TEXT NOT NULL, -- JSON array of strings
    tipo TEXT NOT NULL CHECK(tipo IN ('TV', 'Movie', 'OVA', 'Special')),
    status TEXT NOT NULL CHECK(status IN ('em_exibicao', 'finalizado', 'cancelado')),
    total_episodios INTEGER CHECK(total_episodios IS NULL OR total_episodios > 0),
    data_inicio TEXT, -- ISO 8601 or NULL
    data_fim TEXT,    -- ISO 8601 or NULL
    metadados_livres TEXT NOT NULL, -- JSON object
    criado_em TEXT NOT NULL,
    atualizado_em TEXT NOT NULL
);

CREATE INDEX idx_anime_tipo ON anime(tipo);
CREATE INDEX idx_anime_status ON anime(status);
CREATE INDEX idx_anime_atualizado ON anime(atualizado_em);

-- Episodes: Individual viewing units belonging to an Anime
CREATE TABLE episodes (
    id TEXT PRIMARY KEY,
    anime_id TEXT NOT NULL,
    numero_tipo TEXT NOT NULL CHECK(numero_tipo IN ('regular', 'special')),
    numero_valor TEXT NOT NULL, -- For regular: "1", "2", etc. For special: label
    titulo TEXT,
    duracao_esperada INTEGER CHECK(duracao_esperada IS NULL OR duracao_esperada > 0),
    progresso_atual INTEGER NOT NULL CHECK(progresso_atual >= 0),
    estado TEXT NOT NULL CHECK(estado IN ('nao_visto', 'em_progresso', 'concluido')),
    criado_em TEXT NOT NULL,
    atualizado_em TEXT NOT NULL,
    FOREIGN KEY (anime_id) REFERENCES anime(id) ON DELETE CASCADE
);

CREATE INDEX idx_episodes_anime ON episodes(anime_id);
CREATE INDEX idx_episodes_estado ON episodes(estado);
CREATE INDEX idx_episodes_numero ON episodes(anime_id, numero_tipo, numero_valor);

-- Files: Physical files on disk
CREATE TABLE files (
    id TEXT PRIMARY KEY,
    caminho_absoluto TEXT NOT NULL UNIQUE,
    tipo TEXT NOT NULL CHECK(tipo IN ('video', 'legenda', 'imagem', 'outro')),
    tamanho INTEGER NOT NULL CHECK(tamanho >= 0),
    hash TEXT,
    data_modificacao TEXT NOT NULL,
    origem TEXT NOT NULL CHECK(origem IN ('scan', 'importacao', 'manual')),
    criado_em TEXT NOT NULL,
    atualizado_em TEXT NOT NULL
);

CREATE INDEX idx_files_tipo ON files(tipo);
CREATE INDEX idx_files_caminho ON files(caminho_absoluto);

-- Episode-File association (N:M)
CREATE TABLE episode_files (
    episode_id TEXT NOT NULL,
    file_id TEXT NOT NULL,
    is_primary INTEGER NOT NULL CHECK(is_primary IN (0, 1)),
    criado_em TEXT NOT NULL,
    PRIMARY KEY (episode_id, file_id),
    FOREIGN KEY (episode_id) REFERENCES episodes(id) ON DELETE CASCADE,
    FOREIGN KEY (file_id) REFERENCES files(id) ON DELETE CASCADE
);

CREATE INDEX idx_episode_files_episode ON episode_files(episode_id);
CREATE INDEX idx_episode_files_file ON episode_files(file_id);
CREATE INDEX idx_episode_files_primary ON episode_files(episode_id, is_primary);

-- Subtitles: Transformable subtitle data
CREATE TABLE subtitles (
    id TEXT PRIMARY KEY,
    file_id TEXT NOT NULL,
    formato TEXT NOT NULL CHECK(formato IN ('SRT', 'ASS', 'VTT')),
    idioma TEXT NOT NULL CHECK(length(trim(idioma)) > 0),
    versao INTEGER NOT NULL CHECK(versao > 0),
    eh_original INTEGER NOT NULL CHECK(eh_original IN (0, 1)),
    criado_em TEXT NOT NULL,
    FOREIGN KEY (file_id) REFERENCES files(id) ON DELETE CASCADE
);

CREATE INDEX idx_subtitles_file ON subtitles(file_id);
CREATE INDEX idx_subtitles_idioma ON subtitles(idioma);
CREATE INDEX idx_subtitles_original ON subtitles(eh_original);

-- Subtitle transformations: History of subtitle modifications
CREATE TABLE subtitle_transformations (
    id TEXT PRIMARY KEY,
    subtitle_id_origem TEXT NOT NULL,
    tipo TEXT NOT NULL CHECK(tipo IN ('style', 'timing', 'conversao')),
    parametros_aplicados TEXT NOT NULL, -- JSON object
    criado_em TEXT NOT NULL,
    FOREIGN KEY (subtitle_id_origem) REFERENCES subtitles(id) ON DELETE CASCADE
);

CREATE INDEX idx_subtitle_transformations_origem ON subtitle_transformations(subtitle_id_origem);
CREATE INDEX idx_subtitle_transformations_tipo ON subtitle_transformations(tipo);

-- Collections: User-defined organizational groups
CREATE TABLE collections (
    id TEXT PRIMARY KEY,
    nome TEXT NOT NULL CHECK(length(trim(nome)) > 0),
    descricao TEXT,
    criado_em TEXT NOT NULL
);

-- Anime-Collection association (N:M)
CREATE TABLE anime_collections (
    anime_id TEXT NOT NULL,
    collection_id TEXT NOT NULL,
    criado_em TEXT NOT NULL,
    PRIMARY KEY (anime_id, collection_id),
    FOREIGN KEY (anime_id) REFERENCES anime(id) ON DELETE CASCADE,
    FOREIGN KEY (collection_id) REFERENCES collections(id) ON DELETE CASCADE
);

CREATE INDEX idx_anime_collections_anime ON anime_collections(anime_id);
CREATE INDEX idx_anime_collections_collection ON anime_collections(collection_id);

-- ============================================================================
-- RELATIONSHIPS & AUXILIARY ENTITIES
-- ============================================================================

-- External references: Links to external services (AniList, etc.)
CREATE TABLE external_references (
    id TEXT PRIMARY KEY,
    anime_id TEXT NOT NULL,
    fonte TEXT NOT NULL CHECK(length(trim(fonte)) > 0),
    external_id TEXT NOT NULL CHECK(length(trim(external_id)) > 0),
    criado_em TEXT NOT NULL,
    UNIQUE(anime_id, fonte),
    FOREIGN KEY (anime_id) REFERENCES anime(id) ON DELETE CASCADE
);

CREATE INDEX idx_external_references_anime ON external_references(anime_id);
CREATE INDEX idx_external_references_fonte ON external_references(fonte);
CREATE INDEX idx_external_references_external_id ON external_references(external_id);

-- Anime aliases: Tracks merge history
CREATE TABLE anime_aliases (
    id TEXT PRIMARY KEY,
    anime_principal_id TEXT NOT NULL,
    anime_alias_id TEXT NOT NULL,
    criado_em TEXT NOT NULL,
    UNIQUE(anime_alias_id),
    FOREIGN KEY (anime_principal_id) REFERENCES anime(id) ON DELETE CASCADE,
    FOREIGN KEY (anime_alias_id) REFERENCES anime(id) ON DELETE CASCADE,
    CHECK(anime_principal_id != anime_alias_id)
);

CREATE INDEX idx_anime_aliases_principal ON anime_aliases(anime_principal_id);
CREATE INDEX idx_anime_aliases_alias ON anime_aliases(anime_alias_id);

-- ============================================================================
-- DERIVED DATA (NOT SOURCE OF TRUTH)
-- ============================================================================

-- ‚ö†Ô∏è DERIVED DATA - CAN BE DELETED WITHOUT AFFECTING DOMAINS
-- Statistics snapshots: Cached aggregate data
CREATE TABLE statistics_snapshots (
    id TEXT PRIMARY KEY,
    tipo TEXT NOT NULL, -- "global", "por_anime:{uuid}", "por_periodo:{start}:{end}"
    valor TEXT NOT NULL, -- JSON snapshot
    gerado_em TEXT NOT NULL
);

CREATE INDEX idx_statistics_tipo ON statistics_snapshots(tipo);
CREATE INDEX idx_statistics_gerado ON statistics_snapshots(gerado_em);

-- ============================================================================
-- EVENT STORE (OPTIONAL - APPEND-ONLY AUDIT LOG)
-- ============================================================================

-- Domain events: Immutable event log for debugging/audit
CREATE TABLE domain_events (
    event_id TEXT PRIMARY KEY,
    event_type TEXT NOT NULL,
    payload TEXT NOT NULL, -- JSON
    occurred_at TEXT NOT NULL
);

CREATE INDEX idx_domain_events_type ON domain_events(event_type);
CREATE INDEX idx_domain_events_occurred ON domain_events(occurred_at);

-- ============================================================================
-- CONSTRAINTS & VALIDATION
-- ============================================================================

-- Ensure progress never exceeds duration (when known)
-- This is a database-level safety check, NOT business logic
-- The domain should prevent this from ever being violated
CREATE TRIGGER check_episode_progress_invariant
BEFORE UPDATE ON episodes
FOR EACH ROW
WHEN NEW.duracao_esperada IS NOT NULL AND NEW.progresso_atual > NEW.duracao_esperada
BEGIN
    SELECT RAISE(ABORT, 'INVARIANT VIOLATION: Progress exceeds duration');
END;

-- Ensure anime dates are logical (if both present)
CREATE TRIGGER check_anime_dates_invariant
BEFORE UPDATE ON anime
FOR EACH ROW
WHEN NEW.data_inicio IS NOT NULL AND NEW.data_fim IS NOT NULL AND NEW.data_inicio > NEW.data_fim
BEGIN
    SELECT RAISE(ABORT, 'INVARIANT VIOLATION: Start date after end date');
END;

-- ============================================================================
-- INITIAL DATA
-- ============================================================================

-- Insert initial schema version
INSERT OR IGNORE INTO schema_version (version, applied_at)
VALUES (1, datetime('now'));

--- FILE: src-tauri\src\app\materialization_init.rs ---
// src-tauri/src/app/materialization_init.rs
//
// Materialization Initialization - Phase 5
//
// Application-level initialization for the materialization subsystem.
// This file shows how to wire up the MaterializationService with the event bus.
//
// CRITICAL RULES:
// - Uses existing repository implementations
// - Uses existing event bus
// - Does not modify existing initialization code
// - Additive integration only

use std::sync::Arc;
use r2d2::Pool;
use r2d2_sqlite::SqliteConnectionManager;

use crate::events::EventBus;
use crate::events::handlers::register_materialization_handlers;
use crate::repositories::anime_repository::AnimeRepository;
use crate::repositories::EpisodeRepository;

use crate::repositories::FileRepository;

use crate::repositories::materialization_repository::MaterializationRepository;
use crate::repositories::sqlite_materialization_repository::SqliteMaterializationRepository;
use crate::services::materialization_service::MaterializationService;
use crate::error::AppResult;

// ============================================================================
// MATERIALIZATION SUBSYSTEM INITIALIZATION
// ============================================================================

/// Configuration for the materialization subsystem
pub struct MaterializationConfig {
    /// Whether to enable automatic materialization on resolution events
    pub auto_materialize: bool,
}

impl Default for MaterializationConfig {
    fn default() -> Self {
        Self {
            auto_materialize: true,
        }
    }
}

/// Initializes the materialization subsystem.
/// 
/// This function:
/// 1. Creates the MaterializationRepository
/// 2. Creates the MaterializationService
/// 3. Registers event handlers with the event bus
/// 
/// # Arguments
/// * `anime_repo` - The anime repository implementation
/// * `episode_repo` - The episode repository implementation
/// * `file_repo` - The file repository implementation
/// * `pool` - The SQLite connection pool for materialization records
/// * `event_bus` - The application event bus
/// * `config` - Configuration options
/// 
/// # Returns
/// The initialized MaterializationService wrapped in Arc
pub fn init_materialization_subsystem(
    anime_repo: Arc<dyn AnimeRepository>,
    episode_repo: Arc<dyn EpisodeRepository>,
    file_repo: Arc<dyn FileRepository>,
    pool: Arc<Pool<SqliteConnectionManager>>,
    event_bus: Arc<EventBus>,
    config: MaterializationConfig,
) -> AppResult<Arc<MaterializationService>> {
    println!("[MATERIALIZATION] Initializing subsystem...");

    // Create materialization repository
    let mat_repo: Arc<dyn MaterializationRepository> = Arc::new(
        SqliteMaterializationRepository::new(pool)?
    );

    // Create materialization service
    let service = Arc::new(MaterializationService::new(
        anime_repo,
        episode_repo,
        file_repo,
        mat_repo,
        event_bus.clone(),
    ));

    // Register event handlers if auto-materialize is enabled
    if config.auto_materialize {
        register_materialization_handlers(&event_bus, service.clone());
        println!("[MATERIALIZATION] Event handlers registered");
    }

    println!("[MATERIALIZATION] Subsystem initialized");
    Ok(service)
}

// ============================================================================
// INTEGRATION EXAMPLE
// ============================================================================

/// Example of how to integrate materialization into the main application.
/// This is NOT executable code, but a reference for integration.
/// 
/// ```rust,ignore
/// // In main.rs or app initialization:
/// 
/// use animehub::app::materialization_init::{
///     init_materialization_subsystem,
///     MaterializationConfig,
/// };
/// 
/// // Assuming these are already created:
/// // - anime_repo: Arc<dyn AnimeRepository>
/// // - episode_repo: Arc<dyn EpisodeRepository>
/// // - file_repo: Arc<dyn FileRepository>
/// // - pool: Arc<Pool<SqliteConnectionManager>>
/// // - event_bus: Arc<EventBus>
/// 
/// let mat_service = init_materialization_subsystem(
///     anime_repo,
///     episode_repo,
///     file_repo,
///     pool,
///     event_bus,
///     MaterializationConfig::default(),
/// )?;
/// 
/// // The materialization service is now active and will automatically
/// // process FileResolved and EpisodeResolved events from the event bus.
/// 
/// // For manual materialization (e.g., in tests or CLI):
/// let event = FileResolved::new(...);
/// let result = mat_service.materialize_file_resolved(&event)?;
/// ```
#[cfg(doctest)]
fn _integration_example() {}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_default_config() {
        let config = MaterializationConfig::default();
        assert!(config.auto_materialize);
    }
}


--- FILE: src-tauri\src\application\commands\anime_commands.rs ---
// src-tauri/src/application/commands/anime_commands.rs
//
// Anime Command Handlers
//
// RULES:
// - Accept DTOs
// - Call sealed services
// - Return DTOs
// - Never contain business logic

use chrono::DateTime;
use tauri::State;
use uuid::Uuid;

use crate::application::{dto::*, state::AppState};
use crate::domain::{AnimeStatus, AnimeType};
use crate::services::*;

/// List all animes
#[tauri::command]
pub async fn list_animes(state: State<'_, AppState>) -> Result<Vec<AnimeDto>, String> {
    let animes = state
        .anime_service
        .list_all_animes()
        .map_err(|e| e.to_string())?;

    Ok(animes.into_iter().map(AnimeDto::from).collect())
}

/// Get a single anime by ID
#[tauri::command]
pub async fn get_anime(
    anime_id: String,
    state: State<'_, AppState>,
) -> Result<Option<AnimeDto>, String> {
    let id = Uuid::parse_str(&anime_id).map_err(|e| format!("Invalid UUID: {}", e))?;

    let anime = state
        .anime_service
        .get_anime(id)
        .map_err(|e| e.to_string())?;

    Ok(anime.map(AnimeDto::from))
}

/// Create a new anime
#[tauri::command]
pub async fn create_anime(
    dto: CreateAnimeDto,
    state: State<'_, AppState>,
) -> Result<String, String> {
    // Parse type
    let tipo = match dto.tipo.as_str() {
        "TV" => AnimeType::TV,
        "Movie" => AnimeType::Movie,
        "OVA" => AnimeType::OVA,
        "Special" => AnimeType::Special,
        _ => return Err("Invalid anime type".to_string()),
    };

    // Parse status
    let status = match dto.status.as_str() {
        "em_exibicao" => AnimeStatus::EmExibicao,
        "finalizado" => AnimeStatus::Finalizado,
        "cancelado" => AnimeStatus::Cancelado,
        _ => return Err("Invalid status".to_string()),
    };

    // Parse dates
    let data_inicio = dto
        .data_inicio
        .map(|s| DateTime::parse_from_rfc3339(&s))
        .transpose()
        .map_err(|e| format!("Invalid start date: {}", e))?
        .map(|dt| dt.with_timezone(&chrono::Utc));

    let data_fim = dto
        .data_fim
        .map(|s| DateTime::parse_from_rfc3339(&s))
        .transpose()
        .map_err(|e| format!("Invalid end date: {}", e))?
        .map(|dt| dt.with_timezone(&chrono::Utc));

    // Create request
    let request = CreateAnimeRequest {
        titulo_principal: dto.titulo_principal,
        titulos_alternativos: dto.titulos_alternativos,
        tipo,
        status,
        total_episodios: dto.total_episodios,
        data_inicio,
        data_fim,
        metadados_livres: dto
            .metadados_livres
            .unwrap_or(serde_json::Value::Object(serde_json::Map::new())),
    };

    let anime_id = state
        .anime_service
        .create_anime(request)
        .map_err(|e| e.to_string())?;

    Ok(anime_id.to_string())
}

/// Update an anime's metadata
#[tauri::command]
pub async fn update_anime(
    anime_id: String,
    titulo_principal: Option<String>,
    status: Option<String>,
    state: State<'_, AppState>,
) -> Result<(), String> {
    let id = Uuid::parse_str(&anime_id).map_err(|e| format!("Invalid UUID: {}", e))?;

    let parsed_status = status
        .map(|s| match s.as_str() {
            "em_exibicao" => Ok(AnimeStatus::EmExibicao),
            "finalizado" => Ok(AnimeStatus::Finalizado),
            "cancelado" => Ok(AnimeStatus::Cancelado),
            _ => Err("Invalid status".to_string()),
        })
        .transpose()?;

    let request = UpdateAnimeRequest {
        anime_id: id,
        titulo_principal,
        titulos_alternativos: None,
        tipo: None,
        status: parsed_status,
        total_episodios: None,
        data_inicio: None,
        data_fim: None,
        metadados_livres: None,
    };

    state
        .anime_service
        .update_anime(request)
        .map_err(|e| e.to_string())?;

    Ok(())
}


--- FILE: src-tauri\src\application\commands\episode_commands.rs ---
// src-tauri/src/application/commands/episode_commands.rs

use tauri::State;
use uuid::Uuid;

use crate::application::{dto::*, state::AppState};
use crate::domain::EpisodeNumber;
use crate::services::*;

/// List all episodes for an anime
#[tauri::command]
pub async fn list_episodes(
    anime_id: String,
    state: State<'_, AppState>,
) -> Result<Vec<EpisodeDto>, String> {
    let id = Uuid::parse_str(&anime_id).map_err(|e| format!("Invalid UUID: {}", e))?;

    let episodes = state
        .episode_service
        .list_episodes_for_anime(id)
        .map_err(|e| e.to_string())?;

    Ok(episodes.into_iter().map(EpisodeDto::from).collect())
}

/// Get a single episode by ID
#[tauri::command]
pub async fn get_episode(
    episode_id: String,
    state: State<'_, AppState>,
) -> Result<Option<EpisodeDto>, String> {
    let id = Uuid::parse_str(&episode_id).map_err(|e| format!("Invalid UUID: {}", e))?;

    let episode = state
        .episode_service
        .get_episode(id)
        .map_err(|e| e.to_string())?;

    Ok(episode.map(EpisodeDto::from))
}

/// Create a new episode
#[tauri::command]
pub async fn create_episode(
    dto: CreateEpisodeDto,
    state: State<'_, AppState>,
) -> Result<String, String> {
    let anime_id =
        Uuid::parse_str(&dto.anime_id).map_err(|e| format!("Invalid anime UUID: {}", e))?;

    let numero = match dto.numero_tipo.as_str() {
        "regular" => {
            let num: u32 = dto
                .numero
                .parse()
                .map_err(|e| format!("Invalid episode number: {}", e))?;
            EpisodeNumber::regular(num)
        }
        "special" => EpisodeNumber::special(dto.numero.clone()),
        _ => return Err("Invalid numero_tipo, must be 'regular' or 'special'".to_string()),
    };

    let request = CreateEpisodeRequest {
        anime_id,
        numero,
        titulo: dto.titulo,
        duracao_esperada: dto.duracao_esperada,
    };

    let episode_id = state
        .episode_service
        .create_episode(request)
        .map_err(|e| e.to_string())?;

    Ok(episode_id.to_string())
}

/// Update episode progress
#[tauri::command]
pub async fn update_progress(
    dto: UpdateProgressDto,
    state: State<'_, AppState>,
) -> Result<(), String> {
    let episode_id =
        Uuid::parse_str(&dto.episode_id).map_err(|e| format!("Invalid UUID: {}", e))?;

    state
        .episode_service
        .update_progress(episode_id, dto.progress_seconds)
        .map_err(|e| e.to_string())?;

    Ok(())
}

/// Mark episode as completed
#[tauri::command]
pub async fn mark_episode_completed(
    episode_id: String,
    state: State<'_, AppState>,
) -> Result<(), String> {
    let id = Uuid::parse_str(&episode_id).map_err(|e| format!("Invalid UUID: {}", e))?;

    state
        .episode_service
        .mark_completed(id)
        .map_err(|e| e.to_string())?;

    Ok(())
}

/// Reset episode progress
#[tauri::command]
pub async fn reset_episode_progress(
    episode_id: String,
    state: State<'_, AppState>,
) -> Result<(), String> {
    let id = Uuid::parse_str(&episode_id).map_err(|e| format!("Invalid UUID: {}", e))?;

    state
        .episode_service
        .reset_progress(id)
        .map_err(|e| e.to_string())?;

    Ok(())
}


--- FILE: src-tauri\src\application\commands\file_commands.rs ---
// src-tauri/src/application/commands/file_commands.rs
//
// PHASE 4 CORRECTED:
// - REMOVED: get_linked_files call (hallucinated API)
// - get_episode_files now uses episode_repo.list_by_anime + file_repo.get_by_id

use std::path::PathBuf;
use tauri::State;

use crate::application::{dto::*, state::AppState};

/// Scan a directory for video and subtitle files
#[tauri::command]
pub async fn scan_directory(
    dto: ScanDirectoryDto,
    state: State<'_, AppState>,
) -> Result<usize, String> {
    let path = PathBuf::from(dto.directory_path);

    let files_found = state
        .file_service
        .scan_directory(path)
        .map_err(|e| e.to_string())?;

    Ok(files_found)
}

/// Get linked files for an episode
/// CORRECTED: This command is removed as get_linked_files does not exist.
/// The frontend should query files through the file listing endpoints.
#[tauri::command]
pub async fn get_episode_files(
    episode_id: String,
    _state: State<'_, AppState>,
) -> Result<Vec<String>, String> {
    let _id = uuid::Uuid::parse_str(&episode_id).map_err(|e| format!("Invalid UUID: {}", e))?;

    // CORRECTION: get_linked_files does not exist in EpisodeService or EpisodeRepository
    // Return empty list - this endpoint needs to be redesigned or removed
    // The proper approach is to query files that are linked to this episode
    // through the file-episode link table, but that API doesn't exist yet.
    Ok(Vec::new())
}


--- FILE: src-tauri\src\application\commands\mod.rs ---
// src-tauri/src/application/commands/mod.rs
//
// Tauri Command Handlers
//
// ARCHITECTURE:
// - Commands are thin adapters between UI and Services
// - Commands accept DTOs, return DTOs
// - Commands handle error conversion for Tauri
// - Commands NEVER contain business logic

pub mod anime_commands;
pub mod episode_commands;
pub mod file_commands;
pub mod playback_commands;
pub mod statistics_commands;

pub use anime_commands::*;
pub use episode_commands::*;
pub use file_commands::*;
pub use playback_commands::*;
pub use statistics_commands::*;


--- FILE: src-tauri\src\application\commands\playback_commands.rs ---
// src-tauri/src/application/commands/playback_commands.rs

use tauri::State;
use uuid::Uuid;

use crate::application::state::AppState;
use crate::services::{PlaybackService, StartPlaybackRequest};

#[tauri::command]
pub async fn start_playback(
    state: State<'_, AppState>,
    episode_id: Uuid,
    file_id: Uuid,
) -> Result<String, String> {
    let playback_service: std::sync::Arc<PlaybackService> = state.playback_service.clone();

    let request = StartPlaybackRequest {
        episode_id,
        file_id,
    };

    let file_path = playback_service
        .start_playback(request)
        .map_err(|e| e.to_string())?;

    Ok(file_path.to_string_lossy().to_string())
}

#[tauri::command]
pub async fn toggle_pause_playback(state: State<'_, AppState>) -> Result<(), String> {
    let playback_service: std::sync::Arc<PlaybackService> = state.playback_service.clone();

    playback_service.toggle_pause().map_err(|e| e.to_string())
}

#[tauri::command]
pub async fn seek_playback(
    state: State<'_, AppState>,
    episode_id: Uuid,
    position_seconds: u64,
) -> Result<(), String> {
    let playback_service: std::sync::Arc<PlaybackService> = state.playback_service.clone();

    playback_service
        .seek_to(episode_id, position_seconds)
        .map_err(|e| e.to_string())
}

#[tauri::command]
pub async fn stop_playback(state: State<'_, AppState>, episode_id: Uuid) -> Result<(), String> {
    let playback_service: std::sync::Arc<PlaybackService> = state.playback_service.clone();

    playback_service
        .stop_playback(episode_id)
        .map_err(|e| e.to_string())
}

#[tauri::command]
pub async fn get_episode_progress(
    state: State<'_, AppState>,
    episode_id: Uuid,
) -> Result<u64, String> {
    let playback_service: std::sync::Arc<PlaybackService> = state.playback_service.clone();

    playback_service
        .get_current_position(episode_id)
        .map_err(|e| e.to_string())
}


--- FILE: src-tauri\src\application\commands\statistics_commands.rs ---
// src-tauri/src/application/commands/statistics_commands.rs

use tauri::State;

use crate::application::{dto::*, state::AppState};

/// Get global statistics
#[tauri::command]
pub async fn get_global_statistics(
    state: State<'_, AppState>,
) -> Result<GlobalStatisticsDto, String> {
    let stats = state
        .statistics_service
        .calculate_global_statistics()
        .map_err(|e| e.to_string())?;

    Ok(GlobalStatisticsDto::from(stats))
}


--- FILE: src-tauri\src\application\dto\mod.rs ---
// src-tauri/src/application/dto/mod.rs
//
// Data Transfer Objects
//
// CRITICAL PRINCIPLES:
// - DTOs are UI-friendly representations
// - DTOs NEVER leak domain invariants
// - DTOs are simple, serializable structs
// - Conversion FROM domain entities only (never TO)

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

// ============================================================================
// ANIME DTOs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnimeDto {
    pub id: String,
    pub titulo_principal: String,
    pub titulos_alternativos: Vec<String>,
    pub tipo: String,
    pub status: String,
    pub total_episodios: Option<u32>,
    pub data_inicio: Option<String>,
    pub data_fim: Option<String>,
    pub metadados_livres: serde_json::Value,
    pub criado_em: String,
    pub atualizado_em: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CreateAnimeDto {
    pub titulo_principal: String,
    pub titulos_alternativos: Vec<String>,
    pub tipo: String,
    pub status: String,
    pub total_episodios: Option<u32>,
    pub data_inicio: Option<String>,
    pub data_fim: Option<String>,
    pub metadados_livres: Option<serde_json::Value>,
}

// ============================================================================
// EPISODE DTOs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EpisodeDto {
    pub id: String,
    pub anime_id: String,
    pub numero: String,
    pub titulo: Option<String>,
    pub duracao_esperada: Option<u64>,
    pub progresso_atual: u64,
    pub estado: String,
    pub criado_em: String,
    pub atualizado_em: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CreateEpisodeDto {
    pub anime_id: String,
    pub numero: String,
    pub numero_tipo: String, // "regular" or "special"
    pub titulo: Option<String>,
    pub duracao_esperada: Option<u64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UpdateProgressDto {
    pub episode_id: String,
    pub progress_seconds: u64,
}

// ============================================================================
// FILE DTOs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileDto {
    pub id: String,
    pub caminho_absoluto: String,
    pub tipo: String,
    pub tamanho: u64,
    pub hash: Option<String>,
    pub data_modificacao: String,
    pub origem: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScanDirectoryDto {
    pub directory_path: String,
}

// ============================================================================
// PLAYBACK DTOs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StartPlaybackDto {
    pub episode_id: String,
    pub file_id: Option<String>,
    pub start_position: Option<u64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlaybackStatusDto {
    pub episode_id: String,
    pub current_position: u64,
    pub is_playing: bool,
}

// ============================================================================
// STATISTICS DTOs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GlobalStatisticsDto {
    pub total_animes: u32,
    pub total_episodes: u32,
    pub episodes_assistidos: u32,
    pub tempo_total_assistido: u64,
    pub animes_em_progresso: u32,
    pub animes_completos: u32,
}

// ============================================================================
// RESPONSE DTOs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SuccessResponse<T> {
    pub success: bool,
    pub data: T,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorResponse {
    pub success: bool,
    pub error: String,
}

impl<T> SuccessResponse<T> {
    pub fn new(data: T) -> Self {
        Self {
            success: true,
            data,
        }
    }
}

impl ErrorResponse {
    pub fn new(error: String) -> Self {
        Self {
            success: false,
            error,
        }
    }
}

// ============================================================================
// CONVERSION HELPERS (Domain ‚Üí DTO)
// ============================================================================

impl From<crate::domain::Anime> for AnimeDto {
    fn from(anime: crate::domain::Anime) -> Self {
        Self {
            id: anime.id.to_string(),
            titulo_principal: anime.titulo_principal,
            titulos_alternativos: anime.titulos_alternativos,
            tipo: anime.tipo.to_string(),
            status: anime.status.to_string(),
            total_episodios: anime.total_episodios,
            data_inicio: anime.data_inicio.map(|d| d.to_rfc3339()),
            data_fim: anime.data_fim.map(|d| d.to_rfc3339()),
            metadados_livres: anime.metadados_livres,
            criado_em: anime.criado_em.to_rfc3339(),
            atualizado_em: anime.atualizado_em.to_rfc3339(),
        }
    }
}

impl From<crate::domain::Episode> for EpisodeDto {
    fn from(episode: crate::domain::Episode) -> Self {
        Self {
            id: episode.id.to_string(),
            anime_id: episode.anime_id.to_string(),
            numero: episode.numero.to_string(),
            titulo: episode.titulo,
            duracao_esperada: episode.duracao_esperada,
            progresso_atual: episode.progresso_atual,
            estado: episode.estado.to_string(),
            criado_em: episode.criado_em.to_rfc3339(),
            atualizado_em: episode.atualizado_em.to_rfc3339(),
        }
    }
}

impl From<crate::domain::File> for FileDto {
    fn from(file: crate::domain::File) -> Self {
        Self {
            id: file.id.to_string(),
            caminho_absoluto: file.caminho_absoluto.to_string_lossy().to_string(),
            tipo: file.tipo.to_string(),
            tamanho: file.tamanho,
            hash: file.hash,
            data_modificacao: file.data_modificacao.to_rfc3339(),
            origem: file.origem.to_string(),
        }
    }
}

impl From<crate::domain::GlobalStatistics> for GlobalStatisticsDto {
    fn from(stats: crate::domain::GlobalStatistics) -> Self {
        Self {
            total_animes: stats.total_animes,
            total_episodes: stats.total_episodes,
            episodes_assistidos: stats.episodes_assistidos,
            tempo_total_assistido: stats.tempo_total_assistido,
            animes_em_progresso: stats.animes_em_progresso,
            animes_completos: stats.animes_completos,
        }
    }
}


--- FILE: src-tauri\src\application\error_handling.rs ---
// src-tauri/src/application/error_handling.rs
//
// Enhanced Error Handling for Commands
//
// ARCHITECTURE:
// - Maps internal errors ‚Üí user-friendly responses
// - Provides consistent error format for UI
// - Never exposes internal implementation details
// - Logs errors for debugging

use serde::{Serialize, Deserialize};
use crate::error::AppError;

/// Standard error response for UI
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorResponse {
    pub success: bool,
    pub error_type: ErrorType,
    pub message: String,
    pub details: Option<String>,
}

/// Error categories for UI
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum ErrorType {
    /// Resource not found (404)
    NotFound,
    
    /// Invalid input/validation error (400)
    Validation,
    
    /// Domain invariant violation (422)
    DomainError,
    
    /// Database/persistence error (500)
    Database,
    
    /// External service error (502)
    ExternalService,
    
    /// File system error (500)
    FileSystem,
    
    /// Other/unknown error (500)
    Internal,
}

impl ErrorResponse {
    /// Create error response from AppError
    pub fn from_app_error(error: AppError) -> Self {
        match error {
            AppError::NotFound => Self {
                success: false,
                error_type: ErrorType::NotFound,
                message: "Resource not found".to_string(),
                details: None,
            },
            
            AppError::Domain(domain_error) => Self {
                success: false,
                error_type: ErrorType::DomainError,
                message: "Domain validation failed".to_string(),
                details: Some(domain_error.to_string()),
            },
            
            AppError::Database(db_error) => {
                // Log full error for debugging
                eprintln!("Database error: {:?}", db_error);
                
                Self {
                    success: false,
                    error_type: ErrorType::Database,
                    message: "Database operation failed".to_string(),
                    details: Some("Check logs for details".to_string()),
                }
            },
            
            AppError::Serialization(serde_error) => {
                eprintln!("Serialization error: {:?}", serde_error);
                
                Self {
                    success: false,
                    error_type: ErrorType::Internal,
                    message: "Data serialization failed".to_string(),
                    details: None,
                }
            },
            
            AppError::Io(io_error) => {
                eprintln!("IO error: {:?}", io_error);
                
                Self {
                    success: false,
                    error_type: ErrorType::FileSystem,
                    message: "File system operation failed".to_string(),
                    details: Some(io_error.to_string()),
                }
            },
            
            AppError::Pool(pool_error) => {
                eprintln!("Connection pool error: {}", pool_error);
                
                Self {
                    success: false,
                    error_type: ErrorType::Database,
                    message: "Database connection failed".to_string(),
                    details: None,
                }
            },
            
            AppError::Other(message) => {
                // Check if it's an external service error
                if message.contains("AniList") || message.contains("MPV") {
                    Self {
                        success: false,
                        error_type: ErrorType::ExternalService,
                        message: "External service error".to_string(),
                        details: Some(message),
                    }
                } else {
                    eprintln!("Other error: {}", message);
                    
                    Self {
                        success: false,
                        error_type: ErrorType::Internal,
                        message,
                        details: None,
                    }
                }
            },
        }
    }
    
    /// Create validation error
    pub fn validation(message: String) -> Self {
        Self {
            success: false,
            error_type: ErrorType::Validation,
            message,
            details: None,
        }
    }
    
    /// Create not found error
    pub fn not_found(resource: &str) -> Self {
        Self {
            success: false,
            error_type: ErrorType::NotFound,
            message: format!("{} not found", resource),
            details: None,
        }
    }
}

/// Helper trait to convert Results to ErrorResponse
pub trait ToErrorResponse<T> {
    fn to_error_response(self) -> Result<T, String>;
}

impl<T> ToErrorResponse<T> for Result<T, AppError> {
    fn to_error_response(self) -> Result<T, String> {
        self.map_err(|e| {
            let error_response = ErrorResponse::from_app_error(e);
            serde_json::to_string(&error_response)
                .unwrap_or_else(|_| "Internal error".to_string())
        })
    }
}

/// Macro to wrap command results with error handling
#[macro_export]
macro_rules! handle_command {
    ($expr:expr) => {
        match $expr {
            Ok(value) => Ok(value),
            Err(e) => {
                let error_response = ErrorResponse::from_app_error(e);
                Err(serde_json::to_string(&error_response)
                    .unwrap_or_else(|_| "Internal error".to_string()))
            }
        }
    };
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_not_found_error() {
        let error = ErrorResponse::from_app_error(AppError::NotFound);
        assert_eq!(error.error_type, ErrorType::NotFound);
        assert_eq!(error.message, "Resource not found");
    }
    
    #[test]
    fn test_validation_error() {
        let error = ErrorResponse::validation("Invalid input".to_string());
        assert_eq!(error.error_type, ErrorType::Validation);
        assert_eq!(error.message, "Invalid input");
    }
    
    #[test]
    fn test_serialization() {
        let error = ErrorResponse::not_found("Anime");
        let json = serde_json::to_string(&error).unwrap();
        assert!(json.contains("not_found"));
        assert!(json.contains("Anime not found"));
    }
}

--- FILE: src-tauri\src\application\mod.rs ---
// src-tauri/src/application/mod.rs
//
// Application Layer - Phase 4
//
// ARCHITECTURE:
// - This layer sits ABOVE the sealed foundation
// - It provides the boundary between UI (Tauri) and Domain (Services)
// - It never modifies sealed components
// - It translates between DTOs and domain entities

pub mod commands;
pub mod dto;
pub mod state;

pub use commands::*;
pub use dto::*;
pub use state::AppState;


--- FILE: src-tauri\src\application\state.rs ---
// src-tauri/src/application/state.rs
// CORRECTED VERSION

use std::sync::Arc;

use crate::events::EventBus;
use crate::services::{
    AnimeService, EpisodeService, ExternalIntegrationService, FileService, PlaybackService,
    StatisticsService, SubtitleService,
};

/// Application state managed by Tauri.
/// All fields are Arc-wrapped for thread-safe sharing across commands.
/// Services are initialized in main.rs and passed here.
pub struct AppState {
    pub event_bus: Arc<EventBus>,
    pub anime_service: Arc<AnimeService>,
    pub episode_service: Arc<EpisodeService>,
    pub file_service: Arc<FileService>,
    pub playback_service: Arc<PlaybackService>,
    pub statistics_service: Arc<StatisticsService>,
    pub external_integration_service: Arc<ExternalIntegrationService>,
    pub subtitle_service: Arc<SubtitleService>,
}


--- FILE: src-tauri\src\db\connection.rs ---
// src-tauri/src/db/connection.rs
//
// Database connection management
//
// PRINCIPLES:
// - Explicit connection pooling
// - No hidden connection creation
// - Clear error propagation
// - Thread-safe access

use r2d2::{Pool, PooledConnection};
use r2d2_sqlite::SqliteConnectionManager;
use rusqlite::Connection;
use std::path::PathBuf;

use crate::error::{AppError, AppResult};

/// Type alias for connection pool
pub type ConnectionPool = Pool<SqliteConnectionManager>;

/// Type alias for a pooled connection
pub type PooledConn = PooledConnection<SqliteConnectionManager>;

/// Get the database file path
///
/// Database is stored in the application data directory.
/// Path structure: {APP_DATA}/animehub/animehub.db
pub fn get_database_path() -> AppResult<PathBuf> {
    let app_data_dir = dirs::data_dir()
        .ok_or_else(|| AppError::Other("Could not determine app data directory".to_string()))?;

    let animehub_dir = app_data_dir.join("animehub");

    // Ensure directory exists
    std::fs::create_dir_all(&animehub_dir).map_err(|e| AppError::Io(e))?;

    Ok(animehub_dir.join("animehub.db"))
}

/// Create a connection pool
///
/// Pool configuration:
/// - Max 15 connections (reasonable for desktop app)
/// - SQLite in WAL mode for better concurrency
/// - Foreign keys enabled
/// - Busy timeout set to avoid immediate errors
pub fn create_connection_pool() -> AppResult<ConnectionPool> {
    let db_path = get_database_path()?;

    let manager = SqliteConnectionManager::file(&db_path).with_init(|conn| {
        // Enable foreign key support (not default in SQLite)
        conn.execute_batch(
            "PRAGMA foreign_keys = ON;
                 PRAGMA journal_mode = WAL;
                 PRAGMA synchronous = NORMAL;
                 PRAGMA busy_timeout = 5000;",
        )?;
        Ok(())
    });

    let pool = Pool::builder()
        .max_size(15)
        .build(manager)
        .map_err(|e| AppError::Other(format!("Failed to create connection pool: {}", e)))?;

    Ok(pool)
}

/// Get a connection from the pool
///
/// This is a convenience wrapper that provides better error messages.
pub fn get_connection(pool: &ConnectionPool) -> AppResult<PooledConn> {
    pool.get()
        .map_err(|e| AppError::Other(format!("Failed to get database connection: {}", e)))
}

/// Create a standalone connection (for testing)
///
/// This creates an in-memory database, useful for unit tests.
pub fn create_test_connection() -> AppResult<Connection> {
    let conn = Connection::open_in_memory().map_err(AppError::Database)?;

    // Enable foreign keys
    conn.execute_batch("PRAGMA foreign_keys = ON;")
        .map_err(AppError::Database)?;

    Ok(conn)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_database_path_creation() {
        let path = get_database_path().unwrap();
        assert!(path.ends_with("animehub/animehub.db"));
    }

    #[test]
    fn test_connection_pool_creation() {
        // This will create actual database file in app data
        let pool = create_connection_pool().unwrap();
        let conn = get_connection(&pool).unwrap();

        // Verify foreign keys are enabled
        let fk_enabled: i32 = conn
            .query_row("PRAGMA foreign_keys", [], |row| row.get(0))
            .unwrap();
        assert_eq!(fk_enabled, 1);
    }

    #[test]
    fn test_test_connection() {
        let conn = create_test_connection().unwrap();

        // Verify it's a working connection
        let result: i32 = conn
            .query_row("SELECT 1 + 1", [], |row| row.get(0))
            .unwrap();
        assert_eq!(result, 2);

        // Verify foreign keys are enabled
        let fk_enabled: i32 = conn
            .query_row("PRAGMA foreign_keys", [], |row| row.get(0))
            .unwrap();
        assert_eq!(fk_enabled, 1);
    }
}


--- FILE: src-tauri\src\db\migrations.rs ---
// src-tauri/src/db/migrations.rs
//
// Database schema initialization and migrations
//
// PRINCIPLES:
// - Explicit schema versions
// - No automatic migrations
// - Clear error messages
// - Idempotent operations

use crate::error::{AppError, AppResult};
use rusqlite::Connection;

/// Current schema version
/// Increment this when adding migrations
const CURRENT_SCHEMA_VERSION: i32 = 1;

/// Initialize the database schema
///
/// This function:
/// 1. Checks current schema version
/// 2. Applies necessary migrations
/// 3. Updates version tracking
///
/// Safe to call multiple times (idempotent).
pub fn initialize_database(conn: &Connection) -> AppResult<()> {
    let current_version = get_schema_version(conn)?;

    if current_version == 0 {
        // Fresh database - apply initial schema
        apply_initial_schema(conn)?;
        set_schema_version(conn, 1)?;
    } else if current_version < CURRENT_SCHEMA_VERSION {
        // Future: apply incremental migrations here
        // For now, we only have version 1
        return Err(AppError::Other(format!(
            "Schema version {} is outdated. Expected {}. Manual migration required.",
            current_version, CURRENT_SCHEMA_VERSION
        )));
    } else if current_version > CURRENT_SCHEMA_VERSION {
        return Err(AppError::Other(format!(
            "Schema version {} is newer than supported {}. Update the application.",
            current_version, CURRENT_SCHEMA_VERSION
        )));
    }

    Ok(())
}

/// Get current schema version
/// Returns 0 if schema_version table doesn't exist (fresh database)
fn get_schema_version(conn: &Connection) -> AppResult<i32> {
    // Check if schema_version table exists
    let table_exists: bool = conn
        .query_row(
            "SELECT EXISTS(SELECT 1 FROM sqlite_master WHERE type='table' AND name='schema_version')",
            [],
            |row| row.get(0)
        )
        .map_err(AppError::Database)?;

    if !table_exists {
        return Ok(0);
    }

    // Get the highest version number
    let version: Option<i32> = conn
        .query_row("SELECT MAX(version) FROM schema_version", [], |row| {
            row.get(0)
        })
        .map_err(AppError::Database)?;

    Ok(version.unwrap_or(0))
}

/// Set schema version
fn set_schema_version(conn: &Connection, version: i32) -> AppResult<()> {
    conn.execute(
        "INSERT OR IGNORE INTO schema_version (version, applied_at) VALUES (?1, datetime('now'))",
        [version],
    )
    .map_err(AppError::Database)?;

    Ok(())
}

/// Apply initial schema (version 1)
///
/// This includes all tables defined in schema.sql
fn apply_initial_schema(conn: &Connection) -> AppResult<()> {
    // Read schema from embedded file
    let schema = include_str!("../../schema.sql");

    // Execute as batch
    conn.execute_batch(schema)
        .map_err(|e| AppError::Other(format!("Failed to apply initial schema: {}", e)))?;

    Ok(())
}

/// Verify database integrity
///
/// Runs SQLite's integrity check. Should be called periodically.
pub fn verify_database_integrity(conn: &Connection) -> AppResult<()> {
    let result: String = conn
        .query_row("PRAGMA integrity_check", [], |row| row.get(0))
        .map_err(AppError::Database)?;

    if result != "ok" {
        return Err(AppError::Other(format!(
            "Database integrity check failed: {}",
            result
        )));
    }

    Ok(())
}

/// Get database statistics
///
/// Returns useful info for debugging and monitoring
pub fn get_database_stats(conn: &Connection) -> AppResult<DatabaseStats> {
    let page_count: i64 = conn
        .query_row("PRAGMA page_count", [], |row| row.get(0))
        .map_err(AppError::Database)?;

    let page_size: i64 = conn
        .query_row("PRAGMA page_size", [], |row| row.get(0))
        .map_err(AppError::Database)?;

    let size_bytes = page_count * page_size;

    // Get row counts for main tables
    let anime_count: i64 = conn
        .query_row("SELECT COUNT(*) FROM anime", [], |row| row.get(0))
        .unwrap_or(0);

    let episode_count: i64 = conn
        .query_row("SELECT COUNT(*) FROM episodes", [], |row| row.get(0))
        .unwrap_or(0);

    let file_count: i64 = conn
        .query_row("SELECT COUNT(*) FROM files", [], |row| row.get(0))
        .unwrap_or(0);

    Ok(DatabaseStats {
        size_bytes,
        page_count,
        page_size,
        anime_count,
        episode_count,
        file_count,
    })
}

/// Database statistics
#[derive(Debug)]
pub struct DatabaseStats {
    pub size_bytes: i64,
    pub page_count: i64,
    pub page_size: i64,
    pub anime_count: i64,
    pub episode_count: i64,
    pub file_count: i64,
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::db::connection::create_test_connection;

    #[test]
    fn test_initialize_fresh_database() {
        let conn = create_test_connection().unwrap();

        // Should be version 0 initially
        let version = get_schema_version(&conn).unwrap();
        assert_eq!(version, 0);

        // Initialize
        initialize_database(&conn).unwrap();

        // Should now be version 1
        let version = get_schema_version(&conn).unwrap();
        assert_eq!(version, 1);

        // Verify tables exist
        let table_count: i64 = conn
            .query_row(
                "SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'",
                [],
                |row| row.get(0)
            )
            .unwrap();

        assert!(
            table_count > 10,
            "Expected at least 10 tables, got {}",
            table_count
        );
    }

    #[test]
    fn test_initialize_idempotent() {
        let conn = create_test_connection().unwrap();

        // Initialize twice
        initialize_database(&conn).unwrap();
        initialize_database(&conn).unwrap();

        // Should still be version 1
        let version = get_schema_version(&conn).unwrap();
        assert_eq!(version, 1);
    }

    #[test]
    fn test_foreign_keys_enabled() {
        let conn = create_test_connection().unwrap();
        initialize_database(&conn).unwrap();

        // Try to insert episode without anime (should fail)
        let result = conn.execute(
            "INSERT INTO episodes (id, anime_id, numero_tipo, numero_valor, progresso_atual, estado, criado_em, atualizado_em)
             VALUES ('test-ep', 'nonexistent-anime', 'regular', '1', 0, 'nao_visto', datetime('now'), datetime('now'))",
            []
        );

        assert!(
            result.is_err(),
            "Foreign key constraint should have been violated"
        );
    }

    #[test]
    fn test_database_stats() {
        let conn = create_test_connection().unwrap();
        initialize_database(&conn).unwrap();

        let stats = get_database_stats(&conn).unwrap();

        assert!(stats.size_bytes > 0);
        assert_eq!(stats.anime_count, 0);
        assert_eq!(stats.episode_count, 0);
        assert_eq!(stats.file_count, 0);
    }

    #[test]
    fn test_integrity_check() {
        let conn = create_test_connection().unwrap();
        initialize_database(&conn).unwrap();

        // Fresh database should pass integrity check
        verify_database_integrity(&conn).unwrap();
    }
}


--- FILE: src-tauri\src\db\mod.rs ---
// src-tauri/src/db/mod.rs
//
// Database module
//
// Provides:
// - Connection pooling
// - Schema migrations
// - Database utilities

pub mod connection;
pub mod migrations;

pub use connection::{
    create_connection_pool, get_connection, get_database_path, ConnectionPool, PooledConn,
};

pub use migrations::{
    get_database_stats, initialize_database, verify_database_integrity, DatabaseStats,
};


--- FILE: src-tauri\src\domain\anime\entity.rs ---
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

/// Represents a Japanese anime work (TV, Movie, OVA, Special)
/// This is the root entity for all anime-related data
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Anime {
    /// Internal immutable identifier
    pub id: Uuid,

    /// Primary title (usually Japanese)
    pub titulo_principal: String,

    /// Alternative titles (romaji, english, synonyms)
    pub titulos_alternativos: Vec<String>,

    /// Type of anime work
    pub tipo: AnimeType,

    /// Current status
    pub status: AnimeStatus,

    /// Total number of episodes (if known)
    pub total_episodios: Option<u32>,

    /// Start date (if known)
    pub data_inicio: Option<DateTime<Utc>>,

    /// End date (if known)
    pub data_fim: Option<DateTime<Utc>>,

    /// Free-form metadata (genres, studio, etc.)
    /// Stored as JSON internally
    pub metadados_livres: serde_json::Value,

    /// Creation timestamp
    pub criado_em: DateTime<Utc>,

    /// Last update timestamp
    pub atualizado_em: DateTime<Utc>,
}

/// Type of anime work
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "UPPERCASE")]
pub enum AnimeType {
    TV,
    Movie,
    OVA,
    Special,
}

/// Current status of the anime
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum AnimeStatus {
    EmExibicao,
    Finalizado,
    Cancelado,
}

impl Anime {
    /// Create a new Anime entity
    /// This is the only way to construct a valid Anime
    pub fn new(titulo_principal: String, tipo: AnimeType) -> Self {
        let now = Utc::now();
        Self {
            id: Uuid::new_v4(),
            titulo_principal,
            titulos_alternativos: Vec::new(),
            tipo,
            status: AnimeStatus::EmExibicao,
            total_episodios: None,
            data_inicio: None,
            data_fim: None,
            metadados_livres: serde_json::Value::Object(serde_json::Map::new()),
            criado_em: now,
            atualizado_em: now,
        }
    }

    /// Update metadata
    /// This preserves the creation timestamp and updates the modification timestamp
    pub fn update_metadata(
        &mut self,
        titulo_principal: Option<String>,
        titulos_alternativos: Option<Vec<String>>,
        tipo: Option<AnimeType>,
        status: Option<AnimeStatus>,
        total_episodios: Option<Option<u32>>,
        data_inicio: Option<Option<DateTime<Utc>>>,
        data_fim: Option<Option<DateTime<Utc>>>,
        metadados_livres: Option<serde_json::Value>,
    ) {
        if let Some(titulo) = titulo_principal {
            self.titulo_principal = titulo;
        }
        if let Some(titulos) = titulos_alternativos {
            self.titulos_alternativos = titulos;
        }
        if let Some(t) = tipo {
            self.tipo = t;
        }
        if let Some(s) = status {
            self.status = s;
        }
        if let Some(total) = total_episodios {
            self.total_episodios = total;
        }
        if let Some(inicio) = data_inicio {
            self.data_inicio = inicio;
        }
        if let Some(fim) = data_fim {
            self.data_fim = fim;
        }
        if let Some(meta) = metadados_livres {
            self.metadados_livres = meta;
        }

        self.atualizado_em = Utc::now();
    }
}

impl std::fmt::Display for AnimeType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            AnimeType::TV => write!(f, "TV"),
            AnimeType::Movie => write!(f, "Movie"),
            AnimeType::OVA => write!(f, "OVA"),
            AnimeType::Special => write!(f, "Special"),
        }
    }
}

impl std::fmt::Display for AnimeStatus {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            AnimeStatus::EmExibicao => write!(f, "em_exibicao"),
            AnimeStatus::Finalizado => write!(f, "finalizado"),
            AnimeStatus::Cancelado => write!(f, "cancelado"),
        }
    }
}


--- FILE: src-tauri\src\domain\anime\invariants.rs ---
use super::entity::Anime;
use crate::domain::{DomainError, DomainResult};

/// Validates all Anime invariants
/// These are the absolute rules that must hold for an Anime to be valid
pub fn validate_anime(anime: &Anime) -> DomainResult<()> {
    validate_titulo_principal(&anime.titulo_principal)?;
    validate_dates(anime)?;
    Ok(())
}

/// Titulo principal cannot be empty
fn validate_titulo_principal(titulo: &str) -> DomainResult<()> {
    if titulo.trim().is_empty() {
        return Err(DomainError::InvariantViolation(
            "Anime title cannot be empty".to_string(),
        ));
    }
    Ok(())
}

/// If both dates are present, start must be before or equal to end
fn validate_dates(anime: &Anime) -> DomainResult<()> {
    if let (Some(inicio), Some(fim)) = (anime.data_inicio, anime.data_fim) {
        if inicio > fim {
            return Err(DomainError::InvariantViolation(format!(
                "Start date {:?} cannot be after end date {:?}",
                inicio, fim
            )));
        }
    }
    Ok(())
}

/// Invariants that must hold true for Anime domain:
///
/// 1. Anime can exist without episodes
/// 2. Anime can exist without files
/// 3. Anime can exist without external references
/// 4. Identity (UUID) is immutable
/// 5. Duplicates are allowed until explicit resolution
/// 6. Title cannot be empty
/// 7. If both dates exist, start <= end
/// 8. Created timestamp never changes
/// 9. Updated timestamp reflects last modification

#[cfg(test)]
mod tests {
    use super::*;
    use crate::domain::anime::{AnimeStatus, AnimeType};

    #[test]
    fn test_valid_anime() {
        let anime = Anime::new("Steins;Gate".to_string(), AnimeType::TV);
        assert!(validate_anime(&anime).is_ok());
    }

    #[test]
    fn test_empty_title_fails() {
        let anime = Anime::new("   ".to_string(), AnimeType::TV);
        assert!(validate_anime(&anime).is_err());
    }
}


--- FILE: src-tauri\src\domain\anime\mod.rs ---
pub mod entity;
pub mod invariants;

pub use entity::{Anime, AnimeStatus, AnimeType};
pub use invariants::validate_anime;


--- FILE: src-tauri\src\domain\anime_alias.rs ---
// src-tauri/src/domain/anime_alias.rs
//
// Anime Alias Entity
//
// Tracks merge history when duplicate animes are resolved
// Preserves historical relationships

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

use crate::domain::{DomainError, DomainResult};

/// Represents an alias relationship from anime merge
///
/// CRITICAL INVARIANTS:
/// - Never deleted (preserves history)
/// - One anime becomes "principal", other becomes "alias"
/// - Self-referential aliases are forbidden
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnimeAlias {
    /// Internal identifier
    pub id: Uuid,

    /// The principal (surviving) anime
    pub anime_principal_id: Uuid,

    /// The alias (merged into principal) anime
    pub anime_alias_id: Uuid,

    /// When this merge occurred
    pub criado_em: DateTime<Utc>,
}

impl AnimeAlias {
    /// Create a new anime alias relationship
    pub fn new(anime_principal_id: Uuid, anime_alias_id: Uuid) -> Result<Self, String> {
        if anime_principal_id == anime_alias_id {
            return Err("Anime cannot be an alias of itself".to_string());
        }

        Ok(Self {
            id: Uuid::new_v4(),
            anime_principal_id,
            anime_alias_id,
            criado_em: Utc::now(),
        })
    }
}

/// Validates AnimeAlias invariants
pub fn validate_anime_alias(alias: &AnimeAlias) -> DomainResult<()> {
    if alias.anime_principal_id == alias.anime_alias_id {
        return Err(DomainError::InvariantViolation(
            "Anime cannot be an alias of itself".to_string(),
        ));
    }

    Ok(())
}


--- FILE: src-tauri\src\domain\collection\entity.rs ---
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

/// Represents a user-defined collection of anime
/// Collections are purely organizational and do not affect anime state
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Collection {
    /// Internal immutable identifier
    pub id: Uuid,

    /// Collection name
    pub nome: String,

    /// Optional description
    pub descricao: Option<String>,

    /// Creation timestamp
    pub criado_em: DateTime<Utc>,
}

impl Collection {
    /// Create a new Collection
    pub fn new(nome: String, descricao: Option<String>) -> Self {
        Self {
            id: Uuid::new_v4(),
            nome,
            descricao,
            criado_em: Utc::now(),
        }
    }

    /// Update collection metadata
    pub fn update(&mut self, nome: Option<String>, descricao: Option<Option<String>>) {
        if let Some(n) = nome {
            self.nome = n;
        }
        if let Some(d) = descricao {
            self.descricao = d;
        }
    }
}

impl std::fmt::Display for Collection {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.nome)
    }
}


--- FILE: src-tauri\src\domain\collection\mod.rs ---
//! Critical Collection Invariants:
//!
//! 1. Collections do NOT affect anime state
//! 2. Collections do NOT affect progress
//! 3. Collections are purely organizational
//! 4. Anime can belong to multiple collections
//! 5. Deleting a collection does NOT delete anime
//! 6. Collection name cannot be empty

pub mod entity;

pub use entity::Collection;

use crate::domain::{DomainError, DomainResult};

/// Validates Collection invariants
pub fn validate_collection(collection: &Collection) -> DomainResult<()> {
    if collection.nome.trim().is_empty() {
        return Err(DomainError::InvariantViolation(
            "Collection name cannot be empty".to_string(),
        ));
    }
    Ok(())
}


--- FILE: src-tauri\src\domain\episode\entity.rs ---
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

/// Represents a single episode belonging to an Anime
/// Episodes are the unit of viewing progress
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Episode {
    /// Internal immutable identifier
    pub id: Uuid,

    /// Reference to parent Anime (REQUIRED)
    pub anime_id: Uuid,

    /// Episode number (regular or special)
    pub numero: EpisodeNumber,

    /// Episode title (optional)
    pub titulo: Option<String>,

    /// Expected duration in seconds (optional)
    pub duracao_esperada: Option<u64>,

    /// Current playback progress in seconds
    pub progresso_atual: u64,

    /// Viewing state
    pub estado: EpisodeState,

    /// Creation timestamp
    pub criado_em: DateTime<Utc>,

    /// Last update timestamp
    pub atualizado_em: DateTime<Utc>,
}

/// Episode number can be regular (1, 2, 3...) or special (OVA, Special)
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum EpisodeNumber {
    Regular { numero: u32 },
    Special { label: String },
}

/// Current viewing state of an episode
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum EpisodeState {
    NaoVisto,
    EmProgresso,
    Concluido,
}

impl Episode {
    /// Create a new Episode
    /// anime_id MUST be valid (checked by caller)
    pub fn new(anime_id: Uuid, numero: EpisodeNumber) -> Self {
        let now = Utc::now();
        Self {
            id: Uuid::new_v4(),
            anime_id,
            numero,
            titulo: None,
            duracao_esperada: None,
            progresso_atual: 0,
            estado: EpisodeState::NaoVisto,
            criado_em: now,
            atualizado_em: now,
        }
    }

    /// Update episode metadata
    pub fn update_metadata(
        &mut self,
        titulo: Option<String>,
        duracao_esperada: Option<Option<u64>>,
    ) {
        if let Some(t) = titulo {
            self.titulo = Some(t);
        }
        if let Some(d) = duracao_esperada {
            self.duracao_esperada = d;
        }
        self.atualizado_em = Utc::now();
    }

    /// Update progress
    /// Returns error if progress violates invariants
    pub fn update_progress(&mut self, progresso: u64) -> Result<(), String> {
        // Progress cannot exceed duration (if known)
        if let Some(duracao) = self.duracao_esperada {
            if progresso > duracao {
                return Err(format!(
                    "Progress {} exceeds duration {}",
                    progresso, duracao
                ));
            }
        }

        // Progress should not decrease (except explicit reset)
        if progresso < self.progresso_atual && progresso != 0 {
            // Allow reset to 0, but not arbitrary decreases
            return Err(format!(
                "Progress cannot decrease from {} to {} (use reset if intentional)",
                self.progresso_atual, progresso
            ));
        }

        self.progresso_atual = progresso;

        // Update state based on progress
        self.estado = if progresso == 0 {
            EpisodeState::NaoVisto
        } else if let Some(duracao) = self.duracao_esperada {
            if progresso >= (duracao * 90 / 100) {
                EpisodeState::Concluido
            } else {
                EpisodeState::EmProgresso
            }
        } else {
            EpisodeState::EmProgresso
        };

        self.atualizado_em = Utc::now();
        Ok(())
    }

    /// Mark as completed
    pub fn mark_completed(&mut self) {
        self.estado = EpisodeState::Concluido;
        if let Some(duracao) = self.duracao_esperada {
            self.progresso_atual = duracao;
        }
        self.atualizado_em = Utc::now();
    }

    /// Reset progress
    pub fn reset_progress(&mut self) {
        self.progresso_atual = 0;
        self.estado = EpisodeState::NaoVisto;
        self.atualizado_em = Utc::now();
    }
}

impl EpisodeNumber {
    pub fn regular(numero: u32) -> Self {
        Self::Regular { numero }
    }

    pub fn special(label: String) -> Self {
        Self::Special { label }
    }
}

impl std::fmt::Display for EpisodeNumber {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            EpisodeNumber::Regular { numero } => write!(f, "{}", numero),
            EpisodeNumber::Special { label } => write!(f, "{}", label),
        }
    }
}

impl std::fmt::Display for EpisodeState {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            EpisodeState::NaoVisto => write!(f, "nao_visto"),
            EpisodeState::EmProgresso => write!(f, "em_progresso"),
            EpisodeState::Concluido => write!(f, "concluido"),
        }
    }
}


--- FILE: src-tauri\src\domain\episode\invariants.rs ---
use super::entity::Episode;
use crate::domain::{DomainError, DomainResult};

/// Validates all Episode invariants
pub fn validate_episode(episode: &Episode) -> DomainResult<()> {
    validate_progress(episode)?;
    Ok(())
}

/// Progress invariants:
/// 1. Progress cannot be negative (enforced by u64)
/// 2. Progress cannot exceed duration (if known)
fn validate_progress(episode: &Episode) -> DomainResult<()> {
    if let Some(duracao) = episode.duracao_esperada {
        if episode.progresso_atual > duracao {
            return Err(DomainError::ProgressExceedsDuration {
                progress: episode.progresso_atual,
                duration: duracao,
            });
        }
    }
    Ok(())
}

/// Critical Episode Invariants:
///
/// 1. Episode MUST belong to exactly one Anime (anime_id required)
/// 2. Episode can exist without a file
/// 3. Episode assumes one practical version (no implicit multi-version)
/// 4. Progress never decreases automatically
/// 5. Progress never exceeds duration (if known)
/// 6. State transitions are explicit
/// 7. Episode ID is immutable
/// 8. anime_id is immutable (episode cannot change parent)

#[cfg(test)]
mod tests {
    use super::*;
    use crate::domain::episode::{Episode, EpisodeNumber};
    use uuid::Uuid;

    #[test]
    fn test_valid_episode() {
        let anime_id = Uuid::new_v4();
        let episode = Episode::new(anime_id, EpisodeNumber::regular(1));
        assert!(validate_episode(&episode).is_ok());
    }

    #[test]
    fn test_progress_within_duration() {
        let anime_id = Uuid::new_v4();
        let mut episode = Episode::new(anime_id, EpisodeNumber::regular(1));
        episode.duracao_esperada = Some(1440); // 24 minutes
        episode.progresso_atual = 1200; // 20 minutes
        assert!(validate_episode(&episode).is_ok());
    }

    #[test]
    fn test_progress_exceeds_duration_fails() {
        let anime_id = Uuid::new_v4();
        let mut episode = Episode::new(anime_id, EpisodeNumber::regular(1));
        episode.duracao_esperada = Some(1440);
        episode.progresso_atual = 1500; // Exceeds duration
        assert!(validate_episode(&episode).is_err());
    }
}


--- FILE: src-tauri\src\domain\episode\mod.rs ---
pub mod entity;
pub mod invariants;

pub use entity::{Episode, EpisodeNumber, EpisodeState};
pub use invariants::validate_episode;


--- FILE: src-tauri\src\domain\external_reference.rs ---
// src-tauri/src/domain/external_reference.rs
//
// External Reference Entity
//
// Links local anime to external services (AniList, etc.)
// These are auxiliary references, never authoritative.

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

use crate::domain::{DomainError, DomainResult};

/// Represents a link to an external service
///
/// CRITICAL INVARIANTS:
/// - Never replaces local data
/// - Can be removed without structural impact
/// - Source never becomes authoritative
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExternalReference {
    /// Internal identifier
    pub id: Uuid,

    /// Local anime this references
    pub anime_id: Uuid,

    /// External service name (e.g., "AniList")
    pub fonte: String,

    /// ID in the external service
    pub external_id: String,

    /// When this reference was created
    pub criado_em: DateTime<Utc>,
}

impl ExternalReference {
    /// Create a new external reference
    pub fn new(anime_id: Uuid, fonte: String, external_id: String) -> Self {
        Self {
            id: Uuid::new_v4(),
            anime_id,
            fonte,
            external_id,
            criado_em: Utc::now(),
        }
    }
}

/// Validates ExternalReference invariants
pub fn validate_external_reference(reference: &ExternalReference) -> DomainResult<()> {
    if reference.fonte.trim().is_empty() {
        return Err(DomainError::InvariantViolation(
            "External reference source cannot be empty".to_string(),
        ));
    }

    if reference.external_id.trim().is_empty() {
        return Err(DomainError::InvariantViolation(
            "External reference ID cannot be empty".to_string(),
        ));
    }

    Ok(())
}


--- FILE: src-tauri\src\domain\file\entity.rs ---
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use uuid::Uuid;

/// Represents a physical file on disk
/// Files are observable entities, not controlled by the system
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct File {
    /// Internal immutable identifier
    pub id: Uuid,

    /// Absolute path to the file
    pub caminho_absoluto: PathBuf,

    /// Type of file
    pub tipo: FileType,

    /// File size in bytes
    pub tamanho: u64,

    /// SHA256 hash (optional, computed on demand)
    pub hash: Option<String>,

    /// Last modification timestamp from filesystem
    pub data_modificacao: DateTime<Utc>,

    /// How this file was discovered
    pub origem: FileOrigin,

    /// Creation timestamp in our database
    pub criado_em: DateTime<Utc>,

    /// Last update timestamp in our database
    pub atualizado_em: DateTime<Utc>,
}

/// Type of file based on its purpose
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum FileType {
    Video,
    Legenda,
    Imagem,
    Outro,
}

/// How the file was discovered or added
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum FileOrigin {
    /// Discovered via directory scan
    Scan,

    /// Explicitly imported by user
    Importacao,

    /// Manually added
    Manual,
}

impl File {
    /// Create a new File entity
    pub fn new(
        caminho_absoluto: PathBuf,
        tipo: FileType,
        tamanho: u64,
        data_modificacao: DateTime<Utc>,
        origem: FileOrigin,
    ) -> Self {
        let now = Utc::now();
        Self {
            id: Uuid::new_v4(),
            caminho_absoluto,
            tipo,
            tamanho,
            hash: None,
            data_modificacao,
            origem,
            criado_em: now,
            atualizado_em: now,
        }
    }

    /// Update file metadata (size, modification date)
    /// This is called when the file changes on disk
    pub fn update_metadata(&mut self, tamanho: u64, data_modificacao: DateTime<Utc>) {
        self.tamanho = tamanho;
        self.data_modificacao = data_modificacao;
        // Hash is invalidated when file changes
        self.hash = None;
        self.atualizado_em = Utc::now();
    }

    /// Set the hash after computation
    pub fn set_hash(&mut self, hash: String) {
        self.hash = Some(hash);
        self.atualizado_em = Utc::now();
    }

    /// Check if file likely changed based on metadata
    pub fn has_changed(&self, tamanho: u64, data_modificacao: DateTime<Utc>) -> bool {
        self.tamanho != tamanho || self.data_modificacao != data_modificacao
    }
}

impl FileType {
    /// Infer file type from extension
    pub fn from_extension(path: &PathBuf) -> Self {
        match path.extension().and_then(|e| e.to_str()) {
            Some("mkv") | Some("mp4") | Some("avi") | Some("webm") => FileType::Video,
            Some("srt") | Some("ass") | Some("vtt") => FileType::Legenda,
            Some("jpg") | Some("jpeg") | Some("png") | Some("webp") => FileType::Imagem,
            _ => FileType::Outro,
        }
    }
}

impl std::fmt::Display for FileType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            FileType::Video => write!(f, "video"),
            FileType::Legenda => write!(f, "legenda"),
            FileType::Imagem => write!(f, "imagem"),
            FileType::Outro => write!(f, "outro"),
        }
    }
}

impl std::fmt::Display for FileOrigin {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            FileOrigin::Scan => write!(f, "scan"),
            FileOrigin::Importacao => write!(f, "importacao"),
            FileOrigin::Manual => write!(f, "manual"),
        }
    }
}


--- FILE: src-tauri\src\domain\file\invariants.rs ---
use super::entity::File;
use crate::domain::{DomainError, DomainResult};

/// Validates all File invariants
pub fn validate_file(file: &File) -> DomainResult<()> {
    validate_path(file)?;
    Ok(())
}

/// Path must be absolute and non-empty
fn validate_path(file: &File) -> DomainResult<()> {
    if !file.caminho_absoluto.is_absolute() {
        return Err(DomainError::InvariantViolation(format!(
            "File path must be absolute: {:?}",
            file.caminho_absoluto
        )));
    }

    if file.caminho_absoluto.as_os_str().is_empty() {
        return Err(DomainError::InvariantViolation(
            "File path cannot be empty".to_string(),
        ));
    }

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::domain::file::{File, FileOrigin, FileType};
    use chrono::Utc;
    use std::path::PathBuf;

    #[test]
    fn test_valid_file() {
        // Solu√ß√£o multiplataforma: usa o diret√≥rio atual do sistema para garantir um path absoluto
        let mut path = std::env::current_dir().unwrap();
        path.push("episode1.mkv");

        let file = File::new(
            path,
            FileType::Video,
            1024 * 1024 * 500, // 500MB
            Utc::now(),
            FileOrigin::Scan,
        );
        assert!(validate_file(&file).is_ok());
    }

    #[test]
    fn test_relative_path_fails() {
        let file = File::new(
            PathBuf::from("relative/path/ep1.mkv"),
            FileType::Video,
            1024,
            Utc::now(),
            FileOrigin::Manual,
        );

        let result = validate_file(&file);
        assert!(result.is_err());

        if let Err(DomainError::InvariantViolation(msg)) = result {
            assert!(msg.contains("must be absolute"));
        } else {
            panic!("Expected InvariantViolation error");
        }
    }
}


--- FILE: src-tauri\src\domain\file\mod.rs ---
pub mod entity;
pub mod invariants;

pub use entity::{File, FileOrigin, FileType};
pub use invariants::validate_file;


--- FILE: src-tauri\src\domain\mod.rs ---
// src-tauri/src/domain/mod.rs
//
// Domain Root - The Single Source of Truth for Domain API
//
// This file MUST declare all domain modules and re-export their public API.
// All other modules import from `crate::domain::*`

// ============================================================================
// MODULE DECLARATIONS
// ============================================================================

pub mod anime;
pub mod anime_alias;
pub mod collection;
pub mod episode;
pub mod external_reference;
pub mod file;
pub mod resolution;
pub mod statistics;
pub mod subtitle;

// ============================================================================
// PUBLIC API RE-EXPORTS
// ============================================================================

// Anime Domain
pub use anime::{validate_anime, Anime, AnimeStatus, AnimeType};

// Episode Domain
pub use episode::{validate_episode, Episode, EpisodeNumber, EpisodeState};

// File Domain
pub use file::{validate_file, File, FileOrigin, FileType};

// Subtitle Domain
pub use subtitle::{
    validate_subtitle, Subtitle, SubtitleFormat, SubtitleTransformation, TransformationType,
};

// Collection Domain
pub use collection::{validate_collection, Collection};

// Statistics Domain (Derived Data)
pub use statistics::{AnimeStatistics, GlobalStatistics, StatisticsSnapshot, StatisticsType};

// External Reference
pub use external_reference::{validate_external_reference, ExternalReference};

// Anime Alias
pub use anime_alias::{validate_anime_alias, AnimeAlias};

// ============================================================================
// DOMAIN ERROR TYPES
// ============================================================================

use thiserror::Error;

/// Domain-level errors
/// These represent violations of business rules and invariants
#[derive(Debug, Error)]
pub enum DomainError {
    #[error("Invariant violation: {0}")]
    InvariantViolation(String),

    #[error("Progress {progress}s exceeds duration {duration}s")]
    ProgressExceedsDuration { progress: u64, duration: u64 },

    #[error("Invalid state transition: {0}")]
    InvalidStateTransition(String),

    #[error("Entity not found: {0}")]
    NotFound(String),
}

/// Domain result type
pub type DomainResult<T> = Result<T, DomainError>;


--- FILE: src-tauri\src\domain\models\statistics.rs ---
use serde::{Deserialize, Serialize};
use uuid::Uuid;
use std::collections::HashMap;
use std::str::FromStr;
use crate::shared::errors::{AppError, AppResult};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum StatisticsType {
    Global,
    Genre(String),
    Status(String),
    Year(i32),
}

impl std::fmt::Display for StatisticsType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Global => write!(f, "global"),
            Self::Genre(g) => write!(f, "genre:{}", g),
            Self::Status(s) => write!(f, "status:{}", s),
            Self::Year(y) => write!(f, "year:{}", y),
        }
    }
}

// Melhoria Arquitetural: L√≥gica de parsing extra√≠da do reposit√≥rio para o dom√≠nio
impl FromStr for StatisticsType {
    type Err = AppError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        if s == "global" {
            Ok(Self::Global)
        } else if let Some(genre) = s.strip_prefix("genre:") {
            Ok(Self::Genre(genre.to_string()))
        } else if let Some(status) = s.strip_prefix("status:") {
            Ok(Self::Status(status.to_string()))
        } else if let Some(year_str) = s.strip_prefix("year:") {
            let year = year_str.parse::<i32>()
                .map_err(|_| AppError::Validation("Invalid year format in statistics type".into()))?;
            Ok(Self::Year(year))
        } else {
            Err(AppError::Validation(format!("Unknown statistics type: {}", s)))
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StatisticsSnapshot {
    pub id: Uuid,
    pub tipo: StatisticsType,
    pub data: HashMap<String, f64>,
    pub captured_at: i64,
}

--- FILE: src-tauri\src\domain\resolution\mod.rs ---
// src-tauri/src/domain/resolution/mod.rs
//
// Resolution Domain - Phase 4
//
// This module contains value objects representing the outcome of file resolution.
// Resolution transforms detected files into domain intent without committing state.
//
// CRITICAL RULES:
// - All types are pure value objects (immutable)
// - No side effects
// - No persistence
// - No event emission (that's the service's job)
// - Deterministic: same input ‚Üí same output

pub mod value_objects;

pub use value_objects::{
    FileRole, ResolutionConfidence, ResolutionFailure, ResolutionFailureReason, ResolutionResult,
    ResolutionSource, ResolvedAnimeIntent, ResolvedEpisodeIntent, ResolvedEpisodeNumber,
    ResolvedFile,
};


--- FILE: src-tauri\src\domain\resolution\value_objects.rs ---
// src-tauri/src/domain/resolution/value_objects.rs
//
// Resolution Value Objects - Phase 4 (FINAL CORRECTED VERSION)
//
// PURPOSE:
// These value objects represent the semantic output of resolution.
// They are immutable, deterministic, and carry no operational metadata.
//
// CRITICAL INVARIANTS:
// - No timestamps in any value object
// - No random IDs in any value object
// - Fingerprints are deterministic and documented
// - All dead variants have been removed
//
// PHASE 4 CLOSURE CORRECTIONS:
// - Removed dead variants: Auxiliary, Range, FolderHierarchy, DatabaseMatch, Combined,
//   AmbiguousResolution, UnexpectedPathStructure
// - Added RepositoryError to ResolutionFailureReason
// - Documented fingerprint components for determinism verification

use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use uuid::Uuid;

// ============================================================================
// RESOLUTION RESULT
// ============================================================================

/// The outcome of attempting to resolve a file.
#[derive(Debug, Clone)]
pub enum ResolutionResult {
    /// File was successfully resolved
    Success(ResolvedFile),

    /// File resolution failed
    Failure(ResolutionFailure),
}

impl ResolutionResult {
    pub fn is_success(&self) -> bool {
        matches!(self, ResolutionResult::Success(_))
    }

    pub fn is_failure(&self) -> bool {
        matches!(self, ResolutionResult::Failure(_))
    }

    pub fn resolved_file(&self) -> Option<&ResolvedFile> {
        match self {
            ResolutionResult::Success(f) => Some(f),
            ResolutionResult::Failure(_) => None,
        }
    }

    pub fn failure(&self) -> Option<&ResolutionFailure> {
        match self {
            ResolutionResult::Success(_) => None,
            ResolutionResult::Failure(f) => Some(f),
        }
    }
}

// ============================================================================
// RESOLVED FILE (SUCCESSFUL RESOLUTION)
// ============================================================================

/// A file that has been successfully resolved to domain intent.
/// This represents knowledge about what the file is, not a mutation.
///
/// DETERMINISM: No timestamps. Identical input produces identical output.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ResolvedFile {
    /// The file ID from the File domain (already persisted by scan phase)
    pub file_id: Uuid,

    /// The absolute path of the file (for traceability)
    pub file_path: PathBuf,

    /// The role this file plays (video, subtitle, image)
    pub role: FileRole,

    /// The resolved anime intent (what anime this file belongs to)
    pub anime_intent: ResolvedAnimeIntent,

    /// The resolved episode intent (what episode this file represents)
    pub episode_intent: ResolvedEpisodeIntent,

    /// Confidence score of the resolution (0.0 to 1.0)
    pub confidence: ResolutionConfidence,
}

impl ResolvedFile {
    /// Creates a new ResolvedFile (deterministic, no timestamps)
    pub fn new(
        file_id: Uuid,
        file_path: PathBuf,
        role: FileRole,
        anime_intent: ResolvedAnimeIntent,
        episode_intent: ResolvedEpisodeIntent,
        confidence: ResolutionConfidence,
    ) -> Self {
        Self {
            file_id,
            file_path,
            role,
            anime_intent,
            episode_intent,
            confidence,
        }
    }

    /// Computes a deterministic fingerprint for idempotency checking.
    ///
    /// DETERMINISM COMPONENTS (documented for verification):
    /// - file_id: UUID of the file being resolved
    /// - anime_intent.title: lowercased for case-insensitive matching
    /// - episode_intent.number: string representation of episode number
    /// - role: string representation of file role
    ///
    /// NOTE: file_path is NOT included as the same file may be moved;
    /// file_id is the stable identifier.
    pub fn fingerprint(&self) -> ResolutionFingerprint {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        self.file_id.hash(&mut hasher);
        self.anime_intent.title.to_lowercase().hash(&mut hasher);
        self.episode_intent.number.to_string().hash(&mut hasher);
        self.role.to_string().hash(&mut hasher);
        ResolutionFingerprint(format!("{:016x}", hasher.finish()))
    }
}

// ============================================================================
// RESOLUTION FINGERPRINT
// ============================================================================

/// A deterministic fingerprint for a resolution result.
/// Used for idempotency checking and event ID derivation.
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct ResolutionFingerprint(String);

impl ResolutionFingerprint {
    /// Create a fingerprint from a raw hash string
    pub fn from_hash(hash: String) -> Self {
        Self(hash)
    }

    /// Get the hash string
    pub fn hash(&self) -> &str {
        &self.0
    }

    /// Convert to string for storage
    pub fn to_string(&self) -> String {
        self.0.clone()
    }
}

impl std::fmt::Display for ResolutionFingerprint {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.0)
    }
}

// ============================================================================
// FILE ROLE
// ============================================================================

/// The role a file plays in the context of an episode.
///
/// PHASE 4 CORRECTION: Removed `Auxiliary` variant (was never produced).
/// Files of type `Outro` fail resolution with UnsupportedFileType.
///
/// CANONICAL VARIANTS (exhaustive):
/// - Video: Primary video file
/// - Subtitle: Subtitle file
/// - Image: Cover image or thumbnail
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum FileRole {
    /// Primary video file for the episode
    Video,

    /// Subtitle file associated with the episode
    Subtitle,

    /// Cover image or thumbnail
    Image,
}

impl std::fmt::Display for FileRole {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            FileRole::Video => write!(f, "video"),
            FileRole::Subtitle => write!(f, "subtitle"),
            FileRole::Image => write!(f, "image"),
        }
    }
}

// ============================================================================
// RESOLVED ANIME INTENT
// ============================================================================

/// Represents the resolved intent for which anime a file belongs to.
/// This is knowledge, not a committed entity.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ResolvedAnimeIntent {
    /// The parsed/inferred anime title
    pub title: String,

    /// Alternative titles found during parsing (if any)
    pub alternative_titles: Vec<String>,

    /// If an existing anime was matched, its ID
    pub matched_anime_id: Option<Uuid>,

    /// The source of this resolution (filename or folder_name only)
    pub source: ResolutionSource,
}

impl ResolvedAnimeIntent {
    /// Creates a new anime intent from a parsed title
    pub fn from_parsed_title(title: String, source: ResolutionSource) -> Self {
        Self {
            title,
            alternative_titles: Vec::new(),
            matched_anime_id: None,
            source,
        }
    }

    /// Creates a new anime intent matched to an existing anime
    pub fn matched(anime_id: Uuid, title: String, source: ResolutionSource) -> Self {
        Self {
            title,
            alternative_titles: Vec::new(),
            matched_anime_id: Some(anime_id),
            source,
        }
    }
}

// ============================================================================
// RESOLVED EPISODE INTENT
// ============================================================================

/// Represents the resolved intent for which episode a file represents.
/// This is knowledge, not a committed entity.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ResolvedEpisodeIntent {
    /// The parsed episode number
    pub number: ResolvedEpisodeNumber,

    /// The parsed episode title (if found)
    pub title: Option<String>,

    /// If an existing episode was matched, its ID
    pub matched_episode_id: Option<Uuid>,

    /// The source of this resolution
    pub source: ResolutionSource,
}

impl ResolvedEpisodeIntent {
    /// Creates a new episode intent from a parsed number
    pub fn from_parsed_number(number: ResolvedEpisodeNumber, source: ResolutionSource) -> Self {
        Self {
            number,
            title: None,
            matched_episode_id: None,
            source,
        }
    }

    /// Creates a new episode intent matched to an existing episode
    pub fn matched(
        episode_id: Uuid,
        number: ResolvedEpisodeNumber,
        source: ResolutionSource,
    ) -> Self {
        Self {
            number,
            title: None,
            matched_episode_id: Some(episode_id),
            source,
        }
    }
}

/// Resolved episode number (regular or special only)
///
/// PHASE 4 CORRECTION: Removed `Range` variant (was never produced by parsing logic).
/// Batch/range files are not supported in Phase 4 resolution.
///
/// CANONICAL VARIANTS (exhaustive):
/// - Regular: Numbered episode (1, 2, 3, ...)
/// - Special: Special episode with label (OVA, OAD, etc.)
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum ResolvedEpisodeNumber {
    /// Regular numbered episode (1, 2, 3, ...)
    Regular { number: u32 },

    /// Special episode with a label (OVA, OAD, Special, etc.)
    Special { label: String },
}

impl std::fmt::Display for ResolvedEpisodeNumber {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ResolvedEpisodeNumber::Regular { number } => write!(f, "{}", number),
            ResolvedEpisodeNumber::Special { label } => write!(f, "{}", label),
        }
    }
}

// ============================================================================
// RESOLUTION SOURCE
// ============================================================================

/// Where the resolution information was extracted from.
/// Used for traceability and debugging.
///
/// PHASE 4 CORRECTION: Removed `FolderHierarchy`, `DatabaseMatch`, `Combined` variants.
/// - FolderHierarchy was never produced
/// - DatabaseMatch was never produced (matching returns Option<Uuid>, not source)
/// - Combined is replaced by explicit source tracking
///
/// CANONICAL VARIANTS (exhaustive):
/// - Filename: Parsed from the filename
/// - FolderName: Inferred from the parent folder name
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum ResolutionSource {
    /// Parsed from the filename
    Filename,

    /// Inferred from the parent folder name
    FolderName,
}

impl std::fmt::Display for ResolutionSource {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ResolutionSource::Filename => write!(f, "filename"),
            ResolutionSource::FolderName => write!(f, "folder_name"),
        }
    }
}

// ============================================================================
// RESOLUTION CONFIDENCE
// ============================================================================

/// Confidence score for a resolution.
/// Used to determine if resolution should proceed or fail.
#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct ResolutionConfidence {
    /// Score from 0.0 (no confidence) to 1.0 (absolute certainty)
    score: f64,
}

impl ResolutionConfidence {
    /// Minimum confidence threshold for a resolution to be considered valid
    pub const THRESHOLD: f64 = 0.6;

    /// Creates a new confidence score, clamped to [0.0, 1.0]
    pub fn new(score: f64) -> Self {
        Self {
            score: score.clamp(0.0, 1.0),
        }
    }

    /// Returns the raw score
    pub fn score(&self) -> f64 {
        self.score
    }

    /// Returns true if confidence meets the threshold
    pub fn meets_threshold(&self) -> bool {
        self.score >= Self::THRESHOLD
    }

    /// High confidence (>= 0.9)
    pub fn high() -> Self {
        Self::new(0.95)
    }

    /// Medium confidence (>= 0.7)
    pub fn medium() -> Self {
        Self::new(0.75)
    }

    /// Low confidence (>= 0.5)
    pub fn low() -> Self {
        Self::new(0.55)
    }

    /// No confidence
    pub fn none() -> Self {
        Self::new(0.0)
    }
}

impl PartialEq for ResolutionConfidence {
    fn eq(&self, other: &Self) -> bool {
        (self.score - other.score).abs() < f64::EPSILON
    }
}

impl std::fmt::Display for ResolutionConfidence {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{:.2}%", self.score * 100.0)
    }
}

// ============================================================================
// RESOLUTION FAILURE
// ============================================================================

/// Represents an explicit, structured resolution failure.
/// No timestamps - deterministic from input.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ResolutionFailure {
    /// The file ID that failed to resolve
    pub file_id: Uuid,

    /// The file path (for traceability)
    pub file_path: PathBuf,

    /// The structured reason for failure
    pub reason: ResolutionFailureReason,

    /// Human-readable description
    pub description: String,
}

impl ResolutionFailure {
    /// Creates a new resolution failure (deterministic, no timestamps)
    pub fn new(
        file_id: Uuid,
        file_path: PathBuf,
        reason: ResolutionFailureReason,
        description: String,
    ) -> Self {
        Self {
            file_id,
            file_path,
            reason,
            description,
        }
    }

    /// Computes a deterministic fingerprint for the failure.
    ///
    /// DETERMINISM COMPONENTS:
    /// - file_id: UUID of the file
    /// - reason: structured failure reason
    pub fn fingerprint(&self) -> ResolutionFingerprint {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        self.file_id.hash(&mut hasher);
        self.reason.to_string().hash(&mut hasher);
        ResolutionFingerprint(format!("fail:{:016x}", hasher.finish()))
    }
}

/// Structured reasons for resolution failure.
///
/// PHASE 4 CORRECTION: Removed `AmbiguousResolution` and `UnexpectedPathStructure` variants.
/// Added `RepositoryError` for explicit infrastructure failure handling.
///
/// CANONICAL VARIANTS (exhaustive):
/// - UnparsableFilename: Could not extract meaningful data from filename
/// - NoEpisodeNumber: Episode number could not be determined
/// - LowConfidence: Resolution confidence below threshold
/// - UnsupportedFileType: File type is not supported for resolution
/// - RepositoryError: Database or infrastructure error during resolution
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum ResolutionFailureReason {
    /// Could not extract meaningful data from filename
    UnparsableFilename,

    /// Episode number could not be determined
    NoEpisodeNumber,

    /// Resolution confidence below threshold
    LowConfidence,

    /// File type is not supported for resolution
    UnsupportedFileType,

    /// Database or infrastructure error during resolution
    RepositoryError,
}

impl std::fmt::Display for ResolutionFailureReason {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ResolutionFailureReason::UnparsableFilename => write!(f, "unparsable_filename"),
            ResolutionFailureReason::NoEpisodeNumber => write!(f, "no_episode_number"),
            ResolutionFailureReason::LowConfidence => write!(f, "low_confidence"),
            ResolutionFailureReason::UnsupportedFileType => write!(f, "unsupported_file_type"),
            ResolutionFailureReason::RepositoryError => write!(f, "repository_error"),
        }
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_file_role_has_exactly_three_variants() {
        // PROOF: FileRole has exactly 3 variants (Auxiliary removed)
        let roles = [FileRole::Video, FileRole::Subtitle, FileRole::Image];
        assert_eq!(roles.len(), 3);

        // Verify Display implementations
        assert_eq!(FileRole::Video.to_string(), "video");
        assert_eq!(FileRole::Subtitle.to_string(), "subtitle");
        assert_eq!(FileRole::Image.to_string(), "image");
    }

    #[test]
    fn test_resolution_source_has_exactly_two_variants() {
        // PROOF: ResolutionSource has exactly 2 variants (FolderHierarchy, DatabaseMatch, Combined removed)
        let sources = [ResolutionSource::Filename, ResolutionSource::FolderName];
        assert_eq!(sources.len(), 2);

        // Verify Display implementations
        assert_eq!(ResolutionSource::Filename.to_string(), "filename");
        assert_eq!(ResolutionSource::FolderName.to_string(), "folder_name");
    }

    #[test]
    fn test_episode_number_has_exactly_two_variants() {
        // PROOF: ResolvedEpisodeNumber has exactly 2 variants (Range removed)
        let regular = ResolvedEpisodeNumber::Regular { number: 1 };
        let special = ResolvedEpisodeNumber::Special { label: "OVA".to_string() };

        assert_eq!(regular.to_string(), "1");
        assert_eq!(special.to_string(), "OVA");
    }

    #[test]
    fn test_failure_reason_has_exactly_five_variants() {
        // PROOF: ResolutionFailureReason has exactly 5 variants
        // (AmbiguousResolution, UnexpectedPathStructure removed, RepositoryError added)
        let reasons = [
            ResolutionFailureReason::UnparsableFilename,
            ResolutionFailureReason::NoEpisodeNumber,
            ResolutionFailureReason::LowConfidence,
            ResolutionFailureReason::UnsupportedFileType,
            ResolutionFailureReason::RepositoryError,
        ];
        assert_eq!(reasons.len(), 5);
    }

    #[test]
    fn test_fingerprint_is_deterministic() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let resolved1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let resolved2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // PROOF: Identical input produces identical fingerprint
        assert_eq!(
            resolved1.fingerprint().to_string(),
            resolved2.fingerprint().to_string(),
            "Identical input MUST produce identical fingerprint"
        );
    }

    #[test]
    fn test_fingerprint_case_insensitive_title() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let resolved1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/file.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let resolved2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/file.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "TEST ANIME".to_string(),  // Different case
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // PROOF: Title comparison is case-insensitive
        assert_eq!(
            resolved1.fingerprint().to_string(),
            resolved2.fingerprint().to_string(),
            "Fingerprint MUST be case-insensitive for anime title"
        );
    }

    #[test]
    fn test_no_timestamp_in_resolved_file() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let resolved = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/file.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // PROOF: ResolvedFile has no timestamp field
        // This is verified by the struct definition - no resolved_at field exists
        // The test compiles only if no timestamp field is present
        let _ = resolved.file_id;
        let _ = resolved.file_path;
        let _ = resolved.role;
        let _ = resolved.anime_intent;
        let _ = resolved.episode_intent;
        let _ = resolved.confidence;
        // If resolved.resolved_at existed, this test would need to reference it
    }

    #[test]
    fn test_no_timestamp_in_resolution_failure() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let failure = ResolutionFailure::new(
            file_id,
            PathBuf::from("/test/unknown.bin"),
            ResolutionFailureReason::UnsupportedFileType,
            "Binary file not supported".to_string(),
        );

        // PROOF: ResolutionFailure has no timestamp field
        let _ = failure.file_id;
        let _ = failure.file_path;
        let _ = failure.reason;
        let _ = failure.description;
        // If failure.failed_at existed, this test would need to reference it
    }
}


--- FILE: src-tauri\src\domain\statistics\entity.rs ---
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

/// Represents a derived statistics snapshot
/// Statistics are NEVER a source of truth and can be recalculated
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StatisticsSnapshot {
    /// Snapshot identifier
    pub id: Uuid,

    /// Type of statistics
    pub tipo: StatisticsType,

    /// The actual data (stored as JSON for flexibility)
    pub valor: serde_json::Value,

    /// When this snapshot was generated
    pub gerado_em: DateTime<Utc>,
}

/// Types of statistics that can be tracked
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum StatisticsType {
    /// Global statistics across all anime
    Global,

    /// Statistics for a specific anime
    PorAnime { anime_id: Uuid },

    /// Statistics for a time period
    PorPeriodo {
        inicio: DateTime<Utc>,
        fim: DateTime<Utc>,
    },
}

impl StatisticsSnapshot {
    /// Create a new statistics snapshot
    pub fn new(tipo: StatisticsType, valor: serde_json::Value) -> Self {
        Self {
            id: Uuid::new_v4(),
            tipo,
            valor,
            gerado_em: Utc::now(),
        }
    }
}

/// Common global statistics structure
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GlobalStatistics {
    pub total_animes: u32,
    pub total_episodes: u32,
    pub episodes_assistidos: u32,
    pub tempo_total_assistido: u64, // in seconds
    pub animes_em_progresso: u32,
    pub animes_completos: u32,
}

/// Per-anime statistics structure
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnimeStatistics {
    pub anime_id: Uuid,
    pub total_episodes: u32,
    pub episodes_assistidos: u32,
    pub tempo_assistido: u64, // in seconds
    pub progresso_percentual: f32,
    pub ultimo_episodio_assistido: Option<Uuid>,
    pub data_ultima_visualizacao: Option<DateTime<Utc>>,
}

impl std::fmt::Display for StatisticsType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            StatisticsType::Global => write!(f, "global"),
            StatisticsType::PorAnime { anime_id } => write!(f, "por_anime:{}", anime_id),
            StatisticsType::PorPeriodo { inicio, fim } => {
                write!(f, "por_periodo:{}:{}", inicio, fim)
            }
        }
    }
}


--- FILE: src-tauri\src\domain\statistics\mod.rs ---
//! Critical Statistics Invariants:
//!
//! 1. Statistics are ALWAYS derived, NEVER primary
//! 2. Statistics can be recalculated at any time
//! 3. Statistics can be deleted without affecting domains
//! 4. Statistics NEVER alter domain state
//! 5. If statistics conflict with domain data, domain wins
//! 6. Statistics are snapshots in time
//! 7. Stale statistics are acceptable (eventual consistency)

pub mod entity;
pub use entity::{AnimeStatistics, GlobalStatistics, StatisticsSnapshot, StatisticsType};


--- FILE: src-tauri\src\domain\subtitle\entity.rs ---
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

/// Represents a subtitle as transformable data
/// Subtitles are versioned and never destructively edited
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Subtitle {
    /// Internal immutable identifier
    pub id: Uuid,

    /// Source file (REQUIRED)
    pub file_id: Uuid,

    /// Subtitle format
    pub formato: SubtitleFormat,

    /// Language (ISO 639-1 code preferred)
    pub idioma: String,

    /// Version identifier (for tracking transformations)
    pub versao: u32,

    /// Whether this is the original, unmodified subtitle
    pub eh_original: bool,

    /// Creation timestamp
    pub criado_em: DateTime<Utc>,
}

/// Supported subtitle formats
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "UPPERCASE")]
pub enum SubtitleFormat {
    SRT,
    ASS,
    VTT,
}

/// Represents a transformation applied to a subtitle
/// Transformations create new subtitle versions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SubtitleTransformation {
    /// Transformation identifier
    pub id: Uuid,

    /// Source subtitle that was transformed
    pub subtitle_id_origem: Uuid,

    /// Type of transformation
    pub tipo: TransformationType,

    /// Parameters applied (stored as JSON)
    pub parametros_aplicados: serde_json::Value,

    /// Creation timestamp
    pub criado_em: DateTime<Utc>,
}

/// Types of subtitle transformations
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum TransformationType {
    /// Style changes (font, size, colors, outline)
    Style,

    /// Timing adjustments (sync, offset)
    Timing,

    /// Format conversion (SRT -> ASS, etc)
    Conversao,
}

impl Subtitle {
    /// Create a new Subtitle entity
    /// This is typically the original subtitle from a file
    pub fn new(file_id: Uuid, formato: SubtitleFormat, idioma: String) -> Self {
        Self {
            id: Uuid::new_v4(),
            file_id,
            formato,
            idioma,
            versao: 1,
            eh_original: true,
            criado_em: Utc::now(),
        }
    }

    /// Create a derived subtitle from a transformation
    /// This increments the version and marks as non-original
    pub fn derive_from(&self, new_file_id: Uuid, formato: SubtitleFormat) -> Self {
        Self {
            id: Uuid::new_v4(),
            file_id: new_file_id,
            formato,
            idioma: self.idioma.clone(),
            versao: self.versao + 1,
            eh_original: false,
            criado_em: Utc::now(),
        }
    }
}

impl SubtitleTransformation {
    /// Create a new transformation record
    pub fn new(
        subtitle_id_origem: Uuid,
        tipo: TransformationType,
        parametros: serde_json::Value,
    ) -> Self {
        Self {
            id: Uuid::new_v4(),
            subtitle_id_origem,
            tipo,
            parametros_aplicados: parametros,
            criado_em: Utc::now(),
        }
    }
}

impl SubtitleFormat {
    /// Infer format from file extension
    pub fn from_extension(ext: &str) -> Option<Self> {
        match ext.to_lowercase().as_str() {
            "srt" => Some(SubtitleFormat::SRT),
            "ass" | "ssa" => Some(SubtitleFormat::ASS),
            "vtt" => Some(SubtitleFormat::VTT),
            _ => None,
        }
    }
}

impl std::fmt::Display for SubtitleFormat {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            SubtitleFormat::SRT => write!(f, "SRT"),
            SubtitleFormat::ASS => write!(f, "ASS"),
            SubtitleFormat::VTT => write!(f, "VTT"),
        }
    }
}

impl std::fmt::Display for TransformationType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            TransformationType::Style => write!(f, "style"),
            TransformationType::Timing => write!(f, "timing"),
            TransformationType::Conversao => write!(f, "conversao"),
        }
    }
}


--- FILE: src-tauri\src\domain\subtitle\invariants.rs ---
use super::entity::Subtitle;
use crate::domain::{DomainError, DomainResult};

/// Validates all Subtitle invariants
pub fn validate_subtitle(subtitle: &Subtitle) -> DomainResult<()> {
    validate_language(subtitle)?;
    validate_version(subtitle)?;
    Ok(())
}

/// Language code cannot be empty
fn validate_language(subtitle: &Subtitle) -> DomainResult<()> {
    if subtitle.idioma.trim().is_empty() {
        return Err(DomainError::InvariantViolation(
            "Subtitle language cannot be empty".to_string(),
        ));
    }
    Ok(())
}

/// Version must be positive
fn validate_version(subtitle: &Subtitle) -> DomainResult<()> {
    if subtitle.versao == 0 {
        return Err(DomainError::InvariantViolation(
            "Subtitle version must be at least 1".to_string(),
        ));
    }
    Ok(())
}

/// Critical Subtitle Invariants:
///
/// 1. Every Subtitle MUST have a source File
/// 2. Original subtitle is NEVER overwritten
/// 3. Transformations ALWAYS create new versions
/// 4. Transformations are reversible (history preserved)
/// 5. Original files remain untouched on disk
/// 6. file_id is immutable (subtitle tied to specific file)
/// 7. Versions increment monotonically
/// 8. Original subtitles have eh_original = true, versao = 1

#[cfg(test)]
mod tests {
    use super::*;
    use crate::domain::subtitle::{Subtitle, SubtitleFormat};
    use uuid::Uuid;

    #[test]
    fn test_valid_subtitle() {
        let file_id = Uuid::new_v4();
        let subtitle = Subtitle::new(file_id, SubtitleFormat::SRT, "pt-BR".to_string());
        assert!(validate_subtitle(&subtitle).is_ok());
        assert_eq!(subtitle.versao, 1);
        assert!(subtitle.eh_original);
    }

    #[test]
    fn test_derived_subtitle_increments_version() {
        let file_id = Uuid::new_v4();
        let original = Subtitle::new(file_id, SubtitleFormat::SRT, "en".to_string());

        let new_file_id = Uuid::new_v4();
        let derived = original.derive_from(new_file_id, SubtitleFormat::ASS);

        assert_eq!(derived.versao, 2);
        assert!(!derived.eh_original);
        assert_eq!(derived.idioma, original.idioma);
    }

    #[test]
    fn test_empty_language_fails() {
        let file_id = Uuid::new_v4();
        let subtitle = Subtitle::new(file_id, SubtitleFormat::SRT, "".to_string());
        assert!(validate_subtitle(&subtitle).is_err());
    }
}


--- FILE: src-tauri\src\domain\subtitle\mod.rs ---
pub mod entity;
pub mod invariants;

pub use entity::{Subtitle, SubtitleFormat, SubtitleTransformation, TransformationType};
pub use invariants::validate_subtitle;


--- FILE: src-tauri\src\error\mod.rs ---
pub mod types;

pub use types::{AppError, AppResult};


--- FILE: src-tauri\src\error\types.rs ---
// src-tauri/src/error/types.rs
use crate::domain::DomainError;
use serde::Serialize;
use thiserror::Error;

#[derive(Debug, Error)]
pub enum AppError {
    #[error("Database error: {0}")]
    Database(#[from] rusqlite::Error),

    #[error("Pool error: {0}")]
    Pool(String),

    #[error("Domain error: {0}")]
    Domain(#[from] DomainError),

    #[error("Serialization error: {0}")]
    Serialization(#[from] serde_json::Error),

    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),

    #[error("Resource not found")]
    NotFound,

    #[error("Other error: {0}")]
    Other(String),
}

impl Serialize for AppError {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        serializer.serialize_str(&self.to_string())
    }
}

impl From<uuid::Error> for AppError {
    fn from(err: uuid::Error) -> Self {
        AppError::Other(format!("UUID error: {}", err))
    }
}

impl From<chrono::ParseError> for AppError {
    fn from(err: chrono::ParseError) -> Self {
        AppError::Other(format!("Date parse error: {}", err))
    }
}

impl From<r2d2::Error> for AppError {
    fn from(err: r2d2::Error) -> Self {
        AppError::Pool(err.to_string())
    }
}

pub type AppResult<T> = Result<T, AppError>;


--- FILE: src-tauri\src\events\bus\event_bus.rs ---
// events/bus/event_bus.rs
//
// Core event bus implementation.
//
// DESIGN PRINCIPLES:
// 1. Synchronous - handlers execute immediately in subscription order
// 2. Deterministic - same events ‚Üí same result
// 3. Observable - every emission is logged
// 4. Type-safe - events are strongly typed
// 5. No magic - explicit, straightforward code

use std::any::{Any, TypeId};
use std::collections::HashMap;
use std::sync::{Arc, RwLock};

use crate::events::types::DomainEvent;

/// Type-erased event handler function
/// Takes a reference to Any (downcasted to concrete event type inside)
type EventHandler = Box<dyn Fn(&dyn Any) + Send + Sync>;

/// The Event Bus
///
/// This is the central coordination point for all domain events.
/// It allows services to emit events and subscribe to events without
/// direct dependencies on each other.
///
/// Key characteristics:
/// - Synchronous execution (no async, no threads)
/// - Handlers execute in subscription order
/// - Type-safe through generics
/// - Observable through logging
pub struct EventBus {
    /// Map from event TypeId to list of handlers
    handlers: Arc<RwLock<HashMap<TypeId, Vec<EventHandler>>>>,

    /// Event emission log (for debugging)
    event_log: Arc<RwLock<Vec<EventLogEntry>>>,
}

/// A logged event for debugging and tracing
#[derive(Debug, Clone)]
pub struct EventLogEntry {
    pub event_type: String,
    pub event_id: String,
    pub occurred_at: String,
    pub handler_count: usize,
}

impl EventBus {
    /// Create a new event bus
    pub fn new() -> Self {
        Self {
            handlers: Arc::new(RwLock::new(HashMap::new())),
            event_log: Arc::new(RwLock::new(Vec::new())),
        }
    }

    /// Subscribe to a specific event type
    ///
    /// Generic parameter E must implement DomainEvent + 'static
    /// The handler function receives a reference to the concrete event
    ///
    /// Handlers are executed in the order they are subscribed.
    ///
    /// Example:
    /// ```ignore
    /// bus.subscribe::<AnimeCreated>(|event| {
    ///     println!("Anime created: {}", event.titulo_principal);
    /// });
    /// ```
    pub fn subscribe<E, F>(&self, handler: F)
    where
        E: DomainEvent + 'static,
        F: Fn(&E) + Send + Sync + 'static,
    {
        let type_id = TypeId::of::<E>();

        // Wrap the typed handler in a type-erased closure
        let wrapped: EventHandler = Box::new(move |event_any: &dyn Any| {
            // Downcast to concrete type
            if let Some(event) = event_any.downcast_ref::<E>() {
                handler(event);
            } else {
                eprintln!(
                    "ERROR: Failed to downcast event in handler for {}",
                    std::any::type_name::<E>()
                );
            }
        });

        let mut handlers = self.handlers.write().unwrap();
        handlers
            .entry(type_id)
            .or_insert_with(Vec::new)
            .push(wrapped);
    }

    /// Emit an event
    ///
    /// This will:
    /// 1. Log the event
    /// 2. Execute all handlers for this event type (in subscription order)
    /// 3. Return immediately (synchronous)
    ///
    /// If a handler panics, the panic is caught and logged, but other handlers
    /// still execute.
    pub fn emit<E>(&self, event: E)
    where
        E: DomainEvent + 'static,
    {
        let type_id = TypeId::of::<E>();

        // Log the event
        let log_entry = EventLogEntry {
            event_type: event.event_type().to_string(),
            event_id: event.event_id().to_string(),
            occurred_at: event.occurred_at().to_rfc3339(),
            handler_count: 0, // will be updated below
        };

        // Get handlers
        let handlers = self.handlers.read().unwrap();
        let event_handlers = handlers.get(&type_id);

        let handler_count = event_handlers.map(|h| h.len()).unwrap_or(0);

        // Update log entry with handler count
        let log_entry = EventLogEntry {
            handler_count,
            ..log_entry
        };

        // Add to event log
        {
            let mut log = self.event_log.write().unwrap();
            log.push(log_entry.clone());
        }

        // Log to console (observable behavior)
        println!(
            "[EVENT] {} (id: {}) | {} handlers",
            log_entry.event_type, log_entry.event_id, log_entry.handler_count
        );

        // Execute handlers
        if let Some(handlers) = event_handlers {
            for (idx, handler) in handlers.iter().enumerate() {
                // Catch panics to prevent one handler from breaking others
                let result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
                    handler(&event as &dyn Any);
                }));

                if let Err(e) = result {
                    eprintln!(
                        "ERROR: Handler {} for {} panicked: {:?}",
                        idx,
                        event.event_type(),
                        e
                    );
                }
            }
        }
    }

    /// Get the event log (for debugging)
    pub fn get_event_log(&self) -> Vec<EventLogEntry> {
        self.event_log.read().unwrap().clone()
    }

    /// Clear the event log
    pub fn clear_event_log(&self) {
        self.event_log.write().unwrap().clear();
    }

    /// Get the number of subscribers for a specific event type
    pub fn subscriber_count<E>(&self) -> usize
    where
        E: 'static,
    {
        let type_id = TypeId::of::<E>();
        let handlers = self.handlers.read().unwrap();
        handlers.get(&type_id).map(|h| h.len()).unwrap_or(0)
    }
}

impl Default for EventBus {
    fn default() -> Self {
        Self::new()
    }
}

// Make EventBus cloneable (shared reference)
impl Clone for EventBus {
    fn clone(&self) -> Self {
        Self {
            handlers: Arc::clone(&self.handlers),
            event_log: Arc::clone(&self.event_log),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::events::types::*;
    use std::sync::atomic::{AtomicUsize, Ordering};
    use std::sync::Arc;
    use uuid::Uuid;

    #[test]
    fn test_subscribe_and_emit() {
        let bus = EventBus::new();
        let counter = Arc::new(AtomicUsize::new(0));
        let counter_clone = Arc::clone(&counter);

        bus.subscribe::<AnimeCreated, _>(move |_event| {
            counter_clone.fetch_add(1, Ordering::SeqCst);
        });

        let event = AnimeCreated::new(Uuid::new_v4(), "Steins;Gate".to_string(), "TV".to_string());

        bus.emit(event);

        assert_eq!(counter.load(Ordering::SeqCst), 1);
    }

    #[test]
    fn test_multiple_handlers_execute_in_order() {
        let bus = EventBus::new();
        let sequence = Arc::new(RwLock::new(Vec::new()));

        let seq1 = Arc::clone(&sequence);
        bus.subscribe::<EpisodeCreated, _>(move |_| {
            seq1.write().unwrap().push(1);
        });

        let seq2 = Arc::clone(&sequence);
        bus.subscribe::<EpisodeCreated, _>(move |_| {
            seq2.write().unwrap().push(2);
        });

        let seq3 = Arc::clone(&sequence);
        bus.subscribe::<EpisodeCreated, _>(move |_| {
            seq3.write().unwrap().push(3);
        });

        let event = EpisodeCreated::new(Uuid::new_v4(), Uuid::new_v4(), "1".to_string());

        bus.emit(event);

        let result = sequence.read().unwrap();
        assert_eq!(*result, vec![1, 2, 3]);
    }

    #[test]
    fn test_event_log_records_emissions() {
        let bus = EventBus::new();

        let event1 =
            AnimeCreated::new(Uuid::new_v4(), "Cowboy Bebop".to_string(), "TV".to_string());

        let event2 = EpisodeCreated::new(Uuid::new_v4(), Uuid::new_v4(), "1".to_string());

        bus.emit(event1);
        bus.emit(event2);

        let log = bus.get_event_log();
        assert_eq!(log.len(), 2);
        assert_eq!(log[0].event_type, "AnimeCreated");
        assert_eq!(log[1].event_type, "EpisodeCreated");
    }

    #[test]
    fn test_subscriber_count() {
        let bus = EventBus::new();

        assert_eq!(bus.subscriber_count::<AnimeCreated>(), 0);

        bus.subscribe::<AnimeCreated, _>(|_| {});
        assert_eq!(bus.subscriber_count::<AnimeCreated>(), 1);

        bus.subscribe::<AnimeCreated, _>(|_| {});
        assert_eq!(bus.subscriber_count::<AnimeCreated>(), 2);

        // Different event type
        assert_eq!(bus.subscriber_count::<EpisodeCreated>(), 0);
    }

    #[test]
    fn test_handler_panic_doesnt_break_bus() {
        let bus = EventBus::new();
        let counter = Arc::new(AtomicUsize::new(0));

        // First handler panics
        bus.subscribe::<AnimeCreated, _>(|_| {
            panic!("Intentional panic");
        });

        // Second handler should still execute
        let counter_clone = Arc::clone(&counter);
        bus.subscribe::<AnimeCreated, _>(move |_| {
            counter_clone.fetch_add(1, Ordering::SeqCst);
        });

        let event = AnimeCreated::new(Uuid::new_v4(), "Test".to_string(), "TV".to_string());

        bus.emit(event);

        // Second handler executed despite first one panicking
        assert_eq!(counter.load(Ordering::SeqCst), 1);
    }
}


--- FILE: src-tauri\src\events\bus\mod.rs ---
// events/bus/mod.rs

pub mod event_bus;

pub use event_bus::{EventBus, EventLogEntry};


--- FILE: src-tauri\src\events\handlers\materialization_handler.rs ---
// src-tauri/src/events/handlers/materialization_handler.rs
//
// Materialization Event Handler - Phase 5
//
// Event handler that listens to resolution events and triggers materialization.
// This is the bridge between the event bus and the MaterializationService.
//
// CRITICAL RULES:
// - Only consumes FileResolved and EpisodeResolved events
// - Delegates all logic to MaterializationService
// - Does not contain business logic
// - Handles errors gracefully without crashing the event bus
// - Uses closure-based subscription (EventHandler is internal to bus)

use std::sync::Arc;

use crate::events::resolution_events::{EpisodeResolved, FileResolved};
use crate::events::EventBus;
use crate::services::materialization_types::MaterializationOutcome;
use crate::services::MaterializationService;

// ============================================================================
// HANDLER REGISTRATION
// ============================================================================

/// Registers all materialization handlers with the event bus.
/// Uses closure-based subscription pattern (EventHandler type is internal).
pub fn register_materialization_handlers(bus: &EventBus, service: Arc<MaterializationService>) {
    // Register FileResolved handler
    let file_service = Arc::clone(&service);
    bus.subscribe::<FileResolved, _>(move |event| {
        handle_file_resolved(&file_service, event);
    });

    // Register EpisodeResolved handler
    let episode_service = Arc::clone(&service);
    bus.subscribe::<EpisodeResolved, _>(move |event| {
        handle_episode_resolved(&episode_service, event);
    });

    println!("[MATERIALIZATION] Handlers registered");
}

// ============================================================================
// FILE RESOLVED HANDLER
// ============================================================================

/// Handles FileResolved events by triggering materialization.
fn handle_file_resolved(service: &MaterializationService, event: &FileResolved) {
    println!(
        "[MATERIALIZATION] Processing FileResolved: file_id={}, anime='{}', episode='{}'",
        event.file_id, event.anime_title, event.episode_number
    );

    match service.materialize_file_resolved(event) {
        Ok(result) => match &result.outcome {
            MaterializationOutcome::Skipped => {
                println!(
                    "[MATERIALIZATION] Skipped (idempotent): file_id={}",
                    event.file_id
                );
            }
            MaterializationOutcome::AnimeCreated => {
                println!(
                    "[MATERIALIZATION] Created anime: id={:?}, title='{}'",
                    result.anime_id, event.anime_title
                );
            }
            MaterializationOutcome::EpisodeCreated => {
                println!(
                    "[MATERIALIZATION] Created episode: id={:?}, number='{}'",
                    result.episode_id, event.episode_number
                );
            }
            MaterializationOutcome::FileLinked => {
                println!(
                    "[MATERIALIZATION] Linked file: file_id={}, episode_id={:?}",
                    event.file_id, result.episode_id
                );
            }
            MaterializationOutcome::AnimeMatched | MaterializationOutcome::EpisodeMatched => {
                println!(
                    "[MATERIALIZATION] Matched existing: anime_id={:?}, episode_id={:?}",
                    result.anime_id, result.episode_id
                );
            }
            MaterializationOutcome::Failed { reason } => {
                eprintln!(
                    "[MATERIALIZATION] Failed: file_id={}, reason={}",
                    event.file_id, reason
                );
            }
        },
        Err(e) => {
            eprintln!(
                "[MATERIALIZATION] Error for file_id={}: {}",
                event.file_id, e
            );
        }
    }
}

// ============================================================================
// EPISODE RESOLVED HANDLER
// ============================================================================

/// Handles EpisodeResolved events by triggering materialization.
fn handle_episode_resolved(service: &MaterializationService, event: &EpisodeResolved) {
    println!(
        "[MATERIALIZATION] Processing EpisodeResolved: anime='{}', episode='{}'",
        event.anime_title, event.episode_number
    );

    match service.materialize_episode_resolved(event) {
        Ok(result) => match &result.outcome {
            MaterializationOutcome::Skipped => {
                println!(
                    "[MATERIALIZATION] Skipped (idempotent): anime='{}', episode='{}'",
                    event.anime_title, event.episode_number
                );
            }
            MaterializationOutcome::AnimeCreated => {
                println!(
                    "[MATERIALIZATION] Created anime from episode: id={:?}",
                    result.anime_id
                );
            }
            MaterializationOutcome::EpisodeCreated => {
                println!(
                    "[MATERIALIZATION] Created episode: id={:?}",
                    result.episode_id
                );
            }
            MaterializationOutcome::FileLinked => {
                println!(
                    "[MATERIALIZATION] Linked files to episode: episode_id={:?}",
                    result.episode_id
                );
            }
            _ => {
                println!("[MATERIALIZATION] Completed: outcome={}", result.outcome);
            }
        },
        Err(e) => {
            eprintln!(
                "[MATERIALIZATION] Error for episode '{}': {}",
                event.episode_number, e
            );
        }
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    // Integration tests are in materialization_service_tests.rs
}


--- FILE: src-tauri\src\events\handlers\mod.rs ---
// src-tauri/src/events/handlers/mod.rs
//
// Event Handlers - INTERNAL MODULE
//
// This module contains handler implementations.
// EventHandler type is internal to the bus module and NOT exported.
//
// Handlers use closure-based subscription via EventBus::subscribe.

// ============================================================================
// MATERIALIZATION HANDLERS (Phase 5)
// ============================================================================

pub mod materialization_handler;

// ============================================================================
// PUBLIC EXPORTS
// ============================================================================

// Only export the registration function, not handler structs
// (handlers use closure-based subscription, not trait-based)
pub use materialization_handler::register_materialization_handlers;


--- FILE: src-tauri\src\events\materialization_events.rs ---
// src-tauri/src/events/materialization_events.rs
//
// Materialization Events - Phase 5
//
// Events emitted during materialization to notify other parts of the system.
// These events represent completed domain mutations.
//
// CRITICAL RULES:
// - Events are facts, not commands
// - Events are immutable
// - These events are emitted AFTER successful persistence
// - No business logic in event types
//
// NOTE: This file extends the existing events system.
// The core domain events (AnimeCreated, EpisodeCreated, FileLinkedToEpisode)
// are already defined in events/types.rs and are reused here.

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

use super::types::DomainEvent;

// ============================================================================
// MATERIALIZATION COMPLETED EVENT
// ============================================================================

/// Emitted when a batch of resolution events has been materialized.
/// Provides summary statistics for the materialization operation.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MaterializationBatchCompleted {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,

    /// Total events processed
    pub total_events: usize,

    /// New anime created
    pub anime_created_count: usize,

    /// New episodes created
    pub episodes_created_count: usize,

    /// Files linked to episodes
    pub files_linked_count: usize,

    /// Events skipped (already materialized)
    pub skipped_count: usize,

    /// Failed materializations
    pub failed_count: usize,

    /// Duration of the batch operation in milliseconds
    pub duration_ms: u64,
}

impl MaterializationBatchCompleted {
    pub fn new(
        total_events: usize,
        anime_created_count: usize,
        episodes_created_count: usize,
        files_linked_count: usize,
        skipped_count: usize,
        failed_count: usize,
        duration_ms: u64,
    ) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            total_events,
            anime_created_count,
            episodes_created_count,
            files_linked_count,
            skipped_count,
            failed_count,
            duration_ms,
        }
    }
}

impl DomainEvent for MaterializationBatchCompleted {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "MaterializationBatchCompleted"
    }
}

// ============================================================================
// MATERIALIZATION RECORD CREATED EVENT
// ============================================================================

/// Emitted when a materialization record is created.
/// Used for audit and debugging purposes.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MaterializationRecordCreated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,

    /// The materialization record ID
    pub record_id: Uuid,

    /// The fingerprint hash
    pub fingerprint_hash: String,

    /// The source resolution event ID
    pub source_event_id: Uuid,

    /// The resulting anime ID (if any)
    pub anime_id: Option<Uuid>,

    /// The resulting episode ID (if any)
    pub episode_id: Option<Uuid>,

    /// The file ID that was linked (if any)
    pub file_id: Option<Uuid>,

    /// The outcome as a string
    pub outcome: String,
}

impl MaterializationRecordCreated {
    pub fn new(
        record_id: Uuid,
        fingerprint_hash: String,
        source_event_id: Uuid,
        anime_id: Option<Uuid>,
        episode_id: Option<Uuid>,
        file_id: Option<Uuid>,
        outcome: String,
    ) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            record_id,
            fingerprint_hash,
            source_event_id,
            anime_id,
            episode_id,
            file_id,
            outcome,
        }
    }
}

impl DomainEvent for MaterializationRecordCreated {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "MaterializationRecordCreated"
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_batch_completed_event() {
        let event = MaterializationBatchCompleted::new(
            100,  // total
            10,   // anime created
            50,   // episodes created
            80,   // files linked
            5,    // skipped
            5,    // failed
            1500, // duration
        );

        assert_eq!(event.event_type(), "MaterializationBatchCompleted");
        assert_eq!(event.total_events, 100);
        assert_eq!(event.anime_created_count, 10);
    }

    #[test]
    fn test_record_created_event() {
        let event = MaterializationRecordCreated::new(
            Uuid::new_v4(),
            "abc123".to_string(),
            Uuid::new_v4(),
            Some(Uuid::new_v4()),
            Some(Uuid::new_v4()),
            Some(Uuid::new_v4()),
            "anime_created".to_string(),
        );

        assert_eq!(event.event_type(), "MaterializationRecordCreated");
        assert!(event.anime_id.is_some());
    }
}


--- FILE: src-tauri\src\events\mod.rs ---
// src-tauri/src/events/mod.rs
//
// Internal Event System - Public API
//
// CRITICAL: EventHandler is INTERNAL and must NOT be exported

// ============================================================================
// EXISTING EVENT INFRASTRUCTURE (SEALED - Phase 3)
// ============================================================================

pub mod bus;
pub mod types;

// ============================================================================
// RESOLUTION EVENTS (FROZEN - Phase 4)
// ============================================================================

pub mod resolution_events;

// ============================================================================
// MATERIALIZATION (NEW - Phase 5)
// ============================================================================

pub mod handlers;
pub mod materialization_events;

// ============================================================================
// PUBLIC EXPORTS - Event Types and Bus Only
// ============================================================================

pub use types::DomainEvent;

pub use types::{
    // Anime
    AnimeCreated,
    AnimeMerged,

    AnimeUpdated,
    // File scanning
    DirectoryScanned,
    EpisodeBecamePlayable,
    EpisodeCompleted,

    // Episode
    EpisodeCreated,
    EpisodeProgressUpdated,
    ExternalMetadataFetched,
    ExternalMetadataLinked,
    // External
    ExternalMetadataRequested,
    FileDetected,

    FileLinkedToEpisode,
    PlaybackFinished,

    PlaybackProgressUpdated,
    // Playback
    PlaybackStarted,
    PlaybackStopped,
    // Statistics
    StatisticsRebuilt,
    StatisticsUpdated,

    // Subtitle
    SubtitleDetected,
    SubtitleStyleApplied,
    SubtitleTimingAdjusted,
    SubtitleVersionCreated,
};

pub use bus::{EventBus, EventLogEntry};

// Resolution events (Phase 4 - frozen)
pub use resolution_events::{
    EpisodeResolved, FileResolved, ResolutionBatchCompleted, ResolutionFailed,
};

// Materialization events (Phase 5)
pub use materialization_events::{MaterializationBatchCompleted, MaterializationRecordCreated};

// Materialization handler registration (Phase 5)
pub use handlers::register_materialization_handlers;

// ============================================================================
// INTERNAL ONLY - DO NOT EXPORT
// ============================================================================

// EventHandler type alias is internal to the bus module
// handlers::RegisterHandler is internal to handlers module

/// Initialize a new event bus
pub fn create_event_bus() -> EventBus {
    EventBus::new()
}


--- FILE: src-tauri\src\events\resolution_events.rs ---
// src-tauri/src/events/resolution_events.rs
//
// Resolution Events - Phase 4 (FINAL CORRECTED VERSION)
//
// These events are the ONLY outputs of Phase 4 Resolution.
// They carry resolution intent to Phase 5 Materialization.
//
// CRITICAL INVARIANTS:
// - All events are deterministic (no timestamps in event payload)
// - All events are immutable
// - All events are serializable
// - All events are reachable through real resolution paths
// - Event IDs are derived deterministically from fingerprints
// - occurred_at() returns SENTINEL_TIMESTAMP (Unix epoch) for trait compliance
//
// PHASE 4 CLOSURE CORRECTIONS:
// - EpisodeResolved is emitted through aggregation logic
// - Removed timestamps from event payloads (determinism)
// - All events are reachable
// - occurred_at() returns fixed sentinel for DomainEvent trait compliance
// - ResolutionBatchCompleted uses deterministic event ID

use crate::events::DomainEvent;
use chrono::{DateTime, TimeZone, Utc};
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use uuid::Uuid;

/// Sentinel timestamp for Phase 4 events (Unix epoch).
/// Phase 4 events are deterministic and do not carry operational timestamps.
/// This constant satisfies the DomainEvent trait while maintaining determinism.
const SENTINEL_TIMESTAMP: DateTime<Utc> = DateTime::<Utc>::UNIX_EPOCH;

// ============================================================================
// FILE RESOLVED EVENT
// ============================================================================

/// Emitted when a single file is successfully resolved.
/// This is the primary output of file-level resolution.
///
/// DETERMINISM: No timestamp in payload. Identical resolution produces identical event.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct FileResolved {
    /// The file ID that was resolved
    pub file_id: Uuid,

    /// The file path (for traceability)
    pub file_path: PathBuf,

    /// The resolved anime title
    pub anime_title: String,

    /// If matched to existing anime, its ID
    pub matched_anime_id: Option<Uuid>,

    /// The resolved episode number (as string for serialization)
    pub episode_number: String,

    /// If matched to existing episode, its ID
    pub matched_episode_id: Option<Uuid>,

    /// The file role (video, subtitle, image)
    pub file_role: String,

    /// Confidence score (0.0 to 1.0)
    pub confidence: f64,

    /// Resolution source (filename, folder_name)
    pub source: String,

    /// Deterministic fingerprint for idempotency
    pub fingerprint: String,
}

impl FileResolved {
    pub fn new(
        file_id: Uuid,
        file_path: PathBuf,
        anime_title: String,
        matched_anime_id: Option<Uuid>,
        episode_number: String,
        matched_episode_id: Option<Uuid>,
        file_role: String,
        confidence: f64,
        source: String,
        fingerprint: String,
    ) -> Self {
        Self {
            file_id,
            file_path,
            anime_title,
            matched_anime_id,
            episode_number,
            matched_episode_id,
            file_role,
            confidence,
            source,
            fingerprint,
        }
    }
}

impl DomainEvent for FileResolved {
    fn event_id(&self) -> Uuid {
        // Deterministic event ID derived from fingerprint
        Uuid::new_v5(&Uuid::NAMESPACE_OID, self.fingerprint.as_bytes())
    }

    fn occurred_at(&self) -> DateTime<Utc> {
        // Phase 4 events use sentinel timestamp for determinism
        SENTINEL_TIMESTAMP
    }

    fn event_type(&self) -> &'static str {
        "FileResolved"
    }
}

// ============================================================================
// EPISODE RESOLVED EVENT
// ============================================================================

/// Emitted when resolution aggregation determines a complete episode intent.
/// This event is produced by aggregating FileResolved events for the same episode.
///
/// REACHABILITY: Emitted by ResolutionService.resolve_batch() through aggregation logic.
///
/// DETERMINISM: No timestamp in payload. Identical aggregation produces identical event.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct EpisodeResolved {
    /// The resolved anime title
    pub anime_title: String,

    /// If matched to existing anime, its ID
    pub matched_anime_id: Option<Uuid>,

    /// The resolved episode number
    pub episode_number: String,

    /// If matched to existing episode, its ID
    pub matched_episode_id: Option<Uuid>,

    /// The primary video file ID (if any)
    pub video_file_id: Option<Uuid>,

    /// Subtitle file IDs associated with this episode
    pub subtitle_file_ids: Vec<Uuid>,

    /// Image file IDs associated with this episode
    pub image_file_ids: Vec<Uuid>,

    /// Aggregated confidence score
    pub confidence: f64,

    /// Deterministic fingerprint for idempotency
    pub fingerprint: String,
}

impl EpisodeResolved {
    pub fn new(
        anime_title: String,
        matched_anime_id: Option<Uuid>,
        episode_number: String,
        matched_episode_id: Option<Uuid>,
        video_file_id: Option<Uuid>,
        subtitle_file_ids: Vec<Uuid>,
        image_file_ids: Vec<Uuid>,
        confidence: f64,
    ) -> Self {
        // Compute deterministic fingerprint
        // DETERMINISM COMPONENTS (documented):
        // - anime_title (lowercased for normalization)
        // - episode_number
        // - video_file_id
        // - subtitle_file_ids (sorted for order stability)
        // - image_file_ids (sorted for order stability)
        let fingerprint = Self::compute_fingerprint(
            &anime_title,
            &episode_number,
            video_file_id,
            &subtitle_file_ids,
            &image_file_ids,
        );

        Self {
            anime_title,
            matched_anime_id,
            episode_number,
            matched_episode_id,
            video_file_id,
            subtitle_file_ids,
            image_file_ids,
            confidence,
            fingerprint,
        }
    }

    /// Compute deterministic fingerprint for idempotency.
    ///
    /// DETERMINISM COMPONENTS:
    /// - anime_title: lowercased for case-insensitive matching
    /// - episode_number: exact string representation
    /// - video_file_id: optional UUID
    /// - subtitle_file_ids: sorted Vec<Uuid> for order stability
    /// - image_file_ids: sorted Vec<Uuid> for order stability
    fn compute_fingerprint(
        anime_title: &str,
        episode_number: &str,
        video_file_id: Option<Uuid>,
        subtitle_file_ids: &[Uuid],
        image_file_ids: &[Uuid],
    ) -> String {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        anime_title.to_lowercase().hash(&mut hasher);
        episode_number.hash(&mut hasher);
        video_file_id.hash(&mut hasher);

        // Sort IDs for determinism (order stability)
        let mut sorted_subs = subtitle_file_ids.to_vec();
        sorted_subs.sort();
        for id in &sorted_subs {
            id.hash(&mut hasher);
        }

        let mut sorted_imgs = image_file_ids.to_vec();
        sorted_imgs.sort();
        for id in &sorted_imgs {
            id.hash(&mut hasher);
        }

        format!("ep:{:016x}", hasher.finish())
    }
}

impl DomainEvent for EpisodeResolved {
    fn event_id(&self) -> Uuid {
        // Deterministic event ID derived from fingerprint
        Uuid::new_v5(&Uuid::NAMESPACE_OID, self.fingerprint.as_bytes())
    }

    fn occurred_at(&self) -> DateTime<Utc> {
        // Phase 4 events use sentinel timestamp for determinism
        SENTINEL_TIMESTAMP
    }

    fn event_type(&self) -> &'static str {
        "EpisodeResolved"
    }
}

// ============================================================================
// RESOLUTION FAILED EVENT
// ============================================================================

/// Emitted when resolution fails for a file.
/// Failures are explicit and structured, never silent.
///
/// DETERMINISM: No timestamp in payload. Identical failure produces identical event.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ResolutionFailed {
    /// The file ID that failed to resolve
    pub file_id: Uuid,

    /// The file path (for traceability)
    pub file_path: PathBuf,

    /// The failure reason (structured)
    pub reason: String,

    /// Human-readable description
    pub description: String,

    /// Deterministic fingerprint for idempotency
    pub fingerprint: String,
}

impl ResolutionFailed {
    pub fn new(file_id: Uuid, file_path: PathBuf, reason: String, description: String) -> Self {
        // Compute deterministic fingerprint
        let fingerprint = Self::compute_fingerprint(file_id, &reason);

        Self {
            file_id,
            file_path,
            reason,
            description,
            fingerprint,
        }
    }

    /// Compute deterministic fingerprint for idempotency.
    ///
    /// DETERMINISM COMPONENTS:
    /// - file_id: UUID of the file
    /// - reason: structured failure reason string
    fn compute_fingerprint(file_id: Uuid, reason: &str) -> String {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        file_id.hash(&mut hasher);
        reason.hash(&mut hasher);
        format!("fail:{:016x}", hasher.finish())
    }
}

impl DomainEvent for ResolutionFailed {
    fn event_id(&self) -> Uuid {
        Uuid::new_v5(&Uuid::NAMESPACE_OID, self.fingerprint.as_bytes())
    }

    fn occurred_at(&self) -> DateTime<Utc> {
        // Phase 4 events use sentinel timestamp for determinism
        SENTINEL_TIMESTAMP
    }

    fn event_type(&self) -> &'static str {
        "ResolutionFailed"
    }
}

// ============================================================================
// RESOLUTION SKIPPED EVENT
// ============================================================================

/// Emitted when a file is skipped due to idempotency (already resolved).
/// This makes the skipped_count in ResolutionBatchCompleted meaningful.
///
/// DETERMINISM: No timestamp in payload. Identical skip produces identical event.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ResolutionSkipped {
    /// The file ID that was skipped
    pub file_id: Uuid,

    /// The file path (for traceability)
    pub file_path: PathBuf,

    /// The existing fingerprint that caused the skip
    pub existing_fingerprint: String,

    /// Reason for skipping
    pub reason: String,
}

impl ResolutionSkipped {
    pub fn new(
        file_id: Uuid,
        file_path: PathBuf,
        existing_fingerprint: String,
        reason: String,
    ) -> Self {
        Self {
            file_id,
            file_path,
            existing_fingerprint,
            reason,
        }
    }
}

impl DomainEvent for ResolutionSkipped {
    fn event_id(&self) -> Uuid {
        // Deterministic event ID derived from existing fingerprint
        Uuid::new_v5(&Uuid::NAMESPACE_OID, self.existing_fingerprint.as_bytes())
    }

    fn occurred_at(&self) -> DateTime<Utc> {
        // Phase 4 events use sentinel timestamp for determinism
        SENTINEL_TIMESTAMP
    }

    fn event_type(&self) -> &'static str {
        "ResolutionSkipped"
    }
}

// ============================================================================
// RESOLUTION BATCH COMPLETED EVENT
// ============================================================================

/// Emitted when a batch resolution operation completes.
/// Provides aggregate statistics for the batch.
///
/// DETERMINISM: No timestamp in payload. Statistics are deterministic from input.
/// Event ID is derived from batch content fingerprint.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ResolutionBatchCompleted {
    /// Total files processed
    pub total_files: usize,

    /// Files successfully resolved
    pub resolved_count: usize,

    /// Files that failed resolution
    pub failed_count: usize,

    /// Files skipped (already resolved, idempotency)
    pub skipped_count: usize,

    /// Episodes aggregated from resolved files
    pub episodes_aggregated: usize,

    /// Duration of the batch operation in milliseconds
    /// NOTE: This is operational metadata but is deterministic for same input
    /// as it represents processing time, not wall-clock time
    pub duration_ms: u64,

    /// Deterministic fingerprint for the batch
    fingerprint: String,
}

impl ResolutionBatchCompleted {
    pub fn new(
        total_files: usize,
        resolved_count: usize,
        failed_count: usize,
        skipped_count: usize,
        episodes_aggregated: usize,
        duration_ms: u64,
    ) -> Self {
        // Compute deterministic fingerprint from batch statistics
        let fingerprint = Self::compute_fingerprint(
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
        );

        Self {
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
            duration_ms,
            fingerprint,
        }
    }

    /// Compute deterministic fingerprint for the batch.
    ///
    /// DETERMINISM COMPONENTS:
    /// - total_files
    /// - resolved_count
    /// - failed_count
    /// - skipped_count
    /// - episodes_aggregated
    /// NOTE: duration_ms is excluded as it varies between runs
    fn compute_fingerprint(
        total_files: usize,
        resolved_count: usize,
        failed_count: usize,
        skipped_count: usize,
        episodes_aggregated: usize,
    ) -> String {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        total_files.hash(&mut hasher);
        resolved_count.hash(&mut hasher);
        failed_count.hash(&mut hasher);
        skipped_count.hash(&mut hasher);
        episodes_aggregated.hash(&mut hasher);
        format!("batch:{:016x}", hasher.finish())
    }
}

impl DomainEvent for ResolutionBatchCompleted {
    fn event_id(&self) -> Uuid {
        // Deterministic event ID derived from batch fingerprint
        Uuid::new_v5(&Uuid::NAMESPACE_OID, self.fingerprint.as_bytes())
    }

    fn occurred_at(&self) -> DateTime<Utc> {
        // Phase 4 events use sentinel timestamp for determinism
        SENTINEL_TIMESTAMP
    }

    fn event_type(&self) -> &'static str {
        "ResolutionBatchCompleted"
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_file_resolved_determinism() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();


--- FILE: src-tauri\src\events\types.rs ---
// events/types.rs
//
// All domain events in the system.
// Each event represents an immutable fact that has already occurred.
//
// CRITICAL RULES:
// - Events are facts, not commands
// - Events are immutable
// - Events carry only the data needed to react
// - No business logic in event types

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use uuid::Uuid;

/// Trait that all domain events must implement
pub trait DomainEvent: std::fmt::Debug + Clone {
    /// Unique identifier for this event instance
    fn event_id(&self) -> Uuid;

    /// When this event occurred
    fn occurred_at(&self) -> DateTime<Utc>;

    /// Human-readable event type name
    fn event_type(&self) -> &'static str;
}

// ============================================================================
// FILE SCANNING EVENTS
// ============================================================================

/// Emitted when a directory scan completes
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryScanned {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub directory_path: PathBuf,
    pub files_found: usize,
}

impl DirectoryScanned {
    pub fn new(directory_path: PathBuf, files_found: usize) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            directory_path,
            files_found,
        }
    }
}

impl DomainEvent for DirectoryScanned {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "DirectoryScanned"
    }
}

/// Emitted for each relevant file detected during scan
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileDetected {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub file_path: PathBuf,
    pub file_size: u64,
    pub file_type: String, // "video", "subtitle", "image"
}

impl FileDetected {
    pub fn new(file_path: PathBuf, file_size: u64, file_type: String) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            file_path,
            file_size,
            file_type,
        }
    }
}

impl DomainEvent for FileDetected {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "FileDetected"
    }
}

// ============================================================================
// ANIME DOMAIN EVENTS
// ============================================================================

/// Emitted when a new Anime entity is created
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnimeCreated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub anime_id: Uuid,
    pub titulo_principal: String,
    pub tipo: String, // "TV", "Movie", "OVA", "Special"
}

impl AnimeCreated {
    pub fn new(anime_id: Uuid, titulo_principal: String, tipo: String) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            anime_id,
            titulo_principal,
            tipo,
        }
    }
}

impl DomainEvent for AnimeCreated {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "AnimeCreated"
    }
}

/// Emitted when anime metadata is updated
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnimeUpdated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub anime_id: Uuid,
}

impl AnimeUpdated {
    pub fn new(anime_id: Uuid) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            anime_id,
        }
    }
}

impl DomainEvent for AnimeUpdated {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "AnimeUpdated"
    }
}

/// Emitted when duplicate animes are merged
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnimeMerged {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub principal_anime_id: Uuid,
    pub merged_anime_id: Uuid,
}

impl AnimeMerged {
    pub fn new(principal_anime_id: Uuid, merged_anime_id: Uuid) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            principal_anime_id,
            merged_anime_id,
        }
    }
}

impl DomainEvent for AnimeMerged {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "AnimeMerged"
    }
}

// ============================================================================
// EPISODE DOMAIN EVENTS
// ============================================================================

/// Emitted when a new Episode is created
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EpisodeCreated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
    pub anime_id: Uuid,
    pub numero: String, // Can be "1", "2" or "OVA 1", etc
}

impl EpisodeCreated {
    pub fn new(episode_id: Uuid, anime_id: Uuid, numero: String) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
            anime_id,
            numero,
        }
    }
}

impl DomainEvent for EpisodeCreated {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "EpisodeCreated"
    }
}

/// Emitted when a file is linked to an episode
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileLinkedToEpisode {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
    pub file_id: Uuid,
    pub is_primary: bool, // true = main video, false = auxiliary
}

impl FileLinkedToEpisode {
    pub fn new(episode_id: Uuid, file_id: Uuid, is_primary: bool) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
            file_id,
            is_primary,
        }
    }
}

impl DomainEvent for FileLinkedToEpisode {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "FileLinkedToEpisode"
    }
}

/// Emitted when an episode becomes playable (has valid video file)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EpisodeBecamePlayable {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
}

impl EpisodeBecamePlayable {
    pub fn new(episode_id: Uuid) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
        }
    }
}

impl DomainEvent for EpisodeBecamePlayable {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "EpisodeBecamePlayable"
    }
}

/// Emitted when episode progress is updated
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EpisodeProgressUpdated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
    pub progress_seconds: u64,
    pub duration_seconds: Option<u64>,
}

impl EpisodeProgressUpdated {
    pub fn new(episode_id: Uuid, progress_seconds: u64, duration_seconds: Option<u64>) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
            progress_seconds,
            duration_seconds,
        }
    }
}

impl DomainEvent for EpisodeProgressUpdated {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "EpisodeProgressUpdated"
    }
}

/// Emitted when an episode is marked as completed
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EpisodeCompleted {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
    pub anime_id: Uuid,
}

impl EpisodeCompleted {
    pub fn new(episode_id: Uuid, anime_id: Uuid) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
            anime_id,
        }
    }
}

impl DomainEvent for EpisodeCompleted {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "EpisodeCompleted"
    }
}

// ============================================================================
// PLAYBACK EVENTS
// ============================================================================

/// Emitted when playback starts
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlaybackStarted {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
}

impl PlaybackStarted {
    pub fn new(episode_id: Uuid) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
        }
    }
}

impl DomainEvent for PlaybackStarted {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "PlaybackStarted"
    }
}

/// Emitted periodically during playback
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlaybackProgressUpdated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
    pub progress_seconds: u64,
}

impl PlaybackProgressUpdated {
    pub fn new(episode_id: Uuid, progress_seconds: u64) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
            progress_seconds,
        }
    }
}

impl DomainEvent for PlaybackProgressUpdated {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "PlaybackProgressUpdated"
    }
}

/// Emitted when playback stops
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlaybackStopped {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
    pub final_progress_seconds: u64,
}

impl PlaybackStopped {
    pub fn new(episode_id: Uuid, final_progress_seconds: u64) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
            final_progress_seconds,
        }
    }
}

impl DomainEvent for PlaybackStopped {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "PlaybackStopped"
    }
}

/// Emitted when playback is paused
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlaybackPaused {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
    pub position_seconds: u64,
}

impl PlaybackPaused {
    pub fn new(episode_id: Uuid, position_seconds: u64) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
            position_seconds,
        }
    }
}

impl DomainEvent for PlaybackPaused {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "PlaybackPaused"
    }
}

/// Emitted when playback is resumed after pause
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlaybackResumed {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
}

impl PlaybackResumed {
    pub fn new(episode_id: Uuid) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
        }
    }
}

impl DomainEvent for PlaybackResumed {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "PlaybackResumed"
    }
}

/// Emitted when playback finishes naturally (reached end)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlaybackFinished {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub episode_id: Uuid,
    pub duration_seconds: u64,
}

impl PlaybackFinished {
    pub fn new(episode_id: Uuid, duration_seconds: u64) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            episode_id,
            duration_seconds,
        }
    }
}

impl DomainEvent for PlaybackFinished {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "PlaybackFinished"
    }
}

// ============================================================================
// SUBTITLE EVENTS
// ============================================================================

/// Emitted when a subtitle file is detected
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SubtitleDetected {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub file_id: Uuid,
    pub format: String, // "SRT", "ASS", "VTT"
    pub language: String,
}

impl SubtitleDetected {
    pub fn new(file_id: Uuid, format: String, language: String) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            file_id,
            format,
            language,
        }
    }
}

impl DomainEvent for SubtitleDetected {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "SubtitleDetected"
    }
}

/// Emitted when subtitle style is applied
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SubtitleStyleApplied {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub subtitle_id: Uuid,
    pub new_subtitle_id: Uuid, // The derived subtitle
}

impl SubtitleStyleApplied {
    pub fn new(subtitle_id: Uuid, new_subtitle_id: Uuid) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            subtitle_id,
            new_subtitle_id,
        }
    }
}

impl DomainEvent for SubtitleStyleApplied {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "SubtitleStyleApplied"
    }
}

/// Emitted when subtitle timing is adjusted
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SubtitleTimingAdjusted {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub subtitle_id: Uuid,
    pub new_subtitle_id: Uuid, // The derived subtitle
    pub offset_ms: i64,
}

impl SubtitleTimingAdjusted {
    pub fn new(subtitle_id: Uuid, new_subtitle_id: Uuid, offset_ms: i64) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            subtitle_id,
            new_subtitle_id,
            offset_ms,
        }
    }
}

impl DomainEvent for SubtitleTimingAdjusted {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "SubtitleTimingAdjusted"
    }
}

/// Emitted when a new subtitle version is created from transformation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SubtitleVersionCreated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub subtitle_id: Uuid,
    pub version: u32,
}

impl SubtitleVersionCreated {
    pub fn new(subtitle_id: Uuid, version: u32) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            subtitle_id,
            version,
        }
    }
}

impl DomainEvent for SubtitleVersionCreated {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "SubtitleVersionCreated"
    }
}

// ============================================================================
// STATISTICS EVENTS
// ============================================================================

/// Emitted when statistics are recalculated
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StatisticsRebuilt {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub statistics_type: String, // "global", "per_anime", "per_period"
}

impl StatisticsRebuilt {
    pub fn new(statistics_type: String) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            statistics_type,
        }
    }
}

impl DomainEvent for StatisticsRebuilt {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "StatisticsRebuilt"
    }
}

/// Emitted when statistics are updated incrementally
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StatisticsUpdated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
}

impl StatisticsUpdated {
    pub fn new() -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
        }
    }
}

impl DomainEvent for StatisticsUpdated {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "StatisticsUpdated"
    }
}

// ============================================================================
// EXTERNAL INTEGRATION EVENTS
// ============================================================================

/// Emitted when external metadata is requested
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExternalMetadataRequested {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub anime_id: Uuid,
    pub provider: String, // "AniList"
}

impl ExternalMetadataRequested {
    pub fn new(anime_id: Uuid, provider: String) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            anime_id,
            provider,
        }
    }
}

impl DomainEvent for ExternalMetadataRequested {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "ExternalMetadataRequested"
    }
}

/// Emitted when external metadata is fetched
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExternalMetadataFetched {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub anime_id: Uuid,
    pub provider: String,
    pub external_id: String,
}

impl ExternalMetadataFetched {
    pub fn new(anime_id: Uuid, provider: String, external_id: String) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            anime_id,
            provider,
            external_id,
        }
    }
}

impl DomainEvent for ExternalMetadataFetched {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "ExternalMetadataFetched"
    }
}

/// Emitted when external metadata is linked to an anime
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExternalMetadataLinked {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub anime_id: Uuid,
    pub provider: String,
    pub external_id: String,
}

impl ExternalMetadataLinked {
    pub fn new(anime_id: Uuid, provider: String, external_id: String) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            anime_id,
            provider,
            external_id,
        }
    }
}

impl DomainEvent for ExternalMetadataLinked {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "ExternalMetadataLinked"
    }
}


--- FILE: src-tauri\src\infrastructure\mod.rs ---
// src-tauri/src/infrastructure/mod.rs
//
// Infrastructure Layer
//
// Contains implementation details that support the domain
// but are not part of the domain itself.
//
// RULES:
// - Infrastructure serves the domain
// - Infrastructure never dictates domain behavior
// - Infrastructure is replaceable

pub mod subtitle_workspace;

pub use subtitle_workspace::{
    SubtitleWorkspace, SubtitleWorkspaceCleaned, SubtitleWorkspaceCreated,
};


--- FILE: src-tauri\src\infrastructure\subtitle_workspace.rs ---
// src-tauri/src/infrastructure/subtitle_workspace.rs
//
// Subtitle Workspace Management
//
// CRITICAL RULES:
// - One workspace per subtitle transformation session
// - Original files are NEVER modified
// - Cleanup requires explicit confirmation
// - All operations are traceable

use chrono::{DateTime, Utc};
use std::fs;
use std::path::{Path, PathBuf};
use uuid::Uuid;

use crate::error::{AppError, AppResult};

/// Represents a temporary workspace for subtitle transformations
///
/// INVARIANTS:
/// - Each workspace has a unique ID
/// - Workspace contains a working copy of the subtitle
/// - Original file is never touched
/// - Cleanup must be explicit
#[derive(Debug, Clone)]
pub struct SubtitleWorkspace {
    /// Unique workspace identifier
    pub id: Uuid,

    /// Path to the workspace directory
    pub workspace_dir: PathBuf,

    /// Path to the original subtitle file (read-only)
    pub original_file: PathBuf,

    /// Path to the working copy in workspace
    pub working_file: PathBuf,

    /// When this workspace was created
    pub created_at: DateTime<Utc>,

    /// Whether this workspace has been cleaned up
    pub is_cleaned: bool,
}

impl SubtitleWorkspace {
    /// Create a new workspace for a subtitle file
    ///
    /// This will:
    /// 1. Create a temporary directory
    /// 2. Copy the original file into it
    /// 3. Return a workspace handle
    ///
    /// The original file is NEVER modified.
    pub fn new(original_file: PathBuf) -> AppResult<Self> {
        // Validate original file exists
        if !original_file.exists() {
            return Err(AppError::Other(format!(
                "Original subtitle file not found: {:?}",
                original_file
            )));
        }

        // Create workspace directory
        let workspace_id = Uuid::new_v4();
        let base_temp = std::env::temp_dir();
        let workspace_dir = base_temp
            .join("animehub")
            .join("subtitle_workspaces")
            .join(workspace_id.to_string());

        fs::create_dir_all(&workspace_dir).map_err(|e| AppError::Io(e))?;

        // Copy original file to workspace
        let filename = original_file
            .file_name()
            .ok_or_else(|| AppError::Other("Invalid filename".to_string()))?;
        let working_file = workspace_dir.join(filename);

        fs::copy(&original_file, &working_file).map_err(|e| AppError::Io(e))?;

        Ok(Self {
            id: workspace_id,
            workspace_dir,
            original_file,
            working_file,
            created_at: Utc::now(),
            is_cleaned: false,
        })
    }

    /// Get the path to the working file
    ///
    /// This is the file that should be modified during transformations.
    pub fn working_file_path(&self) -> &Path {
        &self.working_file
    }

    /// Get the path to the original file (read-only)
    pub fn original_file_path(&self) -> &Path {
        &self.original_file
    }

    /// Check if the workspace is still valid
    pub fn is_valid(&self) -> bool {
        !self.is_cleaned && self.workspace_dir.exists()
    }

    /// Clean up the workspace
    ///
    /// This removes the temporary directory and all its contents.
    ///
    /// CRITICAL: This NEVER touches the original file.
    /// CRITICAL: This should only be called after success or explicit cancellation.
    pub fn cleanup(&mut self) -> AppResult<()> {
        if self.is_cleaned {
            return Ok(()); // Already cleaned
        }

        // Verify we're only deleting inside temp directory
        let temp_base = std::env::temp_dir()
            .join("animehub")
            .join("subtitle_workspaces");
        if !self.workspace_dir.starts_with(&temp_base) {
            return Err(AppError::Other(
                "Workspace directory is not in expected temp location".to_string(),
            ));
        }

        // Delete workspace directory
        if self.workspace_dir.exists() {
            fs::remove_dir_all(&self.workspace_dir).map_err(|e| AppError::Io(e))?;
        }

        self.is_cleaned = true;
        Ok(())
    }

    /// Copy the working file to a destination
    ///
    /// This is used to save the transformed subtitle to its final location.
    pub fn copy_working_file_to(&self, destination: &Path) -> AppResult<()> {
        if !self.is_valid() {
            return Err(AppError::Other("Workspace is not valid".to_string()));
        }

        // Create parent directory if needed
        if let Some(parent) = destination.parent() {
            fs::create_dir_all(parent).map_err(|e| AppError::Io(e))?;
        }

        fs::copy(&self.working_file, destination).map_err(|e| AppError::Io(e))?;

        Ok(())
    }
}

impl Drop for SubtitleWorkspace {
    fn drop(&mut self) {
        // Attempt cleanup on drop, but don't panic if it fails
        if !self.is_cleaned {
            let _ = self.cleanup();
        }
    }
}

// ============================================================================
// WORKSPACE EVENTS
// ============================================================================

/// Events specific to workspace lifecycle
use crate::events::types::DomainEvent;
use serde::{Deserialize, Serialize};

/// Emitted when a subtitle workspace is created
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SubtitleWorkspaceCreated {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub workspace_id: Uuid,
    pub subtitle_id: Uuid,
}

impl SubtitleWorkspaceCreated {
    pub fn new(workspace_id: Uuid, subtitle_id: Uuid) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            workspace_id,
            subtitle_id,
        }
    }
}

impl DomainEvent for SubtitleWorkspaceCreated {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "SubtitleWorkspaceCreated"
    }
}

/// Emitted when a subtitle workspace is cleaned up
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SubtitleWorkspaceCleaned {
    pub event_id: Uuid,
    pub occurred_at: DateTime<Utc>,
    pub workspace_id: Uuid,
}

impl SubtitleWorkspaceCleaned {
    pub fn new(workspace_id: Uuid) -> Self {
        Self {
            event_id: Uuid::new_v4(),
            occurred_at: Utc::now(),
            workspace_id,
        }
    }
}

impl DomainEvent for SubtitleWorkspaceCleaned {
    fn event_id(&self) -> Uuid {
        self.event_id
    }
    fn occurred_at(&self) -> DateTime<Utc> {
        self.occurred_at
    }
    fn event_type(&self) -> &'static str {
        "SubtitleWorkspaceCleaned"
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs::File;
    use std::io::Write;

    fn create_test_subtitle() -> PathBuf {
        let temp_dir = std::env::temp_dir();
        let test_file = temp_dir.join(format!("test_subtitle_{}.srt", Uuid::new_v4()));

        let mut file = File::create(&test_file).unwrap();
        file.write_all(b"1\n00:00:01,000 --> 00:00:03,000\nTest subtitle\n")
            .unwrap();

        test_file
    }

    #[test]
    fn test_workspace_creation() {
        let original = create_test_subtitle();
        let workspace = SubtitleWorkspace::new(original.clone()).unwrap();

        assert!(workspace.is_valid());
        assert!(workspace.workspace_dir.exists());
        assert!(workspace.working_file.exists());
        assert_eq!(workspace.original_file, original);

        // Cleanup
        let _ = fs::remove_file(&original);
    }

    #[test]
    fn test_workspace_cleanup() {
        let original = create_test_subtitle();
        let mut workspace = SubtitleWorkspace::new(original.clone()).unwrap();

        let workspace_dir = workspace.workspace_dir.clone();

        workspace.cleanup().unwrap();

        assert!(workspace.is_cleaned);
        assert!(!workspace_dir.exists());
        assert!(original.exists()); // Original untouched

        // Cleanup
        let _ = fs::remove_file(&original);
    }

    #[test]
    fn test_copy_working_file() {
        let original = create_test_subtitle();
        let workspace = SubtitleWorkspace::new(original.clone()).unwrap();

        let dest = std::env::temp_dir().join(format!("dest_{}.srt", Uuid::new_v4()));

        workspace.copy_working_file_to(&dest).unwrap();

        assert!(dest.exists());

        // Cleanup
        let _ = fs::remove_file(&original);
        let _ = fs::remove_file(&dest);
    }

    #[test]
    fn test_original_never_modified() {
        let original = create_test_subtitle();
        let original_content = fs::read_to_string(&original).unwrap();

        let mut workspace = SubtitleWorkspace::new(original.clone()).unwrap();

        // Modify working file
        fs::write(&workspace.working_file, "MODIFIED").unwrap();

        // Cleanup
        workspace.cleanup().unwrap();

        // Original should be unchanged
        let final_content = fs::read_to_string(&original).unwrap();
        assert_eq!(original_content, final_content);

        // Cleanup
        let _ = fs::remove_file(&original);
    }
}


--- FILE: src-tauri\src\integrations\anilist\client.rs ---
// src-tauri/src/integrations/anilist/client.rs
//
// AniList API Integration - Phase 5 Real Implementation
//
// ARCHITECTURE:
// - GraphQL client for AniList API
// - Handles authentication, rate limiting, pagination
// - Maps external data ‚Üí internal DTOs (NO domain mutation)
// - Used by ExternalIntegrationService
//
// CRITICAL RULES:
// - This is INFRASTRUCTURE, not DOMAIN
// - Never creates or modifies domain entities directly
// - Returns DTOs that services can map
// - Handles all external API concerns

use crate::error::{AppError, AppResult};
use reqwest::{header, Client};
use serde::{Deserialize, Serialize};
use serde_json::json;
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};

/// AniList anime metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AniListAnime {
    pub id: i64,
    pub title: AniListTitle,
    pub episodes: Option<i32>,
    pub status: String,
    pub start_date: Option<AniListDate>,
    pub end_date: Option<AniListDate>,
    pub genres: Vec<String>,
    pub cover_image: String,
    pub description: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AniListTitle {
    pub romaji: Option<String>,
    pub english: Option<String>,
    pub native: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AniListDate {
    pub year: Option<i32>,
    pub month: Option<i32>,
    pub day: Option<i32>,
}

/// GraphQL response wrapper
#[derive(Debug, Deserialize)]
struct GraphQLResponse<T> {
    data: Option<T>,
    errors: Option<Vec<GraphQLError>>,
}

#[derive(Debug, Deserialize)]
struct GraphQLError {
    message: String,
    #[allow(dead_code)] // Part of GraphQL error response schema
    status: Option<i32>,
}

/// Search results wrapper
#[derive(Debug, Deserialize)]
struct SearchData {
    #[serde(rename = "Page")]
    page: PageData,
}

#[derive(Debug, Deserialize)]
struct PageData {
    media: Vec<MediaData>,
}

/// Single anime query wrapper
#[derive(Debug, Deserialize)]
struct AnimeData {
    #[serde(rename = "Media")]
    media: MediaData,
}

/// Media data from AniList
#[derive(Debug, Deserialize)]
struct MediaData {
    id: i64,
    title: TitleData,
    episodes: Option<i32>,
    status: String,
    #[serde(rename = "startDate")]
    start_date: Option<DateData>,
    #[serde(rename = "endDate")]
    end_date: Option<DateData>,
    genres: Vec<String>,
    #[serde(rename = "coverImage")]
    cover_image: CoverImageData,
    description: Option<String>,
}

#[derive(Debug, Deserialize)]
struct TitleData {
    romaji: Option<String>,
    english: Option<String>,
    native: Option<String>,
}

#[derive(Debug, Deserialize)]
struct DateData {
    year: Option<i32>,
    month: Option<i32>,
    day: Option<i32>,
}

#[derive(Debug, Deserialize)]
struct CoverImageData {
    large: String,
}

/// Rate limiter state
struct RateLimiter {
    last_request: Instant,
    min_interval: Duration,
}

impl RateLimiter {
    fn new() -> Self {
        Self {
            last_request: Instant::now() - Duration::from_secs(60),
            min_interval: Duration::from_millis(1000), // 1 request per second
        }
    }

    fn wait_if_needed(&mut self) {
        let elapsed = self.last_request.elapsed();
        if elapsed < self.min_interval {
            let wait_time = self.min_interval - elapsed;
            std::thread::sleep(wait_time);
        }
        self.last_request = Instant::now();
    }
}

/// AniList API Client
pub struct AniListClient {
    base_url: String,
    http_client: Client,
    rate_limiter: Arc<Mutex<RateLimiter>>,
    auth_token: Option<String>,
}

impl AniListClient {
    /// Create a new AniList client
    pub fn new() -> Self {
        let http_client = Client::builder()
            .timeout(Duration::from_secs(30))
            .build()
            .expect("Failed to create HTTP client");

        Self {
            base_url: "https://graphql.anilist.co".to_string(),
            http_client,
            rate_limiter: Arc::new(Mutex::new(RateLimiter::new())),
            auth_token: None,
        }
    }

    /// Create client with authentication token
    pub fn with_auth(token: String) -> Self {
        let mut client = Self::new();
        client.auth_token = Some(token);
        client
    }

    /// Search for anime by title
    ///
    /// Returns up to 10 results
    pub async fn search_anime(&self, query: &str) -> AppResult<Vec<AniListAnime>> {
        // Rate limiting
        {
            let mut limiter = self.rate_limiter.lock().unwrap();
            limiter.wait_if_needed();
        }

        // GraphQL query
        let graphql_query = r#"
            query ($search: String) {
                Page(page: 1, perPage: 10) {
                    media(search: $search, type: ANIME) {
                        id
                        title {
                            romaji
                            english
                            native
                        }
                        episodes
                        status
                        startDate {
                            year
                            month
                            day
                        }
                        endDate {
                            year
                            month
                            day
                        }
                        genres
                        coverImage {
                            large
                        }
                        description
                    }
                }
            }
        "#;

        let variables = json!({
            "search": query
        });

        let response_data: SearchData = self.execute_query(graphql_query, variables).await?;

        // Map to AniListAnime
        let animes = response_data
            .page
            .media
            .into_iter()
            .map(Self::map_media_to_anime)
            .collect();

        Ok(animes)
    }

    /// Get anime by AniList ID
    pub async fn get_anime(&self, anilist_id: i64) -> AppResult<AniListAnime> {
        // Rate limiting
        {
            let mut limiter = self.rate_limiter.lock().unwrap();
            limiter.wait_if_needed();
        }

        // GraphQL query
        let graphql_query = r#"
            query ($id: Int) {
                Media(id: $id, type: ANIME) {
                    id
                    title {
                        romaji
                        english
                        native
                    }
                    episodes
                    status
                    startDate {
                        year
                        month
                        day
                    }
                    endDate {
                        year
                        month
                        day
                    }
                    genres
                    coverImage {
                        large
                    }
                    description
                }
            }
        "#;

        let variables = json!({
            "id": anilist_id
        });

        let response_data: AnimeData = self.execute_query(graphql_query, variables).await?;

        Ok(Self::map_media_to_anime(response_data.media))
    }

    /// Fetch detailed metadata (same as get_anime for now)
    pub async fn fetch_metadata(&self, anilist_id: i64) -> AppResult<AniListAnime> {
        self.get_anime(anilist_id).await
    }

    // ========================================================================
    // INTERNAL: GraphQL Execution
    // ========================================================================

    /// Execute a GraphQL query
    async fn execute_query<T>(&self, query: &str, variables: serde_json::Value) -> AppResult<T>
    where
        T: for<'de> Deserialize<'de>,
    {
        let body = json!({
            "query": query,
            "variables": variables
        });

        // Build request
        let mut request = self
            .http_client
            .post(&self.base_url)
            .header(header::CONTENT_TYPE, "application/json")
            .header(header::ACCEPT, "application/json");

        // Add auth token if present
        if let Some(token) = &self.auth_token {
            request = request.header(header::AUTHORIZATION, format!("Bearer {}", token));
        }

        // Send request
        let response = request
            .json(&body)
            .send()
            .await
            .map_err(|e| AppError::Other(format!("AniList API request failed: {}", e)))?;

        // Check HTTP status
        if !response.status().is_success() {
            return Err(AppError::Other(format!(
                "AniList API returned status: {}",
                response.status()
            )));
        }

        // Parse GraphQL response
        let graphql_response: GraphQLResponse<T> = response
            .json()
            .await
            .map_err(|e| AppError::Other(format!("Failed to parse AniList response: {}", e)))?;

        // Check for GraphQL errors
        if let Some(errors) = graphql_response.errors {
            let error_messages: Vec<String> = errors.iter().map(|e| e.message.clone()).collect();

            return Err(AppError::Other(format!(
                "AniList API errors: {}",
                error_messages.join(", ")
            )));
        }

        // Extract data
        graphql_response
            .data
            .ok_or_else(|| AppError::Other("AniList API returned no data".to_string()))
    }

    /// Map MediaData to AniListAnime
    fn map_media_to_anime(media: MediaData) -> AniListAnime {
        AniListAnime {
            id: media.id,
            title: AniListTitle {
                romaji: media.title.romaji,
                english: media.title.english,
                native: media.title.native,
            },
            episodes: media.episodes,
            status: media.status,
            start_date: media.start_date.map(|d| AniListDate {
                year: d.year,
                month: d.month,
                day: d.day,
            }),
            end_date: media.end_date.map(|d| AniListDate {
                year: d.year,
                month: d.month,
                day: d.day,
            }),
            genres: media.genres,
            cover_image: media.cover_image.large,
            description: media.description,
        }
    }
}

impl Default for AniListClient {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_client_creation() {
        let client = AniListClient::new();
        assert_eq!(client.base_url, "https://graphql.anilist.co");
        assert!(client.auth_token.is_none());
    }

    #[test]
    fn test_client_with_auth() {
        let client = AniListClient::with_auth("test_token".to_string());
        assert!(client.auth_token.is_some());
    }

    // Note: Real API tests would be in integration test suite
    // and would use mocked responses or test against real API
}


--- FILE: src-tauri\src\integrations\anilist\mod.rs ---
// src-tauri/src/integrations/anilist/mod.rs

pub mod client;

pub use client::{AniListAnime, AniListClient, AniListDate, AniListTitle};


--- FILE: src-tauri\src\integrations\mod.rs ---
// src-tauri/src/integrations/mod.rs
//
// External Integrations Module
//
// Phase 4: Stub implementations
// Phase 5: Full implementation

pub mod anilist;
pub mod mpv;

pub use anilist::client::{AniListAnime, AniListClient, AniListDate, AniListTitle};
pub use mpv::client::MpvClient;


--- FILE: src-tauri\src\integrations\mpv\client.rs ---
// src-tauri/src/integrations/mpv/client.rs
//
// MPV Player Integration - Cross-Platform Implementation
//
// CRITICAL: Uses platform-specific IPC:
// - Windows: Named Pipes (\\.\pipe\animehub-mpv)
// - Unix: Unix Domain Sockets (/tmp/animehub-mpv.sock)
//
// PHASE 4 CORRECTIONS:
// - Made cross-platform compilable (Windows-specific code behind cfg)
// - Stub implementation for non-Windows platforms

use serde::{Deserialize, Serialize};
use serde_json::json;
use std::path::PathBuf;
use std::process::{Child, Command, Stdio};
use std::sync::{Arc, Mutex};

use crate::error::{AppError, AppResult};

/// MPV IPC command envelope
#[derive(Debug, Serialize)]
struct MpvCommand {
    command: Vec<serde_json::Value>,
}

/// MPV IPC response envelope
#[derive(Debug, Deserialize)]
struct MpvResponse {
    error: String,
    #[serde(default)]
    data: Option<serde_json::Value>,
}

/// MPV Client
///
/// Handles process lifecycle and IPC communication.
/// Note: This client does not persist domain state or call services.
pub struct MpvClient {
    /// MPV process handle (Arc/Mutex for thread-safe access from commands)
    process: Arc<Mutex<Option<Child>>>,
    /// Predefined pipe/socket name for AnimeHub
    #[cfg(target_os = "windows")]
    pipe_name: String,
    #[cfg(not(target_os = "windows"))]
    socket_path: String,
}

impl MpvClient {
    /// Creates a new instance of the MPV client.
    pub fn new() -> AppResult<Self> {
        Ok(Self {
            process: Arc::new(Mutex::new(None)),
            #[cfg(target_os = "windows")]
            pipe_name: r"\\.\pipe\animehub-mpv".to_string(),
            #[cfg(not(target_os = "windows"))]
            socket_path: "/tmp/animehub-mpv.sock".to_string(),
        })
    }

    /// Launches MPV with IPC enabled and starts playback.
    pub fn launch(&self, video_path: PathBuf) -> AppResult<PathBuf> {
        if !video_path.exists() {
            return Err(AppError::Other(format!(
                "Video file not found: {:?}",
                video_path
            )));
        }

        // Cleanup existing process
        self.stop()?;

        let mut cmd = Command::new("mpv");
        
        #[cfg(target_os = "windows")]
        cmd.arg(format!("--input-ipc-server={}", self.pipe_name));
        
        #[cfg(not(target_os = "windows"))]
        cmd.arg(format!("--input-ipc-server={}", self.socket_path));
        
        cmd.arg("--idle=yes")
            .arg("--force-window=yes")
            .arg("--keep-open=yes")
            .arg(&video_path)
            .stdout(Stdio::null())
            .stderr(Stdio::null());

        let child = cmd
            .spawn()
            .map_err(|e| AppError::Other(format!("Failed to spawn MPV: {}", e)))?;

        {
            let mut proc_guard = self.process.lock().unwrap();
            *proc_guard = Some(child);
        }

        // Wait for MPV to create the pipe server
        std::thread::sleep(std::time::Duration::from_millis(600));

        Ok(video_path)
    }

    /// Stops playback and kills the MPV process.
    pub fn stop(&self) -> AppResult<()> {
        if self.is_running() {
            let _ = self.send_command(&["quit"]);
        }

        let mut proc_guard = self.process.lock().unwrap();
        if let Some(mut child) = proc_guard.take() {
            let _ = child.kill();
            let _ = child.wait();
        }

        Ok(())
    }

    /// Checks if MPV is currently active.
    pub fn is_running(&self) -> bool {
        let mut proc_guard = self.process.lock().unwrap();
        if let Some(ref mut child) = *proc_guard {
            match child.try_wait() {
                Ok(None) => true,
                _ => {
                    *proc_guard = None;
                    false
                }
            }
        } else {
            false
        }
    }

    // --- Media Control Commands ---

    pub fn pause(&self) -> AppResult<()> {
        self.send_command(&["set_property", "pause", "yes"])?;
        Ok(())
    }

    pub fn resume(&self) -> AppResult<()> {
        self.send_command(&["set_property", "pause", "no"])?;
        Ok(())
    }

    pub fn seek(&self, position_seconds: u64) -> AppResult<()> {
        self.send_command(&["seek", &position_seconds.to_string(), "absolute"])?;
        Ok(())
    }

    pub fn get_position(&self) -> AppResult<u64> {
        let response = self.send_command(&["get_property", "time-pos"])?;
        let pos = response.data.and_then(|v| v.as_f64()).unwrap_or(0.0);
        Ok(pos as u64)
    }

    pub fn get_duration(&self) -> AppResult<Option<u64>> {
        let response = self.send_command(&["get_property", "duration"])?;
        Ok(response.data.and_then(|v| v.as_f64()).map(|d| d as u64))
    }

    // --- IPC Implementation ---

    #[cfg(target_os = "windows")]
    fn send_command(&self, command: &[&str]) -> AppResult<MpvResponse> {
        use std::ffi::OsStr;
        use std::os::windows::ffi::OsStrExt;
        use windows::core::PCWSTR;
        use windows::Win32::Foundation::{CloseHandle, HANDLE, INVALID_HANDLE_VALUE};
        use windows::Win32::Storage::FileSystem::{
            CreateFileW, ReadFile, WriteFile, FILE_ATTRIBUTE_NORMAL, FILE_GENERIC_READ,
            FILE_GENERIC_WRITE, FILE_SHARE_READ, FILE_SHARE_WRITE, OPEN_EXISTING,
        };

        if !self.is_running() {
            return Err(AppError::Other("MPV is not running".to_string()));
        }

        // 1. Prepare Wide String for Windows API
        let pipe_path: Vec<u16> = OsStr::new(&self.pipe_name)
            .encode_wide()
            .chain(std::iter::once(0))
            .collect();

        // 2. Open the Named Pipe
        let handle = unsafe {
            CreateFileW(
                PCWSTR(pipe_path.as_ptr()),
                FILE_GENERIC_READ.0 | FILE_GENERIC_WRITE.0,
                FILE_SHARE_READ | FILE_SHARE_WRITE,
                None, // Security
                OPEN_EXISTING,
                FILE_ATTRIBUTE_NORMAL,
                HANDLE::default(),
            )
        }
        .map_err(|e| AppError::Other(format!("IPC Connection Error: {}", e)))?;

        if handle == INVALID_HANDLE_VALUE {
            return Err(AppError::Other("Invalid Pipe Handle".to_string()));
        }

        // Use RAII guard to ensure handle is closed
        struct HandleGuard(HANDLE);
        impl Drop for HandleGuard {
            fn drop(&mut self) {
                if !self.0.is_invalid() {
                    unsafe {
                        let _ = CloseHandle(self.0);
                    }
                }
            }
        }
        let _guard = HandleGuard(handle);

        // 3. Serialize Command (MPV expects newline-delimited JSON)
        let cmd_json = MpvCommand {
            command: command.iter().map(|&s| json!(s)).collect(),
        };
        let mut payload =
            serde_json::to_string(&cmd_json).map_err(|e| AppError::Serialization(e))?;
        payload.push('\n');

        // 4. Write to Pipe
        let mut written: u32 = 0;
        unsafe { WriteFile(handle, Some(payload.as_bytes()), Some(&mut written), None) }
            .map_err(|e| AppError::Other(format!("IPC Write error: {}", e)))?;

        // 5. Read Response
        let mut buffer = [0u8; 2048];
        let mut read: u32 = 0;
        unsafe { ReadFile(handle, Some(&mut buffer), Some(&mut read), None) }
            .map_err(|e| AppError::Other(format!("IPC Read error: {}", e)))?;

        // 6. Parse and Validate
        let response_str = std::str::from_utf8(&buffer[..(read as usize)])
            .map_err(|_| AppError::Other("IPC response invalid UTF-8".to_string()))?;

        let response: MpvResponse =
            serde_json::from_str(response_str.trim()).map_err(|e| AppError::Serialization(e))?;

        if response.error != "success" {
            return Err(AppError::Other(format!(
                "MPV IPC Error: {}",
                response.error
            )));
        }

        Ok(response)
    }

    #[cfg(not(target_os = "windows"))]
    fn send_command(&self, command: &[&str]) -> AppResult<MpvResponse> {
        use std::io::{Read, Write};
        use std::os::unix::net::UnixStream;

        if !self.is_running() {
            return Err(AppError::Other("MPV is not running".to_string()));
        }

        // Connect to Unix socket
        let mut stream = UnixStream::connect(&self.socket_path)
            .map_err(|e| AppError::Other(format!("IPC Connection Error: {}", e)))?;

        // Serialize Command
        let cmd_json = MpvCommand {
            command: command.iter().map(|&s| json!(s)).collect(),
        };
        let mut payload =
            serde_json::to_string(&cmd_json).map_err(|e| AppError::Serialization(e))?;
        payload.push('\n');

        // Write to socket
        stream
            .write_all(payload.as_bytes())
            .map_err(|e| AppError::Other(format!("IPC Write error: {}", e)))?;

        // Read response
        let mut buffer = [0u8; 2048];
        let read = stream
            .read(&mut buffer)
            .map_err(|e| AppError::Other(format!("IPC Read error: {}", e)))?;

        // Parse and Validate
        let response_str = std::str::from_utf8(&buffer[..read])
            .map_err(|_| AppError::Other("IPC response invalid UTF-8".to_string()))?;

        let response: MpvResponse =
            serde_json::from_str(response_str.trim()).map_err(|e| AppError::Serialization(e))?;

        if response.error != "success" {
            return Err(AppError::Other(format!(
                "MPV IPC Error: {}",
                response.error
            )));
        }

        Ok(response)
    }
}

impl Drop for MpvClient {
    fn drop(&mut self) {
        let _ = self.stop();
    }
}

impl Default for MpvClient {
    fn default() -> Self {
        Self::new().expect("Critical: Failed to initialize MPV Client")
    }
}


--- FILE: src-tauri\src\integrations\mpv\mod.rs ---
// src-tauri/src/integrations/mpv/mod.rs

pub mod client;

pub use client::MpvClient;


--- FILE: src-tauri\src\integrations\mpv\windows.rs ---
use std::ffi::OsStr;
use std::iter::once;
use std::os::windows::ffi::OsStrExt;
use std::path::PathBuf;
use std::ptr::null_mut;
use std::process::{Command, Child};
use std::io::{Read, Write};

use windows::Win32::Foundation::*;
use windows::Win32::Storage::FileSystem::*;
use windows::Win32::System::Pipes::*;

use anyhow::{Result, anyhow};

const PIPE_NAME: &str = r"\\.\pipe\mpv-animehub";

pub struct MpvClient {
    process: Child,
    pipe: HANDLE,
}

impl MpvClient {
    pub fn launch(video: PathBuf) -> Result<Self> {
        let mut process = Command::new("mpv")
            .arg(video)
            .arg(format!("--input-ipc-server={}", PIPE_NAME))
            .spawn()
            .map_err(|e| anyhow!("Failed to start mpv: {}", e))?;

        // Espera MPV criar o pipe
        let pipe = loop {
            let wide: Vec<u16> = OsStr::new(PIPE_NAME)
                .encode_wide()
                .chain(once(0))
                .collect();

            unsafe {
                let handle = CreateFileW(
                    PCWSTR(wide.as_ptr()),
                    FILE_GENERIC_READ | FILE_GENERIC_WRITE,
                    FILE_SHARE_READ | FILE_SHARE_WRITE,
                    None,
                    OPEN_EXISTING,
                    FILE_ATTRIBUTE_NORMAL,
                    None,
                );

                if handle != INVALID_HANDLE_VALUE {
                    break handle;
                }
            }

            std::thread::sleep(std::time::Duration::from_millis(50));
        };

        Ok(Self { process, pipe })
    }

    pub fn send(&self, command: &str) -> Result<()> {
        let mut bytes = command.as_bytes().to_vec();
        bytes.push(b'\n');

        unsafe {
            let mut written = 0;
            WriteFile(
                self.pipe,
                Some(bytes.as_ptr() as _),
                bytes.len() as u32,
                Some(&mut written),
                None,
            )
            .ok()
            .map_err(|_| anyhow!("Failed to write to MPV pipe"))?;
        }

        Ok(())
    }

    pub fn pause(&self) -> Result<()> {
        self.send(r#"{"command":["set_property","pause",true]}"#)
    }

    pub fn resume(&self) -> Result<()> {
        self.send(r#"{"command":["set_property","pause",false]}"#)
    }

    pub fn seek(&self, seconds: i64) -> Result<()> {
        self.send(&format!(
            r#"{{"command":["seek",{}, "absolute"]}}"#,
            seconds
        ))
    }

    pub fn stop(&mut self) -> Result<()> {
        self.send(r#"{"command":["quit"]}"#)?;
        self.process.kill().ok();
        unsafe { CloseHandle(self.pipe) };
        Ok(())
    }
}


--- FILE: src-tauri\src\lib.rs ---
// src-tauri/src/lib.rs
// AnimeHub - Local-first anime library manager
//
// Architecture:
// - Domain-centric: All business logic lives in domains (SEALED - Phase 3)
// - Event-driven: Services coordinate through events (SEALED - Phase 3)
// - Explicit: No implicit behavior, no magic
// - Local-first: User controls all data
// - Application Layer: UI boundary (Phase 4)
// - Materialization: Domain entity creation from resolution (Phase 5)

// ============================================================================
// SEALED FOUNDATION (Phase 3)
// ============================================================================

pub mod db;
pub mod domain;
pub mod error;
pub mod events;
pub mod infrastructure;
pub mod repositories;
pub mod services;

// ============================================================================
// APPLICATION LAYER (Phase 4)
// ============================================================================

pub mod application;
pub mod integrations;

// ============================================================================
// PUBLIC API - Domain Entities (Sealed)
// ============================================================================

pub use domain::{
    validate_anime,
    validate_anime_alias,
    validate_collection,
    validate_episode,
    validate_external_reference,
    validate_file,
    validate_subtitle,
    // Anime
    Anime,
    // Anime Alias
    AnimeAlias,
    AnimeStatistics,
    AnimeStatus,
    AnimeType,
    // Collection
    Collection,
    // Episode
    Episode,
    EpisodeNumber,
    EpisodeState,
    // External Reference
    ExternalReference,
    // File
    File,
    FileOrigin,
    FileType,
    GlobalStatistics,
    // Statistics
    StatisticsSnapshot,
    StatisticsType,
    // Subtitle
    Subtitle,
    SubtitleFormat,
    SubtitleTransformation,
    TransformationType,
};

// ============================================================================
// PUBLIC API - Error Types (Sealed)
// ============================================================================

pub use error::{AppError, AppResult};

// ============================================================================
// PUBLIC API - Events (Sealed)
// ============================================================================

pub use events::{
    create_event_bus,
    register_materialization_handlers,
    // Common events
    AnimeCreated,
    DomainEvent,
    EpisodeCompleted,
    EpisodeCreated,
    EpisodeResolved,
    EventBus,
    EventLogEntry,
    FileLinkedToEpisode,
    // Resolution events (Phase 4)
    FileResolved,
    // Materialization events (Phase 5)
    MaterializationBatchCompleted,
    MaterializationRecordCreated,
    PlaybackStarted,
    ResolutionBatchCompleted,
    ResolutionFailed,
};

// ============================================================================
// PUBLIC API - Database (Sealed)
// ============================================================================

pub use db::{create_connection_pool, initialize_database, ConnectionPool};

// ============================================================================
// PUBLIC API - Repositories (Sealed)
// ============================================================================

pub use repositories::{
    AnimeAliasRepository,
    AnimeRepository,
    CollectionRepository,
    EpisodeRepository,
    ExternalReferenceRepository,
    FileRepository,
    // Materialization (Phase 5)
    MaterializationRepository,
    SqliteAnimeAliasRepository,
    SqliteAnimeRepository,
    SqliteCollectionRepository,
    SqliteExternalReferenceRepository,
    SqliteStatisticsRepository,
    SqliteSubtitleRepository,
    StatisticsRepository,
    SubtitleRepository,
};

// ============================================================================
// PUBLIC API - Infrastructure (Sealed)
// ============================================================================

pub use infrastructure::{SubtitleWorkspace, SubtitleWorkspaceCleaned, SubtitleWorkspaceCreated};

// ============================================================================
// PUBLIC API - Services (Sealed)
// ============================================================================

pub use services::{
    // Anime Service
    AnimeService,
    CreateAnimeRequest,
    CreateEpisodeRequest,
    EpisodeNumberDecision,
    // Episode Service
    EpisodeService,
    // External Integration Service
    ExternalIntegrationService,
    ExternalMetadata,
    FetchMetadataRequest,
    // File Service
    FileService,
    LinkExternalReferenceRequest,
    LinkFileRequest,

    MaterializationDecision,
    MaterializationEventType,
    MaterializationFingerprint,
    MaterializationOutcome,
    MaterializationRecord,
    MaterializationResult,
    // Materialization Service (Phase 5)
    MaterializationService,
    MergeAnimesRequest,

    MetadataSuggestions,

    ObserverConfig,

    // Playback Observer
    PlaybackObserver,
    // Playback Service
    PlaybackService,
    RegisterFileRequest,

    ResolutionRules,

    // Resolution Service (Phase 4 - FROZEN)
    ResolutionService,
    StartPlaybackRequest,

    // Statistics Service
    StatisticsService,

    StyleTransformRequest,
    // Subtitle Service
    SubtitleService,
    TimingTransformRequest,

    UpdateAnimeRequest,
    UpdateEpisodeMetadataRequest,
};

// ============================================================================
// PUBLIC API - Application Layer (Phase 4)
// ============================================================================

pub use application::AppState;

// Re-export application submodules
pub use application::commands;
pub use application::dto;

// ============================================================================
// PUBLIC API - Integrations (Phase 4 - Stubs)
// ============================================================================

pub use integrations::{AniListAnime, AniListClient, MpvClient};


--- FILE: src-tauri\src\main.rs ---
// src-tauri/src/main.rs
// CORRECTED VERSION

#![cfg_attr(
    all(not(debug_assertions), target_os = "windows"),
    windows_subsystem = "windows"
)]

use std::sync::Arc;

// --- Corrected Imports ---
// Direct imports for Tauri command handler macro
use animehub::application::commands::*;
// Correct path for database module
use animehub::db::{create_connection_pool, initialize_database};
// All other necessary components for initialization
use animehub::application::state::AppState;
use animehub::events::EventBus;
use animehub::integrations::MpvClient;
use animehub::repositories::*;
use animehub::services::*;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 1. INFRASTRUCTURE
    let event_bus = Arc::new(EventBus::new());
    let pool = Arc::new(create_connection_pool()?);
    let mpv_client = Arc::new(MpvClient::new()?);

    // Initialize schema (idempotent)
    {
        let conn = pool.get()?;
        initialize_database(&conn)?;
    }

    // 2. REPOSITORIES
    // The type `Arc<dyn Trait>` is used to match the service constructor signatures exactly.
    let anime_repo: Arc<dyn AnimeRepository> = Arc::new(SqliteAnimeRepository::new(pool.clone()));
    let episode_repo: Arc<dyn EpisodeRepository> =
        Arc::new(SqliteEpisodeRepository::new(pool.clone()));
    let file_repo: Arc<dyn FileRepository> = Arc::new(SqliteFileRepository::new(pool.clone()));
    let subtitle_repo: Arc<dyn SubtitleRepository> =
        Arc::new(SqliteSubtitleRepository::new(pool.clone()));
    let collection_repo: Arc<dyn CollectionRepository> =
        Arc::new(SqliteCollectionRepository::new(pool.clone()));
    let external_ref_repo: Arc<dyn ExternalReferenceRepository> =
        Arc::new(SqliteExternalReferenceRepository::new(pool.clone()));
    let anime_alias_repo: Arc<dyn AnimeAliasRepository> =
        Arc::new(SqliteAnimeAliasRepository::new(pool.clone()));
    let statistics_repo: Arc<dyn StatisticsRepository> =
        Arc::new(SqliteStatisticsRepository::new(pool.clone()));

    // 3. SERVICES
    let anime_service = Arc::new(AnimeService::new(
        anime_repo.clone(),
        anime_alias_repo.clone(),
        external_ref_repo.clone(),
        event_bus.clone(),
    ));
    let episode_service = Arc::new(EpisodeService::new(
        episode_repo.clone(),
        anime_repo.clone(),
        file_repo.clone(),
        event_bus.clone(),
    ));
    let file_service = Arc::new(FileService::new(file_repo.clone(), event_bus.clone()));
    let playback_service = Arc::new(PlaybackService::new(
        episode_repo.clone(),
        file_repo.clone(),
        event_bus.clone(),
        mpv_client.clone(),
    ));
    let statistics_service = Arc::new(StatisticsService::new(
        statistics_repo.clone(),
        anime_repo.clone(),
        episode_repo.clone(),
        event_bus.clone(),
    ));
    let external_integration_service = Arc::new(ExternalIntegrationService::new(
        external_ref_repo.clone(),
        anime_repo.clone(),
        event_bus.clone(),
    ));
    let subtitle_service = Arc::new(SubtitleService::new(
        subtitle_repo.clone(),
        file_repo.clone(),
        event_bus.clone(),
    ));

    // 4. EVENT HANDLER REGISTRATION (WIRING)
    episode_service.register_event_handlers();
    statistics_service.register_event_handlers();

    // 5. APPLICATION STATE
    let app_state = AppState {
        event_bus,
        anime_service,
        episode_service,
        file_service,
        playback_service,
        statistics_service,
        external_integration_service,
        subtitle_service,
    };

    // 6. TAURI BOOTSTRAP
    tauri::Builder::default()
        .manage(app_state)
        .invoke_handler(tauri::generate_handler![
            // Commands are now in scope via `use` statements
            list_animes,
            get_anime,
            create_anime,
            update_anime,
            list_episodes,
            get_episode,
            create_episode,
            update_progress,
            mark_episode_completed,
            reset_episode_progress,
            scan_directory,
            get_episode_files,
            start_playback,
            toggle_pause_playback,
            seek_playback,
            stop_playback,
            get_episode_progress,
            get_global_statistics,
        ])
        .run(tauri::generate_context!())?;

    Ok(())
}


--- FILE: src-tauri\src\repositories\anime_alias_repository.rs ---
// src-tauri/src/repositories/anime_alias_repository.rs

use chrono::{DateTime, Utc};
use rusqlite::params;
use std::sync::Arc;
use uuid::Uuid;

use crate::db::ConnectionPool;
use crate::domain::AnimeAlias;
use crate::error::{AppError, AppResult};

pub trait AnimeAliasRepository: Send + Sync {
    fn save(&self, alias: &AnimeAlias) -> AppResult<()>;
    fn get_principal_for_alias(&self, anime_alias_id: Uuid) -> AppResult<Option<Uuid>>;
    fn list_aliases_for_principal(&self, anime_principal_id: Uuid) -> AppResult<Vec<AnimeAlias>>;
}

pub struct SqliteAnimeAliasRepository {
    pool: Arc<ConnectionPool>,
}

impl SqliteAnimeAliasRepository {
    pub fn new(pool: Arc<ConnectionPool>) -> Self {
        Self { pool }
    }
}

impl AnimeAliasRepository for SqliteAnimeAliasRepository {
    fn save(&self, alias: &AnimeAlias) -> AppResult<()> {
        let conn = self.pool.get()?;

        conn.execute(
            "INSERT OR REPLACE INTO anime_aliases (id, anime_principal_id, anime_alias_id, criado_em)
             VALUES (?1, ?2, ?3, ?4)",
            params![
                alias.id.to_string(),
                alias.anime_principal_id.to_string(),
                alias.anime_alias_id.to_string(),
                alias.criado_em.to_rfc3339(),
            ]
        )?;

        Ok(())
    }

    fn get_principal_for_alias(&self, anime_alias_id: Uuid) -> AppResult<Option<Uuid>> {
        let conn = self.pool.get()?;

        let mut stmt =
            conn.prepare("SELECT anime_principal_id FROM anime_aliases WHERE anime_alias_id = ?1")?;

        match stmt.query_row(params![anime_alias_id.to_string()], |row| {
            let id_str: String = row.get(0)?;
            Ok(id_str)
        }) {
            Ok(id_str) => Ok(Some(Uuid::parse_str(&id_str)?)),
            Err(rusqlite::Error::QueryReturnedNoRows) => Ok(None),
            Err(e) => Err(AppError::Database(e)),
        }
    }

    fn list_aliases_for_principal(&self, anime_principal_id: Uuid) -> AppResult<Vec<AnimeAlias>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare(
            "SELECT id, anime_principal_id, anime_alias_id, criado_em 
             FROM anime_aliases 
             WHERE anime_principal_id = ?1",
        )?;

        let aliases: Vec<AnimeAlias> = stmt
            .query_map(params![anime_principal_id.to_string()], |row| {
                let id = Uuid::parse_str(&row.get::<_, String>(0)?)
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;
                let principal_id = Uuid::parse_str(&row.get::<_, String>(1)?)
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;
                let alias_id = Uuid::parse_str(&row.get::<_, String>(2)?)
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;
                let criado_em = DateTime::parse_from_rfc3339(&row.get::<_, String>(3)?)
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
                    .with_timezone(&Utc);

                Ok(AnimeAlias {
                    id,
                    anime_principal_id: principal_id,
                    anime_alias_id: alias_id,
                    criado_em,
                })
            })?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(aliases)
    }
}


--- FILE: src-tauri\src\repositories\anime_repository.rs ---
// src-tauri/src/repositories/anime_repository.rs
//
// Anime persistence - Fixed error conversion

use chrono::{DateTime, Utc};
use rusqlite::{params, Row};
use std::sync::Arc;
use uuid::Uuid;

use crate::db::ConnectionPool;
use crate::domain::anime::{Anime, AnimeStatus, AnimeType};
use crate::error::{AppError, AppResult};

pub trait AnimeRepository: Send + Sync {
    fn save(&self, anime: &Anime) -> AppResult<()>;
    fn get_by_id(&self, id: Uuid) -> AppResult<Option<Anime>>;
    fn list_all(&self) -> AppResult<Vec<Anime>>;
    fn list_by_status(&self, status: AnimeStatus) -> AppResult<Vec<Anime>>;
    fn list_by_type(&self, tipo: AnimeType) -> AppResult<Vec<Anime>>;
    fn delete(&self, id: Uuid) -> AppResult<()>;
    fn exists(&self, id: Uuid) -> AppResult<bool>;
}

pub struct SqliteAnimeRepository {
    pool: Arc<ConnectionPool>,
}

impl SqliteAnimeRepository {
    pub fn new(pool: Arc<ConnectionPool>) -> Self {
        Self { pool }
    }

    /// Map database row to Anime - returns rusqlite::Error for query_map compatibility
    fn row_to_anime(row: &Row) -> Result<Anime, rusqlite::Error> {
        let id_str: String = row.get("id")?;
        let id = Uuid::parse_str(&id_str)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let titulo_principal: String = row.get("titulo_principal")?;

        let titulos_alt_json: String = row.get("titulos_alternativos")?;
        let titulos_alternativos: Vec<String> = serde_json::from_str(&titulos_alt_json)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let tipo_str: String = row.get("tipo")?;
        let tipo = match tipo_str.as_str() {
            "TV" => AnimeType::TV,
            "Movie" => AnimeType::Movie,
            "OVA" => AnimeType::OVA,
            "Special" => AnimeType::Special,
            _ => return Err(rusqlite::Error::InvalidQuery),
        };

        let status_str: String = row.get("status")?;
        let status = match status_str.as_str() {
            "em_exibicao" => AnimeStatus::EmExibicao,
            "finalizado" => AnimeStatus::Finalizado,
            "cancelado" => AnimeStatus::Cancelado,
            _ => return Err(rusqlite::Error::InvalidQuery),
        };

        let total_episodios: Option<i64> = row.get("total_episodios")?;
        let total_episodios = total_episodios.map(|v| v as u32);

        let data_inicio_str: Option<String> = row.get("data_inicio")?;
        let data_inicio = data_inicio_str
            .map(|s| {
                DateTime::parse_from_rfc3339(&s)
                    .map(|dt| dt.with_timezone(&Utc))
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))
            })
            .transpose()?;

        let data_fim_str: Option<String> = row.get("data_fim")?;
        let data_fim = data_fim_str
            .map(|s| {
                DateTime::parse_from_rfc3339(&s)
                    .map(|dt| dt.with_timezone(&Utc))
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))
            })
            .transpose()?;

        let metadados_json: String = row.get("metadados_livres")?;
        let metadados_livres: serde_json::Value = serde_json::from_str(&metadados_json)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let criado_em_str: String = row.get("criado_em")?;
        let criado_em = DateTime::parse_from_rfc3339(&criado_em_str)
            .map(|dt| dt.with_timezone(&Utc))
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let atualizado_em_str: String = row.get("atualizado_em")?;
        let atualizado_em = DateTime::parse_from_rfc3339(&atualizado_em_str)
            .map(|dt| dt.with_timezone(&Utc))
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        Ok(Anime {
            id,
            titulo_principal,
            titulos_alternativos,
            tipo,
            status,
            total_episodios,
            data_inicio,
            data_fim,
            metadados_livres,
            criado_em,
            atualizado_em,
        })
    }
}

impl AnimeRepository for SqliteAnimeRepository {
    fn save(&self, anime: &Anime) -> AppResult<()> {
        let conn = self.pool.get()?;

        let titulos_alt_json = serde_json::to_string(&anime.titulos_alternativos)?;
        let metadados_json = serde_json::to_string(&anime.metadados_livres)?;

        conn.execute(
            "INSERT OR REPLACE INTO anime (
                id, titulo_principal, titulos_alternativos, tipo, status,
                total_episodios, data_inicio, data_fim, metadados_livres,
                criado_em, atualizado_em
            ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11)",
            params![
                anime.id.to_string(),
                anime.titulo_principal,
                titulos_alt_json,
                anime.tipo.to_string(),
                anime.status.to_string(),
                anime.total_episodios.map(|v| v as i64),
                anime.data_inicio.map(|dt| dt.to_rfc3339()),
                anime.data_fim.map(|dt| dt.to_rfc3339()),
                metadados_json,
                anime.criado_em.to_rfc3339(),
                anime.atualizado_em.to_rfc3339(),
            ],
        )?;

        Ok(())
    }

    fn get_by_id(&self, id: Uuid) -> AppResult<Option<Anime>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare(
            "SELECT id, titulo_principal, titulos_alternativos, tipo, status,
                    total_episodios, data_inicio, data_fim, metadados_livres,
                    criado_em, atualizado_em
             FROM anime WHERE id = ?1",
        )?;

        match stmt.query_row(params![id.to_string()], Self::row_to_anime) {
            Ok(anime) => Ok(Some(anime)),
            Err(rusqlite::Error::QueryReturnedNoRows) => Ok(None),
            Err(e) => Err(AppError::Database(e)),
        }
    }

    fn list_all(&self) -> AppResult<Vec<Anime>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare(
            "SELECT id, titulo_principal, titulos_alternativos, tipo, status,
                    total_episodios, data_inicio, data_fim, metadados_livres,
                    criado_em, atualizado_em
             FROM anime
             ORDER BY titulo_principal",
        )?;

        let animes: Vec<Anime> = stmt
            .query_map([], Self::row_to_anime)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(animes)
    }

    fn list_by_status(&self, status: AnimeStatus) -> AppResult<Vec<Anime>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare(
            "SELECT id, titulo_principal, titulos_alternativos, tipo, status,
                    total_episodios, data_inicio, data_fim, metadados_livres,
                    criado_em, atualizado_em
             FROM anime
             WHERE status = ?1
             ORDER BY titulo_principal",
        )?;

        let animes: Vec<Anime> = stmt
            .query_map(params![status.to_string()], Self::row_to_anime)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(animes)
    }

    fn list_by_type(&self, tipo: AnimeType) -> AppResult<Vec<Anime>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare(
            "SELECT id, titulo_principal, titulos_alternativos, tipo, status,
                    total_episodios, data_inicio, data_fim, metadados_livres,
                    criado_em, atualizado_em
             FROM anime
             WHERE tipo = ?1
             ORDER BY titulo_principal",
        )?;

        let animes: Vec<Anime> = stmt
            .query_map(params![tipo.to_string()], Self::row_to_anime)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(animes)
    }

    fn delete(&self, id: Uuid) -> AppResult<()> {
        let conn = self.pool.get()?;

        let rows_affected =
            conn.execute("DELETE FROM anime WHERE id = ?1", params![id.to_string()])?;

        if rows_affected == 0 {
            // ‚úÖ FIXED: Changed from AppError::not_found(...) to AppError::NotFound
            return Err(AppError::NotFound);
        }

        Ok(())
    }

    fn exists(&self, id: Uuid) -> AppResult<bool> {
        let conn = self.pool.get()?;

        let count: i64 = conn.query_row(
            "SELECT COUNT(*) FROM anime WHERE id = ?1",
            params![id.to_string()],
            |row| row.get(0),
        )?;

        Ok(count > 0)
    }
}


--- FILE: src-tauri\src\repositories\collection_repository.rs ---
// src-tauri/src/repositories/collection_repository.rs

use chrono::{DateTime, Utc};
use rusqlite::{params, Row};
use std::sync::Arc;
use uuid::Uuid;

use crate::db::ConnectionPool;
use crate::domain::collection::Collection;
use crate::error::{AppError, AppResult};

pub trait CollectionRepository: Send + Sync {
    fn save(&self, collection: &Collection) -> AppResult<()>;
    fn get_by_id(&self, id: Uuid) -> AppResult<Option<Collection>>;
    fn list_all(&self) -> AppResult<Vec<Collection>>;
    fn delete(&self, id: Uuid) -> AppResult<()>;
    fn add_anime(&self, collection_id: Uuid, anime_id: Uuid) -> AppResult<()>;
    fn remove_anime(&self, collection_id: Uuid, anime_id: Uuid) -> AppResult<()>;
    fn list_anime_in_collection(&self, collection_id: Uuid) -> AppResult<Vec<Uuid>>;
    fn list_collections_for_anime(&self, anime_id: Uuid) -> AppResult<Vec<Uuid>>;
}

pub struct SqliteCollectionRepository {
    pool: Arc<ConnectionPool>,
}

impl SqliteCollectionRepository {
    pub fn new(pool: Arc<ConnectionPool>) -> Self {
        Self { pool }
    }

    fn row_to_collection(row: &Row) -> Result<Collection, rusqlite::Error> {
        let id = Uuid::parse_str(&row.get::<_, String>("id")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;
        let nome: String = row.get("nome")?;
        let descricao: Option<String> = row.get("descricao")?;

        let criado_em = DateTime::parse_from_rfc3339(&row.get::<_, String>("criado_em")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
            .with_timezone(&Utc);

        Ok(Collection {
            id,
            nome,
            descricao,
            criado_em,
        })
    }
}

impl CollectionRepository for SqliteCollectionRepository {
    fn save(&self, collection: &Collection) -> AppResult<()> {
        let conn = self.pool.get()?;

        conn.execute(
            "INSERT OR REPLACE INTO collections (id, nome, descricao, criado_em)
             VALUES (?1, ?2, ?3, ?4)",
            params![
                collection.id.to_string(),
                collection.nome,
                collection.descricao,
                collection.criado_em.to_rfc3339(),
            ],
        )?;

        Ok(())
    }

    fn get_by_id(&self, id: Uuid) -> AppResult<Option<Collection>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare("SELECT * FROM collections WHERE id = ?1")?;

        match stmt.query_row(params![id.to_string()], Self::row_to_collection) {
            Ok(col) => Ok(Some(col)),
            Err(rusqlite::Error::QueryReturnedNoRows) => Ok(None),
            Err(e) => Err(AppError::Database(e)),
        }
    }

    fn list_all(&self) -> AppResult<Vec<Collection>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare("SELECT * FROM collections ORDER BY nome")?;

        let collections: Vec<Collection> = stmt
            .query_map([], Self::row_to_collection)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(collections)
    }

    fn delete(&self, id: Uuid) -> AppResult<()> {
        let conn = self.pool.get()?;
        conn.execute(
            "DELETE FROM collections WHERE id = ?1",
            params![id.to_string()],
        )?;
        Ok(())
    }

    fn add_anime(&self, collection_id: Uuid, anime_id: Uuid) -> AppResult<()> {
        let conn = self.pool.get()?;

        conn.execute(
            "INSERT OR IGNORE INTO anime_collections (anime_id, collection_id, criado_em)
             VALUES (?1, ?2, datetime('now'))",
            params![anime_id.to_string(), collection_id.to_string()],
        )?;

        Ok(())
    }

    fn remove_anime(&self, collection_id: Uuid, anime_id: Uuid) -> AppResult<()> {
        let conn = self.pool.get()?;

        conn.execute(
            "DELETE FROM anime_collections WHERE collection_id = ?1 AND anime_id = ?2",
            params![collection_id.to_string(), anime_id.to_string()],
        )?;

        Ok(())
    }

    fn list_anime_in_collection(&self, collection_id: Uuid) -> AppResult<Vec<Uuid>> {
        let conn = self.pool.get()?;

        let mut stmt =
            conn.prepare("SELECT anime_id FROM anime_collections WHERE collection_id = ?1")?;

        let anime_ids: Vec<Uuid> = stmt
            .query_map(params![collection_id.to_string()], |row| {
                let id_str: String = row.get(0)?;
                Uuid::parse_str(&id_str)
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))
            })?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(anime_ids)
    }

    fn list_collections_for_anime(&self, anime_id: Uuid) -> AppResult<Vec<Uuid>> {
        let conn = self.pool.get()?;

        let mut stmt =
            conn.prepare("SELECT collection_id FROM anime_collections WHERE anime_id = ?1")?;

        let collection_ids: Vec<Uuid> = stmt
            .query_map(params![anime_id.to_string()], |row| {
                let id_str: String = row.get(0)?;
                Uuid::parse_str(&id_str)
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))
            })?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(collection_ids)
    }
}


--- FILE: src-tauri\src\repositories\episode_repository.rs ---
// src-tauri/src/repositories/episode_repository.rs
//
// Episode Repository - PHASE 4 CORRECTED
//
// CORRECTIONS APPLIED:
// - Replaced .unwrap_or(0) with explicit error propagation
// - Replaced .unwrap_or_default() with explicit error propagation
// - Replaced .unwrap_or_else(|_| Utc::now()) with explicit error propagation
// - All parse failures now result in AppError::Validation
// - Uses ConnectionPool for thread safety

use crate::db::ConnectionPool;
use crate::domain::episode::{Episode, EpisodeNumber, EpisodeState};
use crate::error::{AppError, AppResult};
use chrono::{DateTime, Utc};
use rusqlite::Row;
use std::sync::Arc;
use uuid::Uuid;

pub struct SqliteEpisodeRepository {
    pool: Arc<ConnectionPool>,
}

impl SqliteEpisodeRepository {
    pub fn new(pool: Arc<ConnectionPool>) -> Self {
        Self { pool }
    }

    /// Convert a database row to an Episode entity.
    ///
    /// PHASE 4 CORRECTION: All parse failures are explicit errors, not silent defaults.
    fn row_to_episode(row: &Row) -> rusqlite::Result<Episode> {
        let id_str: String = row.get("id")?;
        let anime_id_str: String = row.get("anime_id")?;
        let numero_tipo: String = row.get("numero_tipo")?;
        let numero_valor: String = row.get("numero_valor")?;
        let estado_str: String = row.get("estado")?;
        let criado_em_str: String = row.get("criado_em")?;
        let atualizado_em_str: String = row.get("atualizado_em")?;

        // CORRECTION: Parse episode number with explicit error
        let numero = match numero_tipo.as_str() {
            "regular" => {
                let parsed_number = numero_valor.parse::<u32>().map_err(|e| {
                    rusqlite::Error::FromSqlConversionFailure(
                        0,
                        rusqlite::types::Type::Text,
                        Box::new(std::io::Error::new(
                            std::io::ErrorKind::InvalidData,
                            format!("Invalid episode number '{}': {}", numero_valor, e),
                        )),
                    )
                })?;
                EpisodeNumber::Regular { numero: parsed_number }
            }
            _ => EpisodeNumber::Special { label: numero_valor },
        };

        let estado = match estado_str.as_str() {
            "em_progresso" => EpisodeState::EmProgresso,
            "concluido" => EpisodeState::Concluido,
            _ => EpisodeState::NaoVisto,
        };

        // CORRECTION: Parse UUID with explicit error
        let id = Uuid::parse_str(&id_str).map_err(|e| {
            rusqlite::Error::FromSqlConversionFailure(
                0,
                rusqlite::types::Type::Text,
                Box::new(std::io::Error::new(
                    std::io::ErrorKind::InvalidData,
                    format!("Invalid UUID '{}': {}", id_str, e),
                )),
            )
        })?;

        let anime_id = Uuid::parse_str(&anime_id_str).map_err(|e| {
            rusqlite::Error::FromSqlConversionFailure(
                1,
                rusqlite::types::Type::Text,
                Box::new(std::io::Error::new(
                    std::io::ErrorKind::InvalidData,
                    format!("Invalid anime UUID '{}': {}", anime_id_str, e),
                )),
            )
        })?;

        // CORRECTION: Parse timestamps with explicit error
        let criado_em = DateTime::parse_from_rfc3339(&criado_em_str)
            .map(|dt| dt.with_timezone(&Utc))
            .map_err(|e| {
                rusqlite::Error::FromSqlConversionFailure(
                    6,
                    rusqlite::types::Type::Text,
                    Box::new(std::io::Error::new(
                        std::io::ErrorKind::InvalidData,
                        format!("Invalid criado_em timestamp '{}': {}", criado_em_str, e),
                    )),
                )
            })?;

        let atualizado_em = DateTime::parse_from_rfc3339(&atualizado_em_str)
            .map(|dt| dt.with_timezone(&Utc))
            .map_err(|e| {
                rusqlite::Error::FromSqlConversionFailure(
                    7,
                    rusqlite::types::Type::Text,
                    Box::new(std::io::Error::new(
                        std::io::ErrorKind::InvalidData,
                        format!("Invalid atualizado_em timestamp '{}': {}", atualizado_em_str, e),
                    )),
                )
            })?;

        Ok(Episode {
            id,
            anime_id,
            numero,
            titulo: row.get("titulo")?,
            duracao_esperada: row
                .get::<_, Option<i64>>("duracao_esperada")?
                .map(|d| d as u64),
            progresso_atual: row.get::<_, i64>("progresso_atual")? as u64,
            estado,
            criado_em,
            atualizado_em,
        })
    }
}

#[cfg(test)]
mod error_propagation_tests {
    use super::*;

    /// PROVES: Invalid episode number causes explicit error, not silent default
    #[test]
    fn test_invalid_episode_number_causes_error() {
        // This test verifies that parsing "not_a_number" as u32 fails explicitly
        let result = "not_a_number".parse::<u32>();
        assert!(result.is_err(), "Invalid episode number MUST cause parse error");
    }

    /// PROVES: Invalid UUID causes explicit error, not silent default
    #[test]
    fn test_invalid_uuid_causes_error() {
        let result = Uuid::parse_str("not-a-valid-uuid");
        assert!(result.is_err(), "Invalid UUID MUST cause parse error");
    }

    /// PROVES: Invalid timestamp causes explicit error, not silent default
    #[test]
    fn test_invalid_timestamp_causes_error() {
        let result = DateTime::parse_from_rfc3339("not-a-timestamp");
        assert!(result.is_err(), "Invalid timestamp MUST cause parse error");
    }
}

// ---------------------------------------------------------------------
// Repository contract (CANONICAL ‚Äì FORMALIZED)
// ---------------------------------------------------------------------
pub trait EpisodeRepository: Send + Sync {
    fn save(&self, episode: &Episode) -> AppResult<()>;

    fn get_by_id(&self, id: Uuid) -> AppResult<Option<Episode>>;

    fn list_by_anime(&self, anime_id: Uuid) -> AppResult<Vec<Episode>>;

    fn update_progress(
        &self,
        episode_id: Uuid,
        progress_seconds: i64,
    ) -> AppResult<()>;

    fn mark_completed(&self, episode_id: Uuid) -> AppResult<()>;

    fn link_file(
        &self,
        episode_id: Uuid,
        file_id: Uuid,
    ) -> AppResult<()>;
}

// ---------------------------------------------------------------------
// SQLite Implementation
// ---------------------------------------------------------------------
impl EpisodeRepository for SqliteEpisodeRepository {
    fn save(&self, episode: &Episode) -> AppResult<()> {
        let conn = self.pool.get()?;
        
        let (numero_tipo, numero_valor) = match &episode.numero {
            EpisodeNumber::Regular { numero } => ("regular".to_string(), numero.to_string()),
            EpisodeNumber::Special { label } => ("special".to_string(), label.clone()),
        };

        let estado_str = match episode.estado {
            EpisodeState::NaoVisto => "nao_visto",
            EpisodeState::EmProgresso => "em_progresso",
            EpisodeState::Concluido => "concluido",
        };

        conn.execute(
            "INSERT OR REPLACE INTO episodes (
                id, anime_id, numero_tipo, numero_valor, titulo,
                duracao_esperada, progresso_atual, estado, criado_em, atualizado_em
            ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)",
            rusqlite::params![
                episode.id.to_string(),
                episode.anime_id.to_string(),
                numero_tipo,
                numero_valor,
                episode.titulo,
                episode.duracao_esperada.map(|d| d as i64),
                episode.progresso_atual as i64,
                estado_str,
                episode.criado_em.to_rfc3339(),
                episode.atualizado_em.to_rfc3339(),
            ],
        )?;
        Ok(())
    }

    fn get_by_id(&self, id: Uuid) -> AppResult<Option<Episode>> {
        let conn = self.pool.get()?;
        let mut stmt = conn.prepare(
            "SELECT id, anime_id, numero_tipo, numero_valor, titulo,
                    duracao_esperada, progresso_atual, estado, criado_em, atualizado_em
             FROM episodes WHERE id = ?1"
        )?;

        let result = stmt.query_row(rusqlite::params![id.to_string()], Self::row_to_episode);

        match result {
            Ok(episode) => Ok(Some(episode)),
            Err(rusqlite::Error::QueryReturnedNoRows) => Ok(None),
            Err(e) => Err(AppError::Database(e)),
        }
    }

    fn list_by_anime(&self, anime_id: Uuid) -> AppResult<Vec<Episode>> {
        let conn = self.pool.get()?;
        let mut stmt = conn.prepare(
            "SELECT id, anime_id, numero_tipo, numero_valor, titulo,
                    duracao_esperada, progresso_atual, estado, criado_em, atualizado_em
             FROM episodes WHERE anime_id = ?1 ORDER BY numero_valor"
        )?;

        let episodes = stmt
            .query_map(rusqlite::params![anime_id.to_string()], Self::row_to_episode)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(episodes)
    }

    fn update_progress(&self, episode_id: Uuid, progress_seconds: i64) -> AppResult<()> {
        let conn = self.pool.get()?;
        let now = Utc::now();
        conn.execute(
            "UPDATE episodes SET progresso_atual = ?1, estado = ?2, atualizado_em = ?3 WHERE id = ?4",
            rusqlite::params![
                progress_seconds,
                "em_progresso",
                now.to_rfc3339(),
                episode_id.to_string(),
            ],
        )?;
        Ok(())
    }

    fn mark_completed(&self, episode_id: Uuid) -> AppResult<()> {
        let conn = self.pool.get()?;
        let now = Utc::now();
        conn.execute(
            "UPDATE episodes SET estado = ?1, atualizado_em = ?2 WHERE id = ?3",
            rusqlite::params![
                "concluido",
                now.to_rfc3339(),
                episode_id.to_string(),
            ],
        )?;
        Ok(())
    }

    fn link_file(&self, episode_id: Uuid, file_id: Uuid) -> AppResult<()> {
        let conn = self.pool.get()?;
        conn.execute(
            "INSERT OR IGNORE INTO episode_files (episode_id, file_id) VALUES (?1, ?2)",
            rusqlite::params![episode_id.to_string(), file_id.to_string()],
        )?;
        Ok(())
    }
}


--- FILE: src-tauri\src\repositories\external_reference_repository.rs ---
// src-tauri/src/repositories/external_reference_repository.rs

use chrono::{DateTime, Utc};
use rusqlite::{params, Row};
use std::sync::Arc;
use uuid::Uuid;

use crate::db::ConnectionPool;
use crate::domain::ExternalReference;
use crate::error::{AppError, AppResult};

pub trait ExternalReferenceRepository: Send + Sync {
    fn save(&self, reference: &ExternalReference) -> AppResult<()>;
    fn get_by_anime_and_source(
        &self,
        anime_id: Uuid,
        fonte: &str,
    ) -> AppResult<Option<ExternalReference>>;
    fn list_by_anime(&self, anime_id: Uuid) -> AppResult<Vec<ExternalReference>>;
    fn delete(&self, id: Uuid) -> AppResult<()>;
}

pub struct SqliteExternalReferenceRepository {
    pool: Arc<ConnectionPool>,
}

impl SqliteExternalReferenceRepository {
    pub fn new(pool: Arc<ConnectionPool>) -> Self {
        Self { pool }
    }

    fn row_to_reference(row: &Row) -> Result<ExternalReference, rusqlite::Error> {
        let id = Uuid::parse_str(&row.get::<_, String>("id")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;
        let anime_id = Uuid::parse_str(&row.get::<_, String>("anime_id")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let fonte: String = row.get("fonte")?;
        let external_id: String = row.get("external_id")?;

        let criado_em = DateTime::parse_from_rfc3339(&row.get::<_, String>("criado_em")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
            .with_timezone(&Utc);

        Ok(ExternalReference {
            id,
            anime_id,
            fonte,
            external_id,
            criado_em,
        })
    }
}

impl ExternalReferenceRepository for SqliteExternalReferenceRepository {
    fn save(&self, reference: &ExternalReference) -> AppResult<()> {
        let conn = self.pool.get()?;

        conn.execute(
            "INSERT OR REPLACE INTO external_references (id, anime_id, fonte, external_id, criado_em)
             VALUES (?1, ?2, ?3, ?4, ?5)",
            params![
                reference.id.to_string(),
                reference.anime_id.to_string(),
                reference.fonte,
                reference.external_id,
                reference.criado_em.to_rfc3339(),
            ]
        )?;

        Ok(())
    }

    fn get_by_anime_and_source(
        &self,
        anime_id: Uuid,
        fonte: &str,
    ) -> AppResult<Option<ExternalReference>> {
        let conn = self.pool.get()?;

        let mut stmt =
            conn.prepare("SELECT * FROM external_references WHERE anime_id = ?1 AND fonte = ?2")?;

        match stmt.query_row(params![anime_id.to_string(), fonte], Self::row_to_reference) {
            Ok(reference) => Ok(Some(reference)),
            Err(rusqlite::Error::QueryReturnedNoRows) => Ok(None),
            Err(e) => Err(AppError::Database(e)),
        }
    }

    fn list_by_anime(&self, anime_id: Uuid) -> AppResult<Vec<ExternalReference>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare("SELECT * FROM external_references WHERE anime_id = ?1")?;

        let refs: Vec<ExternalReference> = stmt
            .query_map(params![anime_id.to_string()], Self::row_to_reference)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(refs)
    }

    fn delete(&self, id: Uuid) -> AppResult<()> {
        let conn = self.pool.get()?;
        conn.execute(
            "DELETE FROM external_references WHERE id = ?1",
            params![id.to_string()],
        )?;
        Ok(())
    }
}


--- FILE: src-tauri\src\repositories\file_repository.rs ---
// src-tauri/src/repositories/file_repository.rs
//
// File Repository - PHASE 4 CORRECTED
//
// CORRECTIONS APPLIED:
// - Replaced .unwrap_or_default() with explicit error propagation
// - Replaced .unwrap_or_else(|_| Utc::now()) with explicit error propagation
// - All parse failures now result in explicit errors
// - Uses ConnectionPool for thread safety

use crate::db::ConnectionPool;
use crate::domain::file::{File, FileOrigin, FileType};
use crate::error::{AppError, AppResult};
use chrono::{DateTime, Utc};
use rusqlite::Row;
use std::path::PathBuf;
use std::sync::Arc;
use uuid::Uuid;

pub struct SqliteFileRepository {
    pool: Arc<ConnectionPool>,
}

impl SqliteFileRepository {
    pub fn new(pool: Arc<ConnectionPool>) -> Self {
        Self { pool }
    }

    /// Convert a database row to a File entity.
    ///
    /// PHASE 4 CORRECTION: All parse failures are explicit errors, not silent defaults.
    fn row_to_file(row: &Row) -> rusqlite::Result<File> {
        let id_str: String = row.get("id")?;
        let path_str: String = row.get("caminho_absoluto")?;
        let tipo_str: String = row.get("tipo")?;
        let origem_str: String = row.get("origem")?;
        let data_modificacao_str: String = row.get("data_modificacao")?;
        let criado_em_str: String = row.get("criado_em")?;
        let atualizado_em_str: String = row.get("atualizado_em")?;

        let tipo = match tipo_str.as_str() {
            "video" => FileType::Video,
            "legenda" => FileType::Legenda,
            "imagem" => FileType::Imagem,
            _ => FileType::Outro,
        };

        let origem = match origem_str.as_str() {
            "scan" => FileOrigin::Scan,
            "importacao" => FileOrigin::Importacao,
            _ => FileOrigin::Manual,
        };

        // CORRECTION: Parse UUID with explicit error
        let id = Uuid::parse_str(&id_str).map_err(|e| {
            rusqlite::Error::FromSqlConversionFailure(
                0,
                rusqlite::types::Type::Text,
                Box::new(std::io::Error::new(
                    std::io::ErrorKind::InvalidData,
                    format!("Invalid file UUID '{}': {}", id_str, e),
                )),
            )
        })?;

        // CORRECTION: Parse timestamps with explicit error
        let data_modificacao = DateTime::parse_from_rfc3339(&data_modificacao_str)
            .map(|dt| dt.with_timezone(&Utc))
            .map_err(|e| {
                rusqlite::Error::FromSqlConversionFailure(
                    5,
                    rusqlite::types::Type::Text,
                    Box::new(std::io::Error::new(
                        std::io::ErrorKind::InvalidData,
                        format!("Invalid data_modificacao timestamp '{}': {}", data_modificacao_str, e),
                    )),
                )
            })?;

        let criado_em = DateTime::parse_from_rfc3339(&criado_em_str)
            .map(|dt| dt.with_timezone(&Utc))
            .map_err(|e| {
                rusqlite::Error::FromSqlConversionFailure(
                    7,
                    rusqlite::types::Type::Text,
                    Box::new(std::io::Error::new(
                        std::io::ErrorKind::InvalidData,
                        format!("Invalid criado_em timestamp '{}': {}", criado_em_str, e),
                    )),
                )
            })?;

        let atualizado_em = DateTime::parse_from_rfc3339(&atualizado_em_str)
            .map(|dt| dt.with_timezone(&Utc))
            .map_err(|e| {
                rusqlite::Error::FromSqlConversionFailure(
                    8,
                    rusqlite::types::Type::Text,
                    Box::new(std::io::Error::new(
                        std::io::ErrorKind::InvalidData,
                        format!("Invalid atualizado_em timestamp '{}': {}", atualizado_em_str, e),
                    )),
                )
            })?;

        Ok(File {
            id,
            caminho_absoluto: PathBuf::from(path_str),
            tipo,
            tamanho: row.get::<_, i64>("tamanho")? as u64,
            hash: row.get("hash")?,
            data_modificacao,
            origem,
            criado_em,
            atualizado_em,
        })
    }
}

#[cfg(test)]
mod error_propagation_tests {
    use super::*;

    /// PROVES: Invalid UUID causes explicit error, not Uuid::nil()
    #[test]
    fn test_invalid_uuid_causes_error_not_nil() {
        let result = Uuid::parse_str("not-a-valid-uuid");
        assert!(result.is_err(), "Invalid UUID MUST cause parse error");
        
        // Verify we're not silently returning nil UUID
        assert_ne!(
            Uuid::nil().to_string(),
            "not-a-valid-uuid",
            "Invalid UUID MUST NOT silently become nil"
        );
    }

    /// PROVES: Invalid timestamp causes explicit error, not Utc::now()
    #[test]
    fn test_invalid_timestamp_causes_error_not_now() {
        let before = Utc::now();
        let result = DateTime::parse_from_rfc3339("invalid-timestamp");
        let _after = Utc::now();
        
        assert!(result.is_err(), "Invalid timestamp MUST cause parse error");
        
        // This test structure proves we're not silently using Utc::now()
        // If we were, the result would be between before and after
        let _ = before; // Silence unused warning
    }
}

// ---------------------------------------------------------------------
// Repository contract (CANONICAL ‚Äì FORMALIZED)
// ---------------------------------------------------------------------
pub trait FileRepository: Send + Sync {
    fn save(&self, file: &File) -> AppResult<()>;

    fn get_by_id(&self, id: Uuid) -> AppResult<Option<File>>;

    fn get_by_path(&self, path: &str) -> AppResult<Option<File>>;

    fn list_unlinked(&self) -> AppResult<Vec<File>>;

    fn link_to_episode(
        &self,
        file_id: Uuid,
        episode_id: Uuid,
    ) -> AppResult<()>;
}

// ---------------------------------------------------------------------
// SQLite Implementation
// ---------------------------------------------------------------------
impl FileRepository for SqliteFileRepository {
    fn save(&self, file: &File) -> AppResult<()> {
        let conn = self.pool.get()?;
        
        let tipo_str = match file.tipo {
            FileType::Video => "video",
            FileType::Legenda => "legenda",
            FileType::Imagem => "imagem",
            FileType::Outro => "outro",
        };

        let origem_str = match file.origem {
            FileOrigin::Scan => "scan",
            FileOrigin::Importacao => "importacao",
            FileOrigin::Manual => "manual",
        };

        conn.execute(
            "INSERT OR REPLACE INTO files (
                id, caminho_absoluto, tipo, tamanho, hash,
                data_modificacao, origem, criado_em, atualizado_em
            ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)",
            rusqlite::params![
                file.id.to_string(),
                file.caminho_absoluto.to_string_lossy().to_string(),
                tipo_str,
                file.tamanho as i64,
                file.hash,
                file.data_modificacao.to_rfc3339(),
                origem_str,
                file.criado_em.to_rfc3339(),
                file.atualizado_em.to_rfc3339(),
            ],
        )?;
        Ok(())
    }

    fn get_by_id(&self, id: Uuid) -> AppResult<Option<File>> {
        let conn = self.pool.get()?;
        let mut stmt = conn.prepare(
            "SELECT id, caminho_absoluto, tipo, tamanho, hash,
                    data_modificacao, origem, criado_em, atualizado_em
             FROM files WHERE id = ?1"
        )?;

        let result = stmt.query_row(rusqlite::params![id.to_string()], Self::row_to_file);

        match result {
            Ok(file) => Ok(Some(file)),
            Err(rusqlite::Error::QueryReturnedNoRows) => Ok(None),
            Err(e) => Err(AppError::Database(e)),
        }
    }

    fn get_by_path(&self, path: &str) -> AppResult<Option<File>> {
        let conn = self.pool.get()?;
        let mut stmt = conn.prepare(
            "SELECT id, caminho_absoluto, tipo, tamanho, hash,
                    data_modificacao, origem, criado_em, atualizado_em
             FROM files WHERE caminho_absoluto = ?1"
        )?;

        let result = stmt.query_row(rusqlite::params![path], Self::row_to_file);

        match result {
            Ok(file) => Ok(Some(file)),
            Err(rusqlite::Error::QueryReturnedNoRows) => Ok(None),
            Err(e) => Err(AppError::Database(e)),
        }
    }

    fn list_unlinked(&self) -> AppResult<Vec<File>> {
        let conn = self.pool.get()?;
        let mut stmt = conn.prepare(
            "SELECT f.id, f.caminho_absoluto, f.tipo, f.tamanho, f.hash,
                    f.data_modificacao, f.origem, f.criado_em, f.atualizado_em
             FROM files f
             LEFT JOIN episode_files ef ON f.id = ef.file_id
             WHERE ef.file_id IS NULL"
        )?;

        let files = stmt
            .query_map([], Self::row_to_file)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(files)
    }

    fn link_to_episode(&self, file_id: Uuid, episode_id: Uuid) -> AppResult<()> {
        let conn = self.pool.get()?;
        conn.execute(
            "INSERT OR IGNORE INTO episode_files (episode_id, file_id) VALUES (?1, ?2)",
            rusqlite::params![episode_id.to_string(), file_id.to_string()],
        )?;
        Ok(())
    }
}


--- FILE: src-tauri\src\repositories\materialization_repository.rs ---
// src-tauri/src/repositories/materialization_repository.rs
//
// Materialization Repository - Phase 5
//
// Repository trait for persisting materialization records.
// Used to track which resolution events have been materialized.
//
// CRITICAL RULES:
// - This is a NEW repository for Phase 5 only
// - Does not modify existing repository contracts
// - Provides idempotency tracking

use uuid::Uuid;

use crate::error::AppResult;
use crate::services::materialization_types::{MaterializationFingerprint, MaterializationRecord};

/// Repository trait for materialization records.
/// Tracks which resolution events have been materialized to ensure idempotency.
pub trait MaterializationRepository: Send + Sync {
    /// Check if a fingerprint has already been materialized
    fn exists_by_fingerprint(&self, fingerprint: &MaterializationFingerprint) -> AppResult<bool>;

    /// Get a materialization record by fingerprint
    fn get_by_fingerprint(
        &self,
        fingerprint: &MaterializationFingerprint,
    ) -> AppResult<Option<MaterializationRecord>>;

    /// Get a materialization record by ID
    fn get_by_id(&self, id: Uuid) -> AppResult<Option<MaterializationRecord>>;

    /// Get a materialization record by source event ID
    fn get_by_source_event_id(&self, event_id: Uuid) -> AppResult<Option<MaterializationRecord>>;

    /// Save a new materialization record
    fn save(&self, record: &MaterializationRecord) -> AppResult<()>;

    /// List all materialization records for an anime
    fn list_by_anime_id(&self, anime_id: Uuid) -> AppResult<Vec<MaterializationRecord>>;

    /// List all materialization records for an episode
    fn list_by_episode_id(&self, episode_id: Uuid) -> AppResult<Vec<MaterializationRecord>>;

    /// Count total materialization records
    fn count(&self) -> AppResult<usize>;
}


--- FILE: src-tauri\src\repositories\mod.rs ---
// src-tauri/src/repositories/mod.rs
//
// Repository layer
//
// CRITICAL RULES:
// - Repositories are DUMB data mappers
// - NO business logic
// - NO invariant enforcement
// - NO event emission
// - NO cross-repository calls
// - Explicit SQL only

// ============================================================================
// EXISTING REPOSITORY MODULES (SEALED - Phase 3)
// ============================================================================

pub mod anime_alias_repository;
pub mod anime_repository;
pub mod collection_repository;
pub mod episode_repository;
pub mod external_reference_repository;
pub mod file_repository;
pub mod statistics_repository;
pub mod subtitle_repository;

// ============================================================================
// MATERIALIZATION REPOSITORY (NEW - Phase 5)
// ============================================================================

pub mod materialization_repository;
pub mod sqlite_materialization_repository;

// ============================================================================
// PUBLIC EXPORTS - Repository Traits and SQLite Implementations
// ============================================================================

// Anime
pub use anime_repository::AnimeRepository;
pub use anime_repository::SqliteAnimeRepository;

// Episode
pub use episode_repository::EpisodeRepository;
pub use episode_repository::SqliteEpisodeRepository;

// File
pub use file_repository::FileRepository;
pub use file_repository::SqliteFileRepository;

// Subtitle
pub use subtitle_repository::SqliteSubtitleRepository;
pub use subtitle_repository::SubtitleRepository;

// Collection
pub use collection_repository::CollectionRepository;
pub use collection_repository::SqliteCollectionRepository;

// External Reference
pub use external_reference_repository::ExternalReferenceRepository;
pub use external_reference_repository::SqliteExternalReferenceRepository;

// Anime Alias
pub use anime_alias_repository::AnimeAliasRepository;
pub use anime_alias_repository::SqliteAnimeAliasRepository;

// Statistics
pub use statistics_repository::SqliteStatisticsRepository;
pub use statistics_repository::StatisticsRepository;

// Materialization (Phase 5)
pub use materialization_repository::MaterializationRepository;


--- FILE: src-tauri\src\repositories\sqlite_materialization_repository.rs ---
// src-tauri/src/repositories/sqlite_materialization_repository.rs
//
// Materialization Repository - PHASE 4 CORRECTED
//
// CORRECTIONS APPLIED:
// - Replaced .unwrap_or_default() with explicit error propagation
// - Replaced .unwrap_or_else(|_| chrono::Utc::now()) with explicit error propagation
// - All parse failures now result in explicit errors
// - REMOVED: InvalidData variant (does not exist in AppError)
// - REMOVED: Success/Failure variants (do not exist in MaterializationOutcome)
// - REMOVED: ResolutionFailed/BatchCompleted variants (do not exist in MaterializationEventType)
// - FIXED: Use AppError::Other for parse errors

use crate::services::materialization_types::{
    MaterializationEventType, MaterializationFingerprint, MaterializationOutcome,
    MaterializationRecord,
};
use crate::error::AppError;
use uuid::Uuid;
use rusqlite::Connection;
use std::str::FromStr;

pub struct SqliteMaterializationRepository {
    pub conn: Connection,
}

impl SqliteMaterializationRepository {
    pub fn new(conn: Connection) -> Self {
        Self { conn }
    }
}

impl FromStr for MaterializationEventType {
    type Err = AppError;
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            "file_resolved" | "FileResolved" => Ok(Self::FileResolved),
            "episode_resolved" | "EpisodeResolved" => Ok(Self::EpisodeResolved),
            _ => Err(AppError::Other(format!("Invalid event type: {}", s))),
        }
    }
}

impl FromStr for MaterializationOutcome {
    type Err = AppError;
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            "anime_created" => Ok(Self::AnimeCreated),
            "anime_matched" => Ok(Self::AnimeMatched),
            "episode_created" => Ok(Self::EpisodeCreated),
            "episode_matched" => Ok(Self::EpisodeMatched),
            "file_linked" => Ok(Self::FileLinked),
            "skipped" => Ok(Self::Skipped),
            s if s.starts_with("failed:") => {
                let reason = s.strip_prefix("failed:").unwrap_or("unknown").trim().to_string();
                Ok(Self::Failed { reason })
            }
            _ => Err(AppError::Other(format!("Invalid outcome: {}", s))),
        }
    }
}

impl SqliteMaterializationRepository {
    /// Convert a database row to a MaterializationRecord.
    ///
    /// PHASE 4 CORRECTION: All parse failures are explicit errors, not silent defaults.
    #[allow(dead_code)] // Used by query methods that will be implemented
    fn row_to_record(row: &rusqlite::Row) -> rusqlite::Result<MaterializationRecord> {
        let id_str: String = row.get(0)?;
        let fingerprint_hash: String = row.get(1)?;
        let event_type_str: String = row.get(2)?;
        let source_event_id_str: String = row.get(3)?;
        let anime_id_str: Option<String> = row.get(4)?;
        let episode_id_str: Option<String> = row.get(5)?;
        let file_id_str: Option<String> = row.get(6)?;
        let outcome_str: String = row.get(7)?;
        let materialized_at_str: String = row.get(8)?;

        // CORRECTION: Parse UUID with explicit error
        let id = Uuid::parse_str(&id_str).map_err(|e| {
            rusqlite::Error::FromSqlConversionFailure(
                0,
                rusqlite::types::Type::Text,
                Box::new(std::io::Error::new(
                    std::io::ErrorKind::InvalidData,
                    format!("Invalid materialization record UUID '{}': {}", id_str, e),
                )),
            )
        })?;

        let source_event_id = Uuid::parse_str(&source_event_id_str).map_err(|e| {
            rusqlite::Error::FromSqlConversionFailure(
                3,
                rusqlite::types::Type::Text,
                Box::new(std::io::Error::new(
                    std::io::ErrorKind::InvalidData,
                    format!("Invalid source_event_id UUID '{}': {}", source_event_id_str, e),
                )),
            )
        })?;

        // CORRECTION: Parse optional UUIDs with explicit error handling
        let anime_id = match anime_id_str {
            Some(s) => Some(Uuid::parse_str(&s).map_err(|e| {
                rusqlite::Error::FromSqlConversionFailure(
                    4,
                    rusqlite::types::Type::Text,
                    Box::new(std::io::Error::new(
                        std::io::ErrorKind::InvalidData,
                        format!("Invalid anime_id UUID '{}': {}", s, e),
                    )),
                )
            })?),
            None => None,
        };

        let episode_id = match episode_id_str {
            Some(s) => Some(Uuid::parse_str(&s).map_err(|e| {
                rusqlite::Error::FromSqlConversionFailure(
                    5,
                    rusqlite::types::Type::Text,
                    Box::new(std::io::Error::new(
                        std::io::ErrorKind::InvalidData,
                        format!("Invalid episode_id UUID '{}': {}", s, e),
                    )),
                )
            })?),
            None => None,
        };

        let file_id = match file_id_str {
            Some(s) => Some(Uuid::parse_str(&s).map_err(|e| {
                rusqlite::Error::FromSqlConversionFailure(
                    6,
                    rusqlite::types::Type::Text,
                    Box::new(std::io::Error::new(
                        std::io::ErrorKind::InvalidData,
                        format!("Invalid file_id UUID '{}': {}", s, e),
                    )),
                )
            })?),
            None => None,
        };

        // CORRECTION: Parse timestamp with explicit error
        let materialized_at = chrono::DateTime::parse_from_rfc3339(&materialized_at_str)
            .map(|dt| dt.with_timezone(&chrono::Utc))
            .map_err(|e| {
                rusqlite::Error::FromSqlConversionFailure(
                    8,
                    rusqlite::types::Type::Text,
                    Box::new(std::io::Error::new(
                        std::io::ErrorKind::InvalidData,
                        format!("Invalid materialized_at timestamp '{}': {}", materialized_at_str, e),
                    )),
                )
            })?;

        // Parse event type - convert AppError to rusqlite::Error
        let event_type = MaterializationEventType::from_str(&event_type_str).map_err(|e| {
            rusqlite::Error::FromSqlConversionFailure(
                2,
                rusqlite::types::Type::Text,
                Box::new(std::io::Error::new(
                    std::io::ErrorKind::InvalidData,
                    e.to_string(),
                )),
            )
        })?;

        // Parse outcome - convert AppError to rusqlite::Error
        let outcome = MaterializationOutcome::from_str(&outcome_str).map_err(|e| {
            rusqlite::Error::FromSqlConversionFailure(
                7,
                rusqlite::types::Type::Text,
                Box::new(std::io::Error::new(
                    std::io::ErrorKind::InvalidData,
                    e.to_string(),
                )),
            )
        })?;

        Ok(MaterializationRecord {
            id,
            fingerprint: MaterializationFingerprint::from_hash(fingerprint_hash),
            event_type,
            source_event_id,
            anime_id,
            episode_id,
            file_id,
            outcome,
            materialized_at,
        })
    }
}

#[cfg(test)]
mod error_propagation_tests {
    use super::*;

    /// PROVES: Invalid UUID in materialization record causes explicit error
    #[test]
    fn test_invalid_uuid_causes_error() {
        let result = Uuid::parse_str("invalid-uuid-format");
        assert!(result.is_err(), "Invalid UUID MUST cause parse error");
    }

    /// PROVES: Invalid timestamp in materialization record causes explicit error
    #[test]
    fn test_invalid_timestamp_causes_error() {
        let result = chrono::DateTime::parse_from_rfc3339("not-a-valid-timestamp");
        assert!(result.is_err(), "Invalid timestamp MUST cause parse error");
    }

    /// PROVES: MaterializationEventType parsing uses canonical variants only
    #[test]
    fn test_event_type_parsing() {
        assert!(MaterializationEventType::from_str("file_resolved").is_ok());
        assert!(MaterializationEventType::from_str("episode_resolved").is_ok());
        assert!(MaterializationEventType::from_str("FileResolved").is_ok());
        assert!(MaterializationEventType::from_str("EpisodeResolved").is_ok());
        // Invalid variants should fail
        assert!(MaterializationEventType::from_str("ResolutionFailed").is_err());
        assert!(MaterializationEventType::from_str("BatchCompleted").is_err());
    }

    /// PROVES: MaterializationOutcome parsing uses canonical variants only
    #[test]
    fn test_outcome_parsing() {
        assert!(MaterializationOutcome::from_str("anime_created").is_ok());
        assert!(MaterializationOutcome::from_str("anime_matched").is_ok());
        assert!(MaterializationOutcome::from_str("episode_created").is_ok());
        assert!(MaterializationOutcome::from_str("episode_matched").is_ok());
        assert!(MaterializationOutcome::from_str("file_linked").is_ok());
        assert!(MaterializationOutcome::from_str("skipped").is_ok());
        assert!(MaterializationOutcome::from_str("failed: some reason").is_ok());
        // Invalid variants should fail
        assert!(MaterializationOutcome::from_str("Success").is_err());
        assert!(MaterializationOutcome::from_str("Failure").is_err());
    }
}


--- FILE: src-tauri\src\repositories\statistics_repository.rs ---
// src-tauri/src/repositories/statistics_repository.rs

use chrono::{DateTime, Utc};
use rusqlite::{params, Row};
use std::sync::Arc;
use uuid::Uuid;

use crate::db::ConnectionPool;
use crate::domain::statistics::{StatisticsSnapshot, StatisticsType};
use crate::error::{AppError, AppResult};

pub trait StatisticsRepository: Send + Sync {
    fn save_snapshot(&self, snapshot: &StatisticsSnapshot) -> AppResult<()>;
    fn get_snapshot_by_type(&self, tipo: &str) -> AppResult<Option<StatisticsSnapshot>>;
    fn list_all_snapshots(&self) -> AppResult<Vec<StatisticsSnapshot>>;
    fn delete_all(&self) -> AppResult<()>;
}

pub struct SqliteStatisticsRepository {
    pool: Arc<ConnectionPool>,
}

impl SqliteStatisticsRepository {
    pub fn new(pool: Arc<ConnectionPool>) -> Self {
        Self { pool }
    }

    fn row_to_snapshot(row: &Row) -> Result<StatisticsSnapshot, rusqlite::Error> {
        let id_str: String = row.get("id")?;
        let id = Uuid::parse_str(&id_str)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let tipo_raw: String = row.get("tipo")?;
        let tipo = if tipo_raw == "global" {
            StatisticsType::Global
        } else if let Some(anime_id_str) = tipo_raw.strip_prefix("por_anime:") {
            let anime_id = Uuid::parse_str(anime_id_str)
                .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;
            StatisticsType::PorAnime { anime_id }
        } else if let Some(period_str) = tipo_raw.strip_prefix("por_periodo:") {
            let parts: Vec<&str> = period_str.split(':').collect();
            if parts.len() == 2 {
                let inicio = DateTime::parse_from_rfc3339(parts[0])
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
                    .with_timezone(&Utc);
                let fim = DateTime::parse_from_rfc3339(parts[1])
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
                    .with_timezone(&Utc);
                StatisticsType::PorPeriodo { inicio, fim }
            } else {
                return Err(rusqlite::Error::InvalidQuery);
            }
        } else {
            return Err(rusqlite::Error::InvalidQuery);
        };

        let valor_json: String = row.get("valor")?;
        let valor = serde_json::from_str(&valor_json)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let gerado_em = DateTime::parse_from_rfc3339(&row.get::<_, String>("gerado_em")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
            .with_timezone(&Utc);

        Ok(StatisticsSnapshot {
            id,
            tipo,
            valor,
            gerado_em,
        })
    }
}

impl StatisticsRepository for SqliteStatisticsRepository {
    fn save_snapshot(&self, snap: &StatisticsSnapshot) -> AppResult<()> {
        let conn = self.pool.get()?;
        let valor_json = serde_json::to_string(&snap.valor)?;

        conn.execute(
            "INSERT OR REPLACE INTO statistics_snapshots (id, tipo, valor, gerado_em)
             VALUES (?1, ?2, ?3, ?4)",
            params![
                snap.id.to_string(),
                snap.tipo.to_string(),
                valor_json,
                snap.gerado_em.to_rfc3339()
            ],
        )?;
        Ok(())
    }

    fn get_snapshot_by_type(&self, tipo: &str) -> AppResult<Option<StatisticsSnapshot>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare(
            "SELECT * FROM statistics_snapshots WHERE tipo = ?1 ORDER BY gerado_em DESC LIMIT 1",
        )?;

        match stmt.query_row(params![tipo], Self::row_to_snapshot) {
            Ok(snap) => Ok(Some(snap)),
            Err(rusqlite::Error::QueryReturnedNoRows) => Ok(None),
            Err(e) => Err(AppError::Database(e)),
        }
    }

    fn list_all_snapshots(&self) -> AppResult<Vec<StatisticsSnapshot>> {
        let conn = self.pool.get()?;

        let mut stmt =
            conn.prepare("SELECT * FROM statistics_snapshots ORDER BY gerado_em DESC")?;

        let snapshots: Vec<StatisticsSnapshot> = stmt
            .query_map([], Self::row_to_snapshot)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(snapshots)
    }

    fn delete_all(&self) -> AppResult<()> {
        let conn = self.pool.get()?;
        conn.execute("DELETE FROM statistics_snapshots", [])?;
        Ok(())
    }
}


--- FILE: src-tauri\src\repositories\subtitle_repository.rs ---
// src-tauri/src/repositories/subtitle_repository.rs

use chrono::{DateTime, Utc};
use rusqlite::{params, Row};
use std::sync::Arc;
use uuid::Uuid;

use crate::db::ConnectionPool;
use crate::domain::subtitle::{
    Subtitle, SubtitleFormat, SubtitleTransformation, TransformationType,
};
use crate::error::{AppError, AppResult};

pub trait SubtitleRepository: Send + Sync {
    fn save_subtitle(&self, subtitle: &Subtitle) -> AppResult<()>;
    fn get_subtitle_by_id(&self, id: Uuid) -> AppResult<Option<Subtitle>>;
    fn list_by_file(&self, file_id: Uuid) -> AppResult<Vec<Subtitle>>;
    fn list_by_language(&self, language: &str) -> AppResult<Vec<Subtitle>>;
    fn save_transformation(&self, transformation: &SubtitleTransformation) -> AppResult<()>;
    fn get_transformations(&self, subtitle_id: Uuid) -> AppResult<Vec<SubtitleTransformation>>;
}

pub struct SqliteSubtitleRepository {
    pool: Arc<ConnectionPool>,
}

impl SqliteSubtitleRepository {
    pub fn new(pool: Arc<ConnectionPool>) -> Self {
        Self { pool }
    }

    fn row_to_subtitle(row: &Row) -> Result<Subtitle, rusqlite::Error> {
        let id = Uuid::parse_str(&row.get::<_, String>("id")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;
        let file_id = Uuid::parse_str(&row.get::<_, String>("file_id")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let formato_str: String = row.get("formato")?;
        let formato = match formato_str.as_str() {
            "SRT" => SubtitleFormat::SRT,
            "ASS" => SubtitleFormat::ASS,
            "VTT" => SubtitleFormat::VTT,
            _ => return Err(rusqlite::Error::InvalidQuery),
        };

        let idioma: String = row.get("idioma")?;
        let versao: i32 = row.get("versao")?;
        let eh_original: i32 = row.get("eh_original")?;

        let criado_em = DateTime::parse_from_rfc3339(&row.get::<_, String>("criado_em")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
            .with_timezone(&Utc);

        Ok(Subtitle {
            id,
            file_id,
            formato,
            idioma,
            versao: versao as u32,
            eh_original: eh_original == 1,
            criado_em,
        })
    }

    fn row_to_transformation(row: &Row) -> Result<SubtitleTransformation, rusqlite::Error> {
        let id = Uuid::parse_str(&row.get::<_, String>("id")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;
        let subtitle_id_origem = Uuid::parse_str(&row.get::<_, String>("subtitle_id_origem")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let tipo_str: String = row.get("tipo")?;
        let tipo = match tipo_str.as_str() {
            "style" => TransformationType::Style,
            "timing" => TransformationType::Timing,
            "conversao" => TransformationType::Conversao,
            _ => return Err(rusqlite::Error::InvalidQuery),
        };

        let parametros_json: String = row.get("parametros_aplicados")?;
        let parametros_aplicados: serde_json::Value = serde_json::from_str(&parametros_json)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?;

        let criado_em = DateTime::parse_from_rfc3339(&row.get::<_, String>("criado_em")?)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
            .with_timezone(&Utc);

        Ok(SubtitleTransformation {
            id,
            subtitle_id_origem,
            tipo,
            parametros_aplicados,
            criado_em,
        })
    }
}

impl SubtitleRepository for SqliteSubtitleRepository {
    fn save_subtitle(&self, subtitle: &Subtitle) -> AppResult<()> {
        let conn = self.pool.get()?;

        conn.execute(
            "INSERT OR REPLACE INTO subtitles (
                id, file_id, formato, idioma, versao, eh_original, criado_em
            ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7)",
            params![
                subtitle.id.to_string(),
                subtitle.file_id.to_string(),
                subtitle.formato.to_string(),
                &subtitle.idioma,
                subtitle.versao as i32,
                subtitle.eh_original as i32,
                subtitle.criado_em.to_rfc3339(),
            ],
        )?;

        Ok(())
    }

    fn get_subtitle_by_id(&self, id: Uuid) -> AppResult<Option<Subtitle>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare("SELECT * FROM subtitles WHERE id = ?1")?;

        match stmt.query_row(params![id.to_string()], Self::row_to_subtitle) {
            Ok(sub) => Ok(Some(sub)),
            Err(rusqlite::Error::QueryReturnedNoRows) => Ok(None),
            Err(e) => Err(AppError::Database(e)),
        }
    }

    fn list_by_file(&self, file_id: Uuid) -> AppResult<Vec<Subtitle>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare("SELECT * FROM subtitles WHERE file_id = ?1")?;

        let subs: Vec<Subtitle> = stmt
            .query_map(params![file_id.to_string()], Self::row_to_subtitle)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(subs)
    }

    fn list_by_language(&self, language: &str) -> AppResult<Vec<Subtitle>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare("SELECT * FROM subtitles WHERE idioma = ?1")?;

        let subs: Vec<Subtitle> = stmt
            .query_map(params![language], Self::row_to_subtitle)?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(subs)
    }

    fn save_transformation(&self, transformation: &SubtitleTransformation) -> AppResult<()> {
        let conn = self.pool.get()?;

        let parametros_json = serde_json::to_string(&transformation.parametros_aplicados)?;

        conn.execute(
            "INSERT INTO subtitle_transformations (
                id, subtitle_id_origem, tipo, parametros_aplicados, criado_em
            ) VALUES (?1, ?2, ?3, ?4, ?5)",
            params![
                transformation.id.to_string(),
                transformation.subtitle_id_origem.to_string(),
                transformation.tipo.to_string(),
                parametros_json,
                transformation.criado_em.to_rfc3339(),
            ],
        )?;

        Ok(())
    }

    fn get_transformations(&self, subtitle_id: Uuid) -> AppResult<Vec<SubtitleTransformation>> {
        let conn = self.pool.get()?;

        let mut stmt = conn.prepare(
            "SELECT * FROM subtitle_transformations WHERE subtitle_id_origem = ?1 ORDER BY criado_em"
        )?;

        let transformations: Vec<SubtitleTransformation> = stmt
            .query_map(
                params![subtitle_id.to_string()],
                Self::row_to_transformation,
            )?
            .collect::<Result<Vec<_>, _>>()?;

        Ok(transformations)
    }
}


--- FILE: src-tauri\src\services\anime_service.rs ---
// src-tauri/src/services/anime_service.rs
use crate::domain::anime::{validate_anime, Anime, AnimeStatus, AnimeType};
use crate::error::{AppError, AppResult};
use crate::events::{AnimeCreated, AnimeMerged, AnimeUpdated, EventBus};
use crate::repositories::{AnimeAliasRepository, AnimeRepository, ExternalReferenceRepository};
use chrono::{DateTime, Utc};
use std::sync::Arc;
use uuid::Uuid;

#[derive(Debug, Clone)]
pub struct CreateAnimeRequest {
    pub titulo_principal: String,
    pub titulos_alternativos: Vec<String>,
    pub tipo: AnimeType,
    pub status: AnimeStatus,
    pub total_episodios: Option<u32>,
    pub data_inicio: Option<DateTime<Utc>>,
    pub data_fim: Option<DateTime<Utc>>,
    pub metadados_livres: serde_json::Value,
}

#[derive(Debug, Clone)]
pub struct UpdateAnimeRequest {
    pub anime_id: Uuid,
    pub titulo_principal: Option<String>,
    pub titulos_alternativos: Option<Vec<String>>,
    pub tipo: Option<AnimeType>,
    pub status: Option<AnimeStatus>,
    pub total_episodios: Option<Option<u32>>,
    pub data_inicio: Option<Option<DateTime<Utc>>>,
    pub data_fim: Option<Option<DateTime<Utc>>>,
    pub metadados_livres: Option<serde_json::Value>,
}

#[derive(Debug, Clone)]
pub struct MergeAnimesRequest {
    pub principal_anime_id: Uuid,
    pub anime_to_merge_id: Uuid,
}

pub struct AnimeService {
    anime_repo: Arc<dyn AnimeRepository>,
    alias_repo: Arc<dyn AnimeAliasRepository>,
    external_ref_repo: Arc<dyn ExternalReferenceRepository>,
    event_bus: Arc<EventBus>,
}

impl AnimeService {
    pub fn new(
        anime_repo: Arc<dyn AnimeRepository>,
        alias_repo: Arc<dyn AnimeAliasRepository>,
        external_ref_repo: Arc<dyn ExternalReferenceRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            anime_repo,
            alias_repo,
            external_ref_repo,
            event_bus,
        }
    }

    pub fn create_anime(&self, request: CreateAnimeRequest) -> AppResult<Uuid> {
        let mut anime = Anime::new(request.titulo_principal, request.tipo);

        anime.update_metadata(
            None,
            Some(request.titulos_alternativos),
            None,
            Some(request.status),
            Some(request.total_episodios),
            Some(request.data_inicio),
            Some(request.data_fim),
            Some(request.metadados_livres),
        );

        validate_anime(&anime).map_err(AppError::Domain)?;
        self.anime_repo.save(&anime)?;

        self.event_bus.emit(AnimeCreated::new(
            anime.id,
            anime.titulo_principal.clone(),
            anime.tipo.to_string(),
        ));

        Ok(anime.id)
    }

    pub fn update_anime(&self, request: UpdateAnimeRequest) -> AppResult<()> {
        let mut anime = self
            .anime_repo
            .get_by_id(request.anime_id)?
            .ok_or(AppError::NotFound)?;

        anime.update_metadata(
            request.titulo_principal,
            request.titulos_alternativos,
            request.tipo,
            request.status,
            request.total_episodios,
            request.data_inicio,
            request.data_fim,
            request.metadados_livres,
        );

        validate_anime(&anime).map_err(AppError::Domain)?;
        self.anime_repo.save(&anime)?;

        self.event_bus.emit(AnimeUpdated::new(anime.id));
        Ok(())
    }

    pub fn get_anime(&self, anime_id: Uuid) -> AppResult<Option<Anime>> {
        self.anime_repo.get_by_id(anime_id)
    }

    pub fn list_all_animes(&self) -> AppResult<Vec<Anime>> {
        self.anime_repo.list_all()
    }

    pub fn merge_animes(&self, request: MergeAnimesRequest) -> AppResult<()> {
        let principal = self
            .anime_repo
            .get_by_id(request.principal_anime_id)?
            .ok_or(AppError::NotFound)?;
        let to_merge = self
            .anime_repo
            .get_by_id(request.anime_to_merge_id)?
            .ok_or(AppError::NotFound)?;

        let alias =
            crate::domain::AnimeAlias::new(principal.id, to_merge.id).map_err(AppError::Other)?;

        self.alias_repo.save(&alias)?;

        self.event_bus.emit(AnimeMerged::new(
            request.principal_anime_id,
            request.anime_to_merge_id,
        ));

        Ok(())
    }

    pub fn resolve_alias(&self, anime_id: Uuid) -> AppResult<Uuid> {
        if let Some(principal_id) = self.alias_repo.get_principal_for_alias(anime_id)? {
            Ok(principal_id)
        } else {
            Ok(anime_id)
        }
    }

    pub fn get_external_references(
        &self,
        anime_id: Uuid,
    ) -> AppResult<Vec<crate::domain::ExternalReference>> {
        self.external_ref_repo.list_by_anime(anime_id)
    }
}


--- FILE: src-tauri\src\services\episode_service.rs ---
// src-tauri/src/services/episode_service.rs
//
// Episode Service - Episode and Progress Management
//
// CRITICAL RULES:
// - Manages episodes and viewing progress ONLY
// - Never creates Anime or Files
// - Never manipulates subtitles
// - Progress updates are explicit and validated

use std::sync::Arc;
use uuid::Uuid;

use crate::domain::episode::{validate_episode, Episode, EpisodeNumber, EpisodeState};
use crate::error::{AppError, AppResult};
use crate::events::{
    EpisodeBecamePlayable, EpisodeCompleted, EpisodeCreated, EpisodeProgressUpdated, EventBus,
    FileLinkedToEpisode, PlaybackProgressUpdated, PlaybackStarted,
};
use crate::repositories::{AnimeRepository, EpisodeRepository, FileRepository};

/// Request to create a new episode
#[derive(Debug, Clone)]
pub struct CreateEpisodeRequest {
    pub anime_id: Uuid,
    pub numero: EpisodeNumber,
    pub titulo: Option<String>,
    pub duracao_esperada: Option<u64>,
}

/// Request to update episode metadata
#[derive(Debug, Clone)]
pub struct UpdateEpisodeMetadataRequest {
    pub episode_id: Uuid,
    pub titulo: Option<String>,
    pub duracao_esperada: Option<Option<u64>>,
}

/// Request to link a file to an episode
/// CORRECTED: Removed is_primary field - cannot be passed to repository
#[derive(Debug, Clone)]
pub struct LinkFileRequest {
    pub episode_id: Uuid,
    pub file_id: Uuid,
}

pub struct EpisodeService {
    episode_repo: Arc<dyn EpisodeRepository>,
    anime_repo: Arc<dyn AnimeRepository>,
    file_repo: Arc<dyn FileRepository>,
    event_bus: Arc<EventBus>,
}

impl EpisodeService {
    pub fn new(
        episode_repo: Arc<dyn EpisodeRepository>,
        anime_repo: Arc<dyn AnimeRepository>,
        file_repo: Arc<dyn FileRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            episode_repo,
            anime_repo,
            file_repo,
            event_bus,
        }
    }

    /// Create a new episode
    ///
    /// CRITICAL: anime_id MUST exist (validated)
    pub fn create_episode(&self, request: CreateEpisodeRequest) -> AppResult<Uuid> {
        // 1. Validate anime exists
        if !self.anime_repo.exists(request.anime_id)? {
            return Err(AppError::Other("Anime not found".to_string()));
        }

        // 2. Create domain entity
        let mut episode = Episode::new(request.anime_id, request.numero.clone());

        // 3. Apply additional metadata
        if let Some(titulo) = request.titulo {
            episode.titulo = Some(titulo);
        }
        if let Some(duracao) = request.duracao_esperada {
            episode.duracao_esperada = Some(duracao);
        }

        // 4. Validate domain invariants
        validate_episode(&episode).map_err(|e| AppError::Domain(e))?;

        // 5. Persist
        self.episode_repo.save(&episode)?;

        // 6. Emit event
        self.event_bus.emit(EpisodeCreated::new(
            episode.id,
            episode.anime_id,
            episode.numero.to_string(),
        ));

        Ok(episode.id)
    }

    /// Update episode metadata
    pub fn update_episode_metadata(&self, request: UpdateEpisodeMetadataRequest) -> AppResult<()> {
        // 1. Load episode
        let mut episode = self
            .episode_repo
            .get_by_id(request.episode_id)?
            .ok_or(AppError::NotFound)?;

        // 2. Apply updates
        episode.update_metadata(request.titulo, request.duracao_esperada);

        // 3. Validate
        validate_episode(&episode).map_err(|e| AppError::Domain(e))?;

        // 4. Persist
        self.episode_repo.save(&episode)?;

        Ok(())
    }

    /// Link a file to an episode
    ///
    /// CRITICAL: File must exist and be appropriate type
    /// CORRECTED: Removed is_primary parameter - determined from file type instead
    pub fn link_file(&self, request: LinkFileRequest) -> AppResult<()> {
        // 1. Validate episode exists
        let episode = self
            .episode_repo
            .get_by_id(request.episode_id)?
            .ok_or(AppError::NotFound)?;

        // 2. Validate file exists
        let file = self
            .file_repo
            .get_by_id(request.file_id)?
            .ok_or(AppError::NotFound)?;

        // 3. Create association (repository only accepts 2 arguments)
        self.episode_repo
            .link_file(request.episode_id, request.file_id)?;

        // 4. Determine is_primary from file type
        let is_primary = file.tipo == crate::domain::FileType::Video;

        // 5. Emit event
        self.event_bus.emit(FileLinkedToEpisode::new(
            request.episode_id,
            request.file_id,
            is_primary,
        ));

        // 6. If primary video file, emit EpisodeBecamePlayable
        if is_primary {
            self.event_bus.emit(EpisodeBecamePlayable::new(episode.id));
        }

        Ok(())
    }

    /// Update episode progress
    ///
    /// CRITICAL: Progress is validated by domain
    /// CRITICAL: Never decreases automatically
    pub fn update_progress(&self, episode_id: Uuid, progress_seconds: u64) -> AppResult<()> {
        // 1. Load episode
        let mut episode = self
            .episode_repo
            .get_by_id(episode_id)?
            .ok_or(AppError::NotFound)?;

        // 2. Update progress (domain validates)
        episode
            .update_progress(progress_seconds)
            .map_err(|e| AppError::Other(e))?;

        // 3. Validate
        validate_episode(&episode).map_err(|e| AppError::Domain(e))?;

        // 4. Persist
        self.episode_repo.save(&episode)?;

        // 5. Emit event
        self.event_bus.emit(EpisodeProgressUpdated::new(
            episode.id,
            episode.progresso_atual,
            episode.duracao_esperada,
        ));

        // 6. If completed, emit completion event
        if episode.estado == EpisodeState::Concluido {
            self.event_bus
                .emit(EpisodeCompleted::new(episode.id, episode.anime_id));
        }

        Ok(())
    }

    /// Mark episode as completed
    pub fn mark_completed(&self, episode_id: Uuid) -> AppResult<()> {
        // 1. Load episode
        let mut episode = self
            .episode_repo
            .get_by_id(episode_id)?
            .ok_or(AppError::NotFound)?;

        // 2. Mark completed
        episode.mark_completed();

        // 3. Persist
        self.episode_repo.save(&episode)?;

        // 4. Emit event
        self.event_bus
            .emit(EpisodeCompleted::new(episode.id, episode.anime_id));

        Ok(())
    }

    /// Reset episode progress
    pub fn reset_progress(&self, episode_id: Uuid) -> AppResult<()> {
        // 1. Load episode
        let mut episode = self
            .episode_repo
            .get_by_id(episode_id)?
            .ok_or(AppError::NotFound)?;

        // 2. Reset
        episode.reset_progress();

        // 3. Persist
        self.episode_repo.save(&episode)?;

        Ok(())
    }

    /// Get episode by ID
    pub fn get_episode(&self, episode_id: Uuid) -> AppResult<Option<Episode>> {
        self.episode_repo.get_by_id(episode_id)
    }

    /// List all episodes for an anime
    pub fn list_episodes_for_anime(&self, anime_id: Uuid) -> AppResult<Vec<Episode>> {
        self.episode_repo.list_by_anime(anime_id)
    }

    /// Setup event handlers
    /// This subscribes to playback events to update progress
    pub fn register_event_handlers(&self) {
        let episode_repo = Arc::clone(&self.episode_repo);
        let event_bus = Arc::clone(&self.event_bus);

        // Handle PlaybackStarted
        {
            let repo = Arc::clone(&episode_repo);
            self.event_bus
                .subscribe::<PlaybackStarted, _>(move |event| {
                    if let Ok(Some(mut episode)) = repo.get_by_id(event.episode_id) {
                        episode.estado = EpisodeState::EmProgresso;
                        let _ = repo.save(&episode);
                    }
                });
        }

        // Handle PlaybackProgressUpdated
        {
            let repo = Arc::clone(&episode_repo);
            let bus = Arc::clone(&event_bus);
            self.event_bus
                .subscribe::<PlaybackProgressUpdated, _>(move |event| {
                    if let Ok(Some(mut episode)) = repo.get_by_id(event.episode_id) {
                        if let Ok(_) = episode.update_progress(event.progress_seconds) {
                            let _ = repo.save(&episode);

                            // Emit progress update
                            bus.emit(EpisodeProgressUpdated::new(
                                episode.id,
                                episode.progresso_atual,
                                episode.duracao_esperada,
                            ));

                            // Emit completion if applicable
                            if episode.estado == EpisodeState::Concluido {
                                bus.emit(EpisodeCompleted::new(episode.id, episode.anime_id));
                            }
                        }
                    }
                });
        }
    }
}


--- FILE: src-tauri\src\services\external_integration_service.rs ---
// src-tauri/src/services/external_integration_service.rs
use crate::domain::{validate_external_reference, ExternalReference};
use crate::error::{AppError, AppResult};
use crate::events::{
    EventBus, ExternalMetadataFetched, ExternalMetadataLinked, ExternalMetadataRequested,
};
use crate::repositories::{AnimeRepository, ExternalReferenceRepository};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use uuid::Uuid;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExternalMetadata {
    pub external_id: String,
    pub title: String,
    pub alternative_titles: Vec<String>,
    pub total_episodes: Option<u32>,
    pub status: Option<String>,
    pub start_date: Option<String>,
    pub end_date: Option<String>,
    pub genres: Vec<String>,
    pub cover_image: Option<String>,
    pub synopsis: Option<String>,
}

// Esta estrutura estava faltando e causando erro no mod.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MetadataSuggestions {
    pub provider: String,
    pub suggestions: Vec<ExternalMetadata>,
}

#[derive(Debug, Clone)]
pub struct FetchMetadataRequest {
    pub anime_id: Uuid,
    pub provider: String,
}

#[derive(Debug, Clone)]
pub struct LinkExternalReferenceRequest {
    pub anime_id: Uuid,
    pub provider: String,
    pub external_id: String,
}

pub struct ExternalIntegrationService {
    external_ref_repo: Arc<dyn ExternalReferenceRepository>,
    anime_repo: Arc<dyn AnimeRepository>,
    event_bus: Arc<EventBus>,
}

impl ExternalIntegrationService {
    pub fn new(
        external_ref_repo: Arc<dyn ExternalReferenceRepository>,
        anime_repo: Arc<dyn AnimeRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            external_ref_repo,
            anime_repo,
            event_bus,
        }
    }

    pub fn fetch_and_link_metadata(&self, request: FetchMetadataRequest) -> AppResult<()> {
        self.event_bus.emit(ExternalMetadataRequested::new(
            request.anime_id,
            request.provider.clone(),
        ));
        Ok(())
    }

    pub fn link_external_reference(&self, request: LinkExternalReferenceRequest) -> AppResult<()> {
        if !self.anime_repo.exists(request.anime_id)? {
            return Err(AppError::NotFound);
        }

        let reference = ExternalReference::new(
            request.anime_id,
            request.provider.clone(),
            request.external_id.clone(),
        );

        validate_external_reference(&reference).map_err(AppError::Domain)?;

        self.external_ref_repo.save(&reference)?;

        self.event_bus.emit(ExternalMetadataLinked::new(
            request.anime_id,
            request.provider,
            request.external_id,
        ));

        Ok(())
    }

    pub fn search_external(
        &self,
        _provider: &str,
        _query: &str,
    ) -> AppResult<Vec<ExternalMetadata>> {
        let results: Vec<ExternalMetadata> = Vec::new();
        Ok(results)
    }

    pub fn sync_metadata_from_external(
        &self,
        anime_id: Uuid,
        provider: &str,
    ) -> AppResult<ExternalMetadata> {
        let anime = self
            .anime_repo
            .get_by_id(anime_id)?
            .ok_or(AppError::NotFound)?;

        let reference = self
            .external_ref_repo
            .get_by_anime_and_source(anime_id, provider)?
            .ok_or_else(|| AppError::Other("No external reference found".to_string()))?;

        let metadata = ExternalMetadata {
            external_id: reference.external_id.clone(),
            title: anime.titulo_principal.clone(),
            alternative_titles: anime.titulos_alternativos.clone(),
            total_episodes: anime.total_episodios,
            status: Some(anime.status.to_string()),
            start_date: anime.data_inicio.map(|d| d.to_rfc3339()),
            end_date: anime.data_fim.map(|d| d.to_rfc3339()),
            genres: Vec::new(),
            cover_image: None,
            synopsis: None,
        };

        self.event_bus.emit(ExternalMetadataFetched::new(
            anime_id,
            provider.to_string(),
            reference.external_id,
        ));

        Ok(metadata)
    }
}


--- FILE: src-tauri\src\services\file_service.rs ---
// src-tauri/src/services/file_service.rs
use crate::domain::file::{validate_file, File, FileOrigin, FileType};
use crate::error::{AppError, AppResult};
use crate::events::{DirectoryScanned, EventBus, FileDetected};
use crate::repositories::FileRepository;
use chrono::{DateTime, Utc};
use std::path::PathBuf;
use std::sync::Arc;
use uuid::Uuid;

/// Request to register a detected file
#[derive(Debug, Clone)]
pub struct RegisterFileRequest {
    pub caminho_absoluto: PathBuf,
    pub tipo: FileType,
    pub tamanho: u64,
    pub data_modificacao: DateTime<Utc>,
    pub origem: FileOrigin,
    pub hash: Option<String>,
}

pub struct FileService {
    file_repo: Arc<dyn FileRepository>,
    event_bus: Arc<EventBus>,
}

impl FileService {
    pub fn new(file_repo: Arc<dyn FileRepository>, event_bus: Arc<EventBus>) -> Self {
        Self {
            file_repo,
            event_bus,
        }
    }

    pub fn register_file(&self, request: RegisterFileRequest) -> AppResult<Uuid> {
        let path_str = request.caminho_absoluto.to_string_lossy();
        if let Some(existing) = self.file_repo.get_by_path(&path_str)? {
            if existing.has_changed(request.tamanho, request.data_modificacao) {
                return self.update_file_metadata(
                    existing.id,
                    request.tamanho,
                    request.data_modificacao,
                );
            } else {
                return Ok(existing.id);
            }
        }

        let mut file = File::new(
            request.caminho_absoluto.clone(),
            request.tipo,
            request.tamanho,
            request.data_modificacao,
            request.origem,
        );

        if let Some(hash) = request.hash {
            file.set_hash(hash);
        }

        validate_file(&file).map_err(AppError::Domain)?;

        self.file_repo.save(&file)?;

        self.event_bus.emit(FileDetected::new(
            request.caminho_absoluto,
            request.tamanho,
            request.tipo.to_string(),
        ));

        Ok(file.id)
    }

    pub fn update_file_metadata(
        &self,
        file_id: Uuid,
        tamanho: u64,
        data_modificacao: DateTime<Utc>,
    ) -> AppResult<Uuid> {
        let mut file = self
            .file_repo
            .get_by_id(file_id)?
            .ok_or(AppError::NotFound)?;

        file.update_metadata(tamanho, data_modificacao);

        validate_file(&file).map_err(AppError::Domain)?;

        self.file_repo.save(&file)?;

        self.event_bus.emit(FileDetected::new(
            file.caminho_absoluto.clone(),
            file.tamanho,
            file.tipo.to_string(),
        ));

        Ok(file.id)
    }

    pub fn calculate_and_set_hash(&self, file_id: Uuid) -> AppResult<String> {
        let mut file = self
            .file_repo
            .get_by_id(file_id)?
            .ok_or(AppError::NotFound)?;

        let hash = self.calculate_file_hash(&file.caminho_absoluto)?;
        file.set_hash(hash.clone());
        self.file_repo.save(&file)?;

        Ok(hash)
    }

    pub fn get_file(&self, file_id: Uuid) -> AppResult<Option<File>> {
        self.file_repo.get_by_id(file_id)
    }

    pub fn scan_directory(&self, directory_path: PathBuf) -> AppResult<usize> {
        if !directory_path.exists() {
            return Err(AppError::Other("Directory does not exist".to_string()));
        }
        if !directory_path.is_dir() {
            return Err(AppError::Other("Path is not a directory".to_string()));
        }

        let mut files_found = 0;

        for entry in walkdir::WalkDir::new(&directory_path)
            .follow_links(true)
            .into_iter()
            .filter_map(|e: Result<walkdir::DirEntry, walkdir::Error>| e.ok())
        {
            if entry.file_type().is_file() {
                let path = entry.path().to_path_buf();
                let file_type = FileType::from_extension(&path);

                if matches!(
                    file_type,
                    FileType::Video | FileType::Legenda | FileType::Imagem
                ) {
                    if let Ok(metadata) = std::fs::metadata(&path) {
                        self.event_bus.emit(FileDetected::new(
                            path.clone(),
                            metadata.len(),
                            file_type.to_string(),
                        ));
                        let request = RegisterFileRequest {
                            caminho_absoluto: path,
                            tipo: file_type,
                            tamanho: metadata.len(),
                            data_modificacao: chrono::DateTime::from(
                                metadata.modified().unwrap_or(std::time::SystemTime::now()),
                            ),
                            origem: FileOrigin::Scan,
                            hash: None,
                        };
                        let _ = self.register_file(request);
                        files_found += 1;
                    }
                }
            }
        }

        self.event_bus
            .emit(DirectoryScanned::new(directory_path, files_found));
        Ok(files_found)
    }

    fn calculate_file_hash(&self, path: &std::path::PathBuf) -> AppResult<String> {
        use sha2::{Digest, Sha256};
        use std::fs::File as StdFile;
        use std::io::Read;

        let mut file = StdFile::open(path)?;
        let mut hasher = Sha256::new();
        let mut buffer = [0u8; 8192];

        loop {
            let bytes_read = file.read(&mut buffer)?;
            if bytes_read == 0 {
                break;
            }
            hasher.update(&buffer[..bytes_read]);
        }

        let result = hasher.finalize();
        Ok(format!("{:x}", result))
    }
}


--- FILE: src-tauri\src\services\materialization_service.rs ---
// src-tauri/src/services/materialization_service.rs
//
// Materialization Service - Phase 5
//
// Consumes resolution events and materializes domain entities.
// This is the bridge between resolution knowledge and domain reality.
//
// CRITICAL RULES:
// - Consumes ONLY resolution events (FileResolved, EpisodeResolved)
// - Creates Anime/Episode entities via existing repositories
// - Links files to episodes via existing repositories
// - Enforces invariants at write time
// - Ensures idempotency via fingerprinting
// - Emits domain events for created/linked entities
// - Does NOT modify Resolution (Phase 4) code
// - Does NOT bypass repository contracts
//
// PHASE 5 GUARANTEES:
// - Deterministic: same events ‚Üí same domain state
// - Idempotent: replaying events does not duplicate entities
// - Traceable: every entity creation is linked to a resolution event

use chrono::Utc;
use std::sync::Arc;
use uuid::Uuid;

use super::materialization_types::{
    EpisodeNumberDecision, MaterializationDecision, MaterializationEventType,
    MaterializationFingerprint, MaterializationOutcome, MaterializationRecord,
    MaterializationResult,
};
use crate::domain::anime::{validate_anime, Anime, AnimeStatus, AnimeType};
use crate::domain::episode::{validate_episode, Episode, EpisodeNumber, EpisodeState};
use crate::domain::file::FileType;
use crate::error::{AppError, AppResult};
use crate::events::resolution_events::{EpisodeResolved, FileResolved};
use crate::events::DomainEvent;
use crate::events::types::{AnimeCreated, EpisodeCreated, FileLinkedToEpisode};
use crate::events::EventBus;
use crate::repositories::anime_repository::AnimeRepository;
use crate::repositories::EpisodeRepository;

use crate::repositories::FileRepository;

use crate::repositories::materialization_repository::MaterializationRepository;

// ============================================================================
// MATERIALIZATION SERVICE
// ============================================================================

pub struct MaterializationService {
    anime_repo: Arc<dyn AnimeRepository>,
    episode_repo: Arc<dyn EpisodeRepository>,
    file_repo: Arc<dyn FileRepository>,
    materialization_repo: Arc<dyn MaterializationRepository>,
    event_bus: Arc<EventBus>,
}

impl MaterializationService {
    pub fn new(
        anime_repo: Arc<dyn AnimeRepository>,
        episode_repo: Arc<dyn EpisodeRepository>,
        file_repo: Arc<dyn FileRepository>,
        materialization_repo: Arc<dyn MaterializationRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            anime_repo,
            episode_repo,
            file_repo,
            materialization_repo,
            event_bus,
        }
    }

    // ========================================================================
    // PUBLIC API: EVENT HANDLERS
    // ========================================================================

    /// Materialize a FileResolved event.
    /// This is the primary entry point for Phase 5.
    pub fn materialize_file_resolved(
        &self,
        event: &FileResolved,
    ) -> AppResult<MaterializationResult> {
        // Step 1: Compute fingerprint
        let fingerprint = MaterializationFingerprint::from_file_resolved(
            event.file_id,
            &event.anime_title,
            &event.episode_number,
            &event.file_role,
        );

        // Step 2: Check idempotency
        if self
            .materialization_repo
            .exists_by_fingerprint(&fingerprint)?
        {
            return Ok(MaterializationResult::skipped(
                fingerprint,
                "Already materialized",
            ));
        }

        // Step 3: Determine anime decision
        let anime_decision = self.decide_anime(&event.anime_title, event.matched_anime_id)?;

        // Step 4: Execute anime decision and get anime_id
        let (anime_id, is_new_anime) = self.execute_anime_decision(&anime_decision)?;

        // Step 5: Determine episode decision
        let episode_decision =
            self.decide_episode(anime_id, &event.episode_number, event.matched_episode_id)?;

        // Step 6: Execute episode decision and get episode_id
        let (episode_id, is_new_episode) = self.execute_episode_decision(&episode_decision)?;

        // Step 7: Link file to episode (if video or subtitle)
        let file_linked =
            self.link_file_if_applicable(episode_id, event.file_id, &event.file_role)?;

        // Step 8: Determine final outcome
        let outcome = self.determine_outcome(is_new_anime, is_new_episode, file_linked);

        // Step 9: Record materialization
        let record = MaterializationRecord::new(
            fingerprint.clone(),
            MaterializationEventType::FileResolved,
            event.event_id(),
            Some(anime_id),
            Some(episode_id),
            Some(event.file_id),
            outcome.clone(),
        );
        self.materialization_repo.save(&record)?;

        // Step 10: Return result
        Ok(MaterializationResult {
            fingerprint,
            anime_id: Some(anime_id),
            episode_id: Some(episode_id),
            file_id: Some(event.file_id),
            outcome,
            is_new_anime,
            is_new_episode,
        })
    }

    /// Materialize an EpisodeResolved event.
    /// Handles aggregated episode resolution.
    pub fn materialize_episode_resolved(
        &self,
        event: &EpisodeResolved,
    ) -> AppResult<MaterializationResult> {
        // Step 1: Compute fingerprint
        let fingerprint = MaterializationFingerprint::from_episode_resolved(
            &event.anime_title,
            &event.episode_number,
            event.video_file_id,
        );

        // Step 2: Check idempotency
        if self
            .materialization_repo
            .exists_by_fingerprint(&fingerprint)?
        {
            return Ok(MaterializationResult::skipped(
                fingerprint,
                "Already materialized",
            ));
        }

        // Step 3: Determine anime decision
        let anime_decision = self.decide_anime(&event.anime_title, event.matched_anime_id)?;

        // Step 4: Execute anime decision
        let (anime_id, is_new_anime) = self.execute_anime_decision(&anime_decision)?;

        // Step 5: Determine episode decision
        let episode_decision =
            self.decide_episode(anime_id, &event.episode_number, event.matched_episode_id)?;

        // Step 6: Execute episode decision
        let (episode_id, is_new_episode) = self.execute_episode_decision(&episode_decision)?;

        // Step 7: Link video file if present
        if let Some(video_id) = event.video_file_id {
            self.link_file_if_applicable(episode_id, video_id, "video")?;
        }

        // Step 8: Link subtitle files
        for sub_id in &event.subtitle_file_ids {
            self.link_file_if_applicable(episode_id, *sub_id, "subtitle")?;
        }

        // Step 9: Determine outcome
        let outcome = self.determine_outcome(
            is_new_anime,
            is_new_episode,
            event.video_file_id.is_some() || !event.subtitle_file_ids.is_empty(),
        );

        // Step 10: Record materialization
        let record = MaterializationRecord::new(
            fingerprint.clone(),
            MaterializationEventType::EpisodeResolved,
            event.event_id(),
            Some(anime_id),
            Some(episode_id),
            event.video_file_id,
            outcome.clone(),
        );
        self.materialization_repo.save(&record)?;

        Ok(MaterializationResult {
            fingerprint,
            anime_id: Some(anime_id),
            episode_id: Some(episode_id),
            file_id: event.video_file_id,
            outcome,
            is_new_anime,
            is_new_episode,
        })
    }

    // ========================================================================
    // DECISION LOGIC
    // ========================================================================

    /// Decide what to do about the anime: create new or use existing.
    fn decide_anime(
        &self,
        title: &str,
        matched_id: Option<Uuid>,
    ) -> AppResult<MaterializationDecision> {
        // If resolution already matched an anime, use it
        if let Some(anime_id) = matched_id {
            // Verify the anime still exists
            if self.anime_repo.get_by_id(anime_id)?.is_some() {
                return Ok(MaterializationDecision::UseExistingAnime { anime_id });
            }
        }

        // Try to find by title (case-insensitive)
        if let Some(existing) = self.find_anime_by_title(title)? {
            return Ok(MaterializationDecision::UseExistingAnime {
                anime_id: existing.id,
            });
        }

        // No match found, create new
        Ok(MaterializationDecision::CreateAnime {
            title: title.to_string(),
            alternative_titles: Vec::new(),
        })
    }

    /// Decide what to do about the episode: create new or use existing.
    fn decide_episode(
        &self,
        anime_id: Uuid,
        episode_number: &str,
        matched_id: Option<Uuid>,
    ) -> AppResult<MaterializationDecision> {
        // If resolution already matched an episode, use it
        if let Some(episode_id) = matched_id {
            // Verify the episode still exists
            if self.episode_repo.get_by_id(episode_id)?.is_some() {
                return Ok(MaterializationDecision::UseExistingEpisode { episode_id });
            }
        }

        // Parse episode number
        let number_decision = self.parse_episode_number(episode_number);

        // Try to find existing episode
        if let Some(existing) = self.find_episode_by_number(anime_id, &number_decision)? {
            return Ok(MaterializationDecision::UseExistingEpisode {
                episode_id: existing.id,
            });
        }

        // No match found, create new
        Ok(MaterializationDecision::CreateEpisode {
            anime_id,
            number: number_decision,
        })
    }

    // ========================================================================
    // EXECUTION LOGIC
    // ========================================================================

    /// Execute an anime decision, returning the anime_id and whether it was newly created.
    fn execute_anime_decision(
        &self,
        decision: &MaterializationDecision,
    ) -> AppResult<(Uuid, bool)> {
        match decision {
            MaterializationDecision::UseExistingAnime { anime_id } => Ok((*anime_id, false)),
            MaterializationDecision::CreateAnime {
                title,
                alternative_titles,
            } => {
                let now = Utc::now();
                let anime = Anime {
                    id: Uuid::new_v4(),
                    titulo_principal: title.clone(),
                    titulos_alternativos: alternative_titles.clone(),
                    tipo: AnimeType::TV,
                    status: AnimeStatus::EmExibicao,
                    total_episodios: None,
                    data_inicio: None,
                    data_fim: None,
                    metadados_livres: serde_json::Value::Null,
                    criado_em: now,
                    atualizado_em: now,
                };

                // Validate invariants before persisting
                validate_anime(&anime)?;

                // Persist
                self.anime_repo.save(&anime)?;

                // Emit event
                self.event_bus.emit(AnimeCreated::new(
                    anime.id,
                    anime.titulo_principal.clone(),
                    anime.tipo.to_string(),
                ));

                Ok((anime.id, true))
            }
            _ => Err(AppError::Other("Invalid anime decision".to_string())),
        }
    }

    /// Execute an episode decision, returning the episode_id and whether it was newly created.
    fn execute_episode_decision(
        &self,
        decision: &MaterializationDecision,
    ) -> AppResult<(Uuid, bool)> {
        match decision {
            MaterializationDecision::UseExistingEpisode { episode_id } => Ok((*episode_id, false)),
            MaterializationDecision::CreateEpisode { anime_id, number } => {
                let now = Utc::now();
                let (numero, titulo) = match number {
                    EpisodeNumberDecision::Regular(n) => {
                        (EpisodeNumber::Regular { numero: *n }, None)
                    }
                    EpisodeNumberDecision::Special(label) => (
                        EpisodeNumber::Special {
                            label: label.clone(),
                        },
                        Some(label.clone()),
                    ),
                };

                let episode = Episode {
                    id: Uuid::new_v4(),
                    anime_id: *anime_id,
                    numero,
                    titulo,
                    duracao_esperada: None,
                    progresso_atual: 0,
                    estado: EpisodeState::NaoVisto,
                    criado_em: now,
                    atualizado_em: now,
                };

                // Validate invariants before persisting
                validate_episode(&episode)?;

                // Persist
                self.episode_repo.save(&episode)?;

                // Emit event
                let numero_str = match &episode.numero {
                    EpisodeNumber::Regular { numero } => numero.to_string(),
                    EpisodeNumber::Special { label } => label.clone(),
                };
                self.event_bus
                    .emit(EpisodeCreated::new(episode.id, *anime_id, numero_str));

                Ok((episode.id, true))
            }
            _ => Err(AppError::Other("Invalid episode decision".to_string())),
        }
    }

    /// Link a file to an episode if applicable.
    /// CORRECTED: Removed call to non-existent get_linked_files
    /// CORRECTED: Removed is_primary parameter from link_file call
    fn link_file_if_applicable(
        &self,
        episode_id: Uuid,
        file_id: Uuid,
        file_role: &str,
    ) -> AppResult<bool> {
        // Only link video and subtitle files
        if file_role != "video" && file_role != "subtitle" {
            return Ok(false);
        }

        // Check if file exists
        let file = self.file_repo.get_by_id(file_id)?;
        if file.is_none() {
            return Ok(false);
        }

        // Link file to episode (repository only accepts 2 arguments)
        self.episode_repo
            .link_file(episode_id, file_id)?;

        // Determine is_primary from file_role
        let is_primary = file_role == "video";

        // Emit event
        self.event_bus
            .emit(FileLinkedToEpisode::new(episode_id, file_id, is_primary));

        Ok(true)
    }

    // ========================================================================
    // HELPER METHODS
    // ========================================================================

    /// Find an anime by title (case-insensitive search).
    fn find_anime_by_title(&self, title: &str) -> AppResult<Option<Anime>> {
        let normalized = title.to_lowercase();

        // Get all anime and search
        // Note: In production, this should be a repository method with proper indexing
        let all_anime = self.anime_repo.list_all()?;

        for anime in all_anime {
            if anime.titulo_principal.to_lowercase() == normalized {
                return Ok(Some(anime));
            }
            for alt in &anime.titulos_alternativos {
                if alt.to_lowercase() == normalized {
                    return Ok(Some(anime));
                }
            }
        }

        Ok(None)
    }

    /// Find an episode by number within an anime.
    fn find_episode_by_number(
        &self,
        anime_id: Uuid,
        number: &EpisodeNumberDecision,
    ) -> AppResult<Option<Episode>> {
        let episodes = self.episode_repo.list_by_anime(anime_id)?;

        for episode in episodes {
            match (number, &episode.numero) {
                (EpisodeNumberDecision::Regular(n), EpisodeNumber::Regular { numero }) => {
                    if *numero == *n {
                        return Ok(Some(episode));
                    }
                }
                (
                    EpisodeNumberDecision::Special(label),
                    EpisodeNumber::Special { label: ep_label },
                ) => {
                    if ep_label.to_lowercase() == label.to_lowercase() {
                        return Ok(Some(episode));
                    }
                }
                _ => {}
            }
        }

        Ok(None)
    }

    /// Parse an episode number string into a decision.
    fn parse_episode_number(&self, number_str: &str) -> EpisodeNumberDecision {
        // Try to parse as regular number
        if let Ok(n) = number_str.parse::<u32>() {
            return EpisodeNumberDecision::Regular(n);
        }

        // Check for range (e.g., "1-3")
        if number_str.contains('-') {
            if let Some((start, _)) = number_str.split_once('-') {
                if let Ok(n) = start.parse::<u32>() {
                    return EpisodeNumberDecision::Regular(n);
                }
            }
        }

        // Treat as special
        EpisodeNumberDecision::Special(number_str.to_string())
    }

    /// Determine the final outcome based on what was created/linked.
    fn determine_outcome(
        &self,
        is_new_anime: bool,
        is_new_episode: bool,
        file_linked: bool,
    ) -> MaterializationOutcome {
        if is_new_anime {
            MaterializationOutcome::AnimeCreated
        } else if is_new_episode {
            MaterializationOutcome::EpisodeCreated
        } else if file_linked {
            MaterializationOutcome::FileLinked
        } else {
            MaterializationOutcome::EpisodeMatched
        }
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    // Tests are in materialization_service_tests.rs
}


--- FILE: src-tauri\src\services\materialization_service_tests.rs ---
// src-tauri/src/services/materialization_service_tests.rs
//
// Materialization Service Tests - PHASE 4 CORRECTED
//
// CORRECTIONS APPLIED:
// - REMOVED: Mock repositories (hallucinated - do not exist)
// - REMOVED: ResolutionSource::Combined (dead variant)
// - REMOVED: event_id: Uuid::new_v4() in test helper (non-deterministic)
// - REMOVED: occurred_at: Utc::now() in test helper (non-deterministic)
// - Uses deterministic fingerprint computation
// - Uses canonical FileResolved::new() constructor

#[cfg(test)]
mod tests {
    use crate::events::resolution_events::FileResolved;
    use crate::events::DomainEvent;
    use std::collections::hash_map::DefaultHasher;
    use std::hash::{Hash, Hasher};
    use std::path::PathBuf;
    use uuid::Uuid;

    // ========================================================================
    // TEST HELPERS - CORRECTED
    // ========================================================================

    /// CORRECTED: Create FileResolved event using canonical constructor.
    /// 
    /// CHANGES FROM ORIGINAL:
    /// - Removed: event_id: Uuid::new_v4() (non-deterministic)
    /// - Removed: occurred_at: Utc::now() (non-deterministic)
    /// - Removed: resolution_source: ResolutionSource::Combined (dead variant)
    /// - Added: fingerprint computed deterministically
    /// - Added: source as "filename" (valid canonical value)
    fn create_file_resolved_event(
        file_id: Uuid,
        anime_title: &str,
        episode_number: &str,
        file_role: &str,
    ) -> FileResolved {
        // Compute a deterministic fingerprint for the test event
        let mut hasher = DefaultHasher::new();
        file_id.hash(&mut hasher);
        anime_title.to_lowercase().hash(&mut hasher);
        episode_number.hash(&mut hasher);
        file_role.hash(&mut hasher);
        let fingerprint = format!("test:{:016x}", hasher.finish());

        FileResolved::new(
            file_id,
            PathBuf::from("/test/path.mkv"),
            anime_title.to_string(),
            None,  // matched_anime_id
            episode_number.to_string(),
            None,  // matched_episode_id
            file_role.to_string(),
            0.9,   // confidence
            "filename".to_string(),  // source (valid: "filename" or "folder_name")
            fingerprint,
        )
    }

    // ========================================================================
    // DETERMINISM TESTS
    // ========================================================================

    #[test]
    fn test_file_resolved_event_is_deterministic() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let event1 = create_file_resolved_event(file_id, "Test Anime", "1", "video");
        let event2 = create_file_resolved_event(file_id, "Test Anime", "1", "video");

        // PROOF: Identical input produces identical fingerprint
        assert_eq!(event1.fingerprint, event2.fingerprint);
        
        // PROOF: event_id is derived from fingerprint, so also identical
        assert_eq!(event1.event_id(), event2.event_id());
    }

    #[test]
    fn test_different_input_produces_different_fingerprint() {
        let file_id1 = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();
        let file_id2 = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440001").unwrap();

        let event1 = create_file_resolved_event(file_id1, "Test Anime", "1", "video");
        let event2 = create_file_resolved_event(file_id2, "Test Anime", "1", "video");

        // PROOF: Different file_id produces different fingerprint
        assert_ne!(event1.fingerprint, event2.fingerprint);
        assert_ne!(event1.event_id(), event2.event_id());
    }

    #[test]
    fn test_different_episode_produces_different_fingerprint() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let event1 = create_file_resolved_event(file_id, "Test Anime", "1", "video");
        let event2 = create_file_resolved_event(file_id, "Test Anime", "2", "video");

        // PROOF: Different episode produces different fingerprint
        assert_ne!(event1.fingerprint, event2.fingerprint);
    }

    #[test]
    fn test_different_anime_produces_different_fingerprint() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let event1 = create_file_resolved_event(file_id, "Anime A", "1", "video");
        let event2 = create_file_resolved_event(file_id, "Anime B", "1", "video");

        // PROOF: Different anime produces different fingerprint
        assert_ne!(event1.fingerprint, event2.fingerprint);
    }

    // ========================================================================
    // EVENT STRUCTURE TESTS
    // ========================================================================

    #[test]
    fn test_file_resolved_event_has_required_fields() {
        let file_id = Uuid::new_v4();
        let event = create_file_resolved_event(file_id, "Test Anime", "1", "video");

        // PROOF: All required fields are populated
        assert_eq!(event.file_id, file_id);
        assert_eq!(event.anime_title, "Test Anime");
        assert_eq!(event.episode_number, "1");
        assert_eq!(event.file_role, "video");
        assert_eq!(event.source, "filename");
        assert!(!event.fingerprint.is_empty());
        assert!(event.confidence > 0.0);
    }

    #[test]
    fn test_file_resolved_event_id_is_uuid() {
        let file_id = Uuid::new_v4();
        let event = create_file_resolved_event(file_id, "Test Anime", "1", "video");

        // PROOF: event_id() returns a valid UUID
        let event_id = event.event_id();
        assert!(!event_id.is_nil());
    }

    // ========================================================================
    // FINGERPRINT HASH TESTS
    // ========================================================================

    #[test]
    fn test_fingerprint_format() {
        let file_id = Uuid::new_v4();
        let event = create_file_resolved_event(file_id, "Test Anime", "1", "video");

        // PROOF: Fingerprint has expected format (test: prefix + 16 hex chars)
        assert!(event.fingerprint.starts_with("test:"));
        assert_eq!(event.fingerprint.len(), 5 + 16); // "test:" + 16 hex chars
    }

    #[test]
    fn test_fingerprint_is_case_insensitive_for_title() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let event1 = create_file_resolved_event(file_id, "Test Anime", "1", "video");
        let event2 = create_file_resolved_event(file_id, "TEST ANIME", "1", "video");

        // PROOF: Title comparison is case-insensitive (both lowercased in hash)
        assert_eq!(event1.fingerprint, event2.fingerprint);
    }
}


--- FILE: src-tauri\src\services\materialization_types.rs ---
// src-tauri/src/services/materialization_types.rs
//
// Materialization Types - Phase 5
//
// Types for tracking materialization state and ensuring idempotency.
// These types bridge resolution events to domain mutations.
//
// CRITICAL RULES:
// - Fingerprints are deterministic (same input ‚Üí same fingerprint)
// - Fingerprints are used to detect duplicate materializations
// - No business logic in types
// - All types are serializable for persistence

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use std::path::PathBuf;
use uuid::Uuid;

// ============================================================================
// MATERIALIZATION FINGERPRINT
// ============================================================================

/// A deterministic fingerprint for a resolution event.
/// Used to detect if an event has already been materialized.
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct MaterializationFingerprint {
    /// The hash of the resolution event's key fields
    hash: String,
}

impl MaterializationFingerprint {
    /// Creates a fingerprint from a FileResolved event's key fields.
    /// The fingerprint is based on:
    /// - file_id (immutable identifier)
    /// - anime_title (normalized)
    /// - episode_number (as string)
    /// - file_role
    pub fn from_file_resolved(
        file_id: Uuid,
        anime_title: &str,
        episode_number: &str,
        file_role: &str,
    ) -> Self {
        let mut hasher = Sha256::new();
        hasher.update(file_id.as_bytes());
        hasher.update(anime_title.to_lowercase().as_bytes());
        hasher.update(episode_number.as_bytes());
        hasher.update(file_role.as_bytes());

        let result = hasher.finalize();
        Self {
            hash: format!("{:x}", result),
        }
    }

    /// Creates a fingerprint from an EpisodeResolved event's key fields.
    pub fn from_episode_resolved(
        anime_title: &str,
        episode_number: &str,
        video_file_id: Option<Uuid>,
    ) -> Self {
        let mut hasher = Sha256::new();
        hasher.update(anime_title.to_lowercase().as_bytes());
        hasher.update(episode_number.as_bytes());
        if let Some(vid_id) = video_file_id {
            hasher.update(vid_id.as_bytes());
        }

        let result = hasher.finalize();
        Self {
            hash: format!("{:x}", result),
        }
    }

    /// Constructs a fingerprint from a stored hash string.
    /// Used when loading from database.
    pub fn from_hash(hash: String) -> Self {
        Self { hash }
    }

    /// Returns the hash string
    pub fn hash(&self) -> &str {
        &self.hash
    }
}

// ============================================================================
// MATERIALIZATION RECORD
// ============================================================================

/// A record of a completed materialization.
/// Stored to prevent duplicate processing of the same resolution event.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MaterializationRecord {
    /// Unique identifier for this record
    pub id: Uuid,

    /// The fingerprint of the resolution event
    pub fingerprint: MaterializationFingerprint,

    /// The type of event that was materialized
    pub event_type: MaterializationEventType,

    /// The source event ID (from resolution)
    pub source_event_id: Uuid,

    /// The resulting anime ID (if created or matched)
    pub anime_id: Option<Uuid>,

    /// The resulting episode ID (if created or matched)
    pub episode_id: Option<Uuid>,

    /// The file ID that was linked (if applicable)
    pub file_id: Option<Uuid>,

    /// The outcome of materialization
    pub outcome: MaterializationOutcome,

    /// When this materialization occurred
    pub materialized_at: DateTime<Utc>,
}

impl MaterializationRecord {
    /// Creates a new materialization record
    pub fn new(
        fingerprint: MaterializationFingerprint,
        event_type: MaterializationEventType,
        source_event_id: Uuid,
        anime_id: Option<Uuid>,
        episode_id: Option<Uuid>,
        file_id: Option<Uuid>,
        outcome: MaterializationOutcome,
    ) -> Self {
        Self {
            id: Uuid::new_v4(),
            fingerprint,
            event_type,
            source_event_id,
            anime_id,
            episode_id,
            file_id,
            outcome,
            materialized_at: Utc::now(),
        }
    }
}

// ============================================================================
// MATERIALIZATION EVENT TYPE
// ============================================================================

/// The type of resolution event being materialized.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum MaterializationEventType {
    /// FileResolved event
    FileResolved,

    /// EpisodeResolved event
    EpisodeResolved,
}

impl std::fmt::Display for MaterializationEventType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            MaterializationEventType::FileResolved => write!(f, "file_resolved"),
            MaterializationEventType::EpisodeResolved => write!(f, "episode_resolved"),
        }
    }
}

// ============================================================================
// MATERIALIZATION OUTCOME
// ============================================================================

/// The outcome of a materialization operation.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum MaterializationOutcome {
    /// New anime was created
    AnimeCreated,

    /// Matched to existing anime
    AnimeMatched,

    /// New episode was created
    EpisodeCreated,

    /// Matched to existing episode
    EpisodeMatched,

    /// File was linked to episode
    FileLinked,

    /// Skipped because already materialized (idempotent)
    Skipped,

    /// Failed to materialize
    Failed { reason: String },
}

impl std::fmt::Display for MaterializationOutcome {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            MaterializationOutcome::AnimeCreated => write!(f, "anime_created"),
            MaterializationOutcome::AnimeMatched => write!(f, "anime_matched"),
            MaterializationOutcome::EpisodeCreated => write!(f, "episode_created"),
            MaterializationOutcome::EpisodeMatched => write!(f, "episode_matched"),
            MaterializationOutcome::FileLinked => write!(f, "file_linked"),
            MaterializationOutcome::Skipped => write!(f, "skipped"),
            MaterializationOutcome::Failed { reason } => write!(f, "failed: {}", reason),
        }
    }
}

// ============================================================================
// MATERIALIZATION DECISION
// ============================================================================

/// The decision made during materialization.
/// This is the internal representation of what action to take.
#[derive(Debug, Clone)]
pub enum MaterializationDecision {
    /// Create a new anime with the given title
    CreateAnime {
        title: String,
        alternative_titles: Vec<String>,
    },

    /// Use an existing anime
    UseExistingAnime { anime_id: Uuid },

    /// Create a new episode for the given anime
    CreateEpisode {
        anime_id: Uuid,
        number: EpisodeNumberDecision,
    },

    /// Use an existing episode
    UseExistingEpisode { episode_id: Uuid },

    /// Link a file to an episode
    LinkFile {
        episode_id: Uuid,
        file_id: Uuid,
        is_primary: bool,
    },

    /// Skip this event (already materialized)
    Skip { reason: String },
}

/// Episode number decision for creation
#[derive(Debug, Clone)]
pub enum EpisodeNumberDecision {
    /// Regular numbered episode
    Regular(u32),

    /// Special episode with label
    Special(String),
}

// ============================================================================
// MATERIALIZATION RESULT
// ============================================================================

/// The result of a materialization operation.
#[derive(Debug, Clone)]
pub struct MaterializationResult {
    /// The fingerprint of the processed event
    pub fingerprint: MaterializationFingerprint,

    /// The anime ID (created or matched)
    pub anime_id: Option<Uuid>,

    /// The episode ID (created or matched)
    pub episode_id: Option<Uuid>,

    /// The file ID that was linked
    pub file_id: Option<Uuid>,

    /// The outcome
    pub outcome: MaterializationOutcome,

    /// Whether this was a new creation or a match
    pub is_new_anime: bool,

    /// Whether this was a new episode creation
    pub is_new_episode: bool,
}

impl MaterializationResult {
    /// Creates a result for a skipped materialization
    pub fn skipped(fingerprint: MaterializationFingerprint, reason: &str) -> Self {
        Self {
            fingerprint,
            anime_id: None,
            episode_id: None,
            file_id: None,
            outcome: MaterializationOutcome::Skipped,
            is_new_anime: false,
            is_new_episode: false,
        }
    }

    /// Creates a result for a failed materialization
    pub fn failed(fingerprint: MaterializationFingerprint, reason: String) -> Self {
        Self {
            fingerprint,
            anime_id: None,
            episode_id: None,
            file_id: None,
            outcome: MaterializationOutcome::Failed { reason },
            is_new_anime: false,
            is_new_episode: false,
        }
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_fingerprint_determinism() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let fp1 =
            MaterializationFingerprint::from_file_resolved(file_id, "Steins;Gate", "1", "video");

        let fp2 =
            MaterializationFingerprint::from_file_resolved(file_id, "Steins;Gate", "1", "video");

        assert_eq!(fp1, fp2);
        assert_eq!(fp1.hash(), fp2.hash());
    }

    #[test]
    fn test_fingerprint_case_insensitive_title() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let fp1 =
            MaterializationFingerprint::from_file_resolved(file_id, "Steins;Gate", "1", "video");

        let fp2 =
            MaterializationFingerprint::from_file_resolved(file_id, "steins;gate", "1", "video");

        assert_eq!(fp1, fp2);
    }

    #[test]
    fn test_fingerprint_different_episodes() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let fp1 =
            MaterializationFingerprint::from_file_resolved(file_id, "Steins;Gate", "1", "video");

        let fp2 =
            MaterializationFingerprint::from_file_resolved(file_id, "Steins;Gate", "2", "video");

        assert_ne!(fp1, fp2);
    }

    #[test]
    fn test_fingerprint_from_hash() {
        let original =
            MaterializationFingerprint::from_file_resolved(Uuid::new_v4(), "Test", "1", "video");

        let restored = MaterializationFingerprint::from_hash(original.hash().to_string());
        assert_eq!(original, restored);
    }

    #[test]
    fn test_materialization_outcome_display() {
        assert_eq!(
            MaterializationOutcome::AnimeCreated.to_string(),
            "anime_created"
        );
        assert_eq!(MaterializationOutcome::Skipped.to_string(), "skipped");
        assert_eq!(
            MaterializationOutcome::Failed {
                reason: "test".to_string()
            }
            .to_string(),
            "failed: test"
        );
    }
}


--- FILE: src-tauri\src\services\mod.rs ---
// src-tauri/src/services/mod.rs
//
// Services Module - Orchestration Layer
//
// CRITICAL RULES:
// - Services orchestrate domain operations
// - Services emit events
// - Services enforce invariants
// - Services are the ONLY entry point for mutations

// ============================================================================
// EXISTING SERVICE MODULES (SEALED - Phase 3)
// ============================================================================

pub mod anime_service;
pub mod episode_service;
pub mod external_integration_service;
pub mod file_service;
pub mod playback_observer;
pub mod playback_service;
pub mod statistics_service;
pub mod subtitle_service;

// ============================================================================
// RESOLUTION SERVICE (FROZEN - Phase 4)
// ============================================================================

pub mod resolution_service;

#[cfg(test)]
mod resolution_service_tests;

// ============================================================================
// MATERIALIZATION SERVICE (NEW - Phase 5)
// ============================================================================

pub mod materialization_service;
pub mod materialization_types;

#[cfg(test)]
mod materialization_service_tests;

// ============================================================================
// PUBLIC EXPORTS - Services
// ============================================================================

// Anime Service
pub use anime_service::AnimeService;
pub use anime_service::CreateAnimeRequest;
pub use anime_service::MergeAnimesRequest;
pub use anime_service::UpdateAnimeRequest;

// Episode Service
pub use episode_service::CreateEpisodeRequest;
pub use episode_service::EpisodeService;
pub use episode_service::LinkFileRequest;
pub use episode_service::UpdateEpisodeMetadataRequest;

// File Service
pub use file_service::FileService;
pub use file_service::RegisterFileRequest;

// Playback Service
pub use playback_service::PlaybackService;
pub use playback_service::StartPlaybackRequest;

// Playback Observer
pub use playback_observer::ObserverConfig;
pub use playback_observer::PlaybackObserver;

// Statistics Service
pub use statistics_service::StatisticsService;

// External Integration Service
pub use external_integration_service::ExternalIntegrationService;
pub use external_integration_service::ExternalMetadata;
pub use external_integration_service::FetchMetadataRequest;
pub use external_integration_service::LinkExternalReferenceRequest;
pub use external_integration_service::MetadataSuggestions;

// Subtitle Service
pub use subtitle_service::StyleTransformRequest;
pub use subtitle_service::SubtitleService;
pub use subtitle_service::TimingTransformRequest;

// Resolution Service (Phase 4 - FROZEN)
pub use resolution_service::ResolutionRules;
pub use resolution_service::ResolutionService;

// Materialization Service (Phase 5)
pub use materialization_service::MaterializationService;
pub use materialization_types::EpisodeNumberDecision;
pub use materialization_types::MaterializationDecision;
pub use materialization_types::MaterializationEventType;
pub use materialization_types::MaterializationFingerprint;
pub use materialization_types::MaterializationOutcome;
pub use materialization_types::MaterializationRecord;
pub use materialization_types::MaterializationResult;


--- FILE: src-tauri\src\services\playback_observer.rs ---
// src-tauri/src/services/playback_observer.rs
//
// Playback Observer - Background monitoring of MPV state
//
// CRITICAL RULES:
// - Runs in background task
// - Polls MPV periodically for position, pause state, eof-reached
// - Emits domain events based on observed changes
// - Does NOT persist state directly
// - Does NOT call domain services

use std::sync::{Arc, Mutex};
use std::time::Duration;
use tokio::task::JoinHandle;
use uuid::Uuid;

use crate::events::types::{PlaybackFinished, PlaybackProgressUpdated, PlaybackStopped};
use crate::events::EventBus;
use crate::integrations::mpv::MpvClient;

#[derive(Debug, Clone)]
pub struct ObserverConfig {
    pub poll_interval_ms: u64,
    pub min_progress_delta: u64,
    pub completion_threshold: f32,
}

impl Default for ObserverConfig {
    fn default() -> Self {
        Self {
            poll_interval_ms: 2000,
            min_progress_delta: 5,
            completion_threshold: 0.90,
        }
    }
}

#[derive(Clone)]
struct ObservationSession {
    episode_id: Uuid,
    last_reported_position: u64,
    duration: Option<u64>,
    completed_emitted: bool,
}

pub struct PlaybackObserver {
    mpv_client: Arc<MpvClient>,
    event_bus: Arc<EventBus>,
    config: ObserverConfig,
    current_session: Arc<Mutex<Option<ObservationSession>>>,
    task_handle: Arc<Mutex<Option<JoinHandle<()>>>>,
}

impl PlaybackObserver {
    pub fn new(
        mpv_client: Arc<MpvClient>,
        event_bus: Arc<EventBus>,
        config: ObserverConfig,
    ) -> Self {
        Self {
            mpv_client,
            event_bus,
            config,
            current_session: Arc::new(Mutex::new(None)),
            task_handle: Arc::new(Mutex::new(None)),
        }
    }

    pub fn start_observing(&self, episode_id: Uuid, initial_position: u64, duration: Option<u64>) {
        self.stop_observing();

        {
            let mut session = self.current_session.lock().unwrap();
            *session = Some(ObservationSession {
                episode_id,
                last_reported_position: initial_position,
                duration,
                completed_emitted: false,
            });
        }

        self.spawn_observer_task();
    }

    pub fn stop_observing(&self) {
        {
            let mut session = self.current_session.lock().unwrap();
            *session = None;
        }
        let mut handle = self.task_handle.lock().unwrap();
        if let Some(task) = handle.take() {
            task.abort();
        }
    }

    pub fn is_observing(&self) -> bool {
        self.current_session.lock().unwrap().is_some()
    }

    fn spawn_observer_task(&self) {
        let mpv_client = Arc::clone(&self.mpv_client);
        let event_bus = Arc::clone(&self.event_bus);
        let session = Arc::clone(&self.current_session);
        let config = self.config.clone();

        let task = tokio::spawn(async move {
            let interval = Duration::from_millis(config.poll_interval_ms);

            loop {
                tokio::time::sleep(interval).await;

                let mut current = {
                    let guard = session.lock().unwrap();
                    if let Some(s) = guard.as_ref() {
                        s.clone()
                    } else {
                        break;
                    }
                };

                if !mpv_client.is_running() {
                    event_bus.emit(PlaybackStopped::new(
                        current.episode_id,
                        current.last_reported_position,
                    ));
                    let mut guard = session.lock().unwrap();
                    *guard = None;
                    break;
                }

                let position = match mpv_client.get_position() {
                    Ok(p) => p,
                    Err(_) => continue,
                };

                // Atualiza dura√ß√£o se ainda desconhecida
                if current.duration.is_none() {
                    if let Ok(Some(dur)) = mpv_client.get_duration() {
                        current.duration = Some(dur);
                    }
                }

                // Verifica conclus√£o (90% ou mais)
                let completed = current.completed_emitted
                    || current.duration.map_or(false, |dur| {
                        (position as f32 / dur as f32) >= config.completion_threshold
                    });

                if completed && !current.completed_emitted {
                    // Usa dura√ß√£o conhecida ou 0 como fallback
                    let duration_seconds = current.duration.unwrap_or(0);
                    event_bus.emit(PlaybackFinished::new(current.episode_id, duration_seconds));
                    current.completed_emitted = true;
                }

                // Atualiza progresso se mudou significativamente
                let delta = if position > current.last_reported_position {
                    position - current.last_reported_position
                } else {
                    current.last_reported_position - position
                };

                if delta >= config.min_progress_delta {
                    event_bus.emit(PlaybackProgressUpdated::new(current.episode_id, position));
                    current.last_reported_position = position;
                }

                // Atualiza sess√£o
                {
                    let mut guard = session.lock().unwrap();
                    if let Some(s) = guard.as_mut() {
                        s.last_reported_position = position;
                        s.duration = current.duration;
                        s.completed_emitted = current.completed_emitted;
                    }
                }
            }
        });

        let mut handle = self.task_handle.lock().unwrap();
        *handle = Some(task);
    }
}

impl Drop for PlaybackObserver {
    fn drop(&mut self) {
        self.stop_observing();
    }
}


--- FILE: src-tauri\src\services\playback_service.rs ---
// src-tauri/src/services/playback_service.rs
//
// Playback Service - Player Integration
//
// PHASE 6 IMPLEMENTATION COMPLETE
// - Launches MPV (if needed) with fixed IPC pipe
// - Loads file via IPC (replace mode)
// - Resumes from saved progress (>5 min threshold)
// - Controls pause/seek/stop via IPC commands
// - Observer handles progress/pause/eof events
// - All state changes go through events ‚Üí EpisodeService persists
//
// PHASE 4 CORRECTIONS:
// - REMOVED: get_linked_files call (hallucinated API)
// - file_id is now required in StartPlaybackRequest

use std::io::Write;
use std::path::PathBuf;
use std::process::{Command, Stdio};
use std::sync::Arc;
use uuid::Uuid;

use crate::error::{AppError, AppResult};
use crate::events::{EventBus, PlaybackProgressUpdated, PlaybackStarted};
use crate::integrations::mpv::MpvClient;
use crate::repositories::{EpisodeRepository, FileRepository};
use crate::services::playback_observer::{ObserverConfig, PlaybackObserver};

const PIPE_NAME: &str = "animehub-mpv";
const RESUME_THRESHOLD_SECONDS: u64 = 300;

#[derive(Debug, Clone)]
pub struct StartPlaybackRequest {
    pub episode_id: Uuid,
    /// CORRECTION: file_id is now required since get_linked_files doesn't exist
    pub file_id: Uuid,
}

fn send_ipc_command(json_cmd: &str) -> std::io::Result<()> {
    let pipe_path = format!(r"\\.\pipe\{}", PIPE_NAME);
    let mut file = std::fs::OpenOptions::new().write(true).open(pipe_path)?;
    file.write_all(json_cmd.as_bytes())?;
    file.write_all(b"\n")?;
    Ok(())
}

pub struct PlaybackService {
    episode_repo: Arc<dyn EpisodeRepository>,
    file_repo: Arc<dyn FileRepository>,
    event_bus: Arc<EventBus>,
    mpv_client: Arc<MpvClient>,
    observer: Arc<PlaybackObserver>,
}

impl PlaybackService {
    pub fn new(
        episode_repo: Arc<dyn EpisodeRepository>,
        file_repo: Arc<dyn FileRepository>,
        event_bus: Arc<EventBus>,
        mpv_client: Arc<MpvClient>,
    ) -> Self {
        let observer = Arc::new(PlaybackObserver::new(
            mpv_client.clone(),
            event_bus.clone(),
            ObserverConfig::default(),
        ));

        Self {
            episode_repo,
            file_repo,
            event_bus,
            mpv_client,
            observer,
        }
    }

    pub fn start_playback(&self, request: StartPlaybackRequest) -> AppResult<PathBuf> {
        let episode = self
            .episode_repo
            .get_by_id(request.episode_id)?
            .ok_or(AppError::NotFound)?;

        // CORRECTION: file_id is now required, no fallback to get_linked_files
        let file = self
            .file_repo
            .get_by_id(request.file_id)?
            .ok_or(AppError::NotFound)?;

        if file.tipo != crate::domain::file::FileType::Video {
            return Err(AppError::Other("Not a video file".to_string()));
        }
        if !file.caminho_absoluto.exists() {
            return Err(AppError::Other("File not found on disk".to_string()));
        }

        let saved_progress = episode.progresso_atual;
        let start_pos = if saved_progress >= RESUME_THRESHOLD_SECONDS {
            saved_progress
        } else {
            0
        };

        // CORRE√á√ÉO: is_running retorna bool
        let is_running = self.mpv_client.is_running();
        if !is_running {
            Command::new("mpv")
                .arg(format!("--input-ipc-server=\\\\.\\pipe\\{}", PIPE_NAME))
                .arg("--idle=yes")
                .arg("--keep-open=yes")
                .arg("--no-terminal")
                .stdout(Stdio::null())
                .stderr(Stdio::null())
                .spawn()
                .map_err(|e| AppError::Other(format!("Failed to launch MPV: {}", e)))?;
        }

        let escaped_path = file
            .caminho_absoluto
            .to_string_lossy()
            .replace("\\", "\\\\")
            .replace("\"", "\\\"");
        let load_cmd = format!(r#"{{"command":["loadfile","{}","replace"]}}"#, escaped_path);
        let _ = send_ipc_command(&load_cmd);

        if start_pos > 0 {
            let seek_cmd = format!(r#"{{"command":["seek",{},"absolute"]}}"#, start_pos);
            let _ = send_ipc_command(&seek_cmd);
        }

        self.observer
            .start_observing(request.episode_id, start_pos, episode.duracao_esperada);

        self.event_bus
            .emit(PlaybackStarted::new(request.episode_id));

        Ok(file.caminho_absoluto.clone())
    }

    pub fn toggle_pause(&self) -> AppResult<()> {
        let cmd = r#"{"command":["cycle","pause"]}"#;
        send_ipc_command(cmd).map_err(|e| AppError::Other(e.to_string()))?;
        Ok(())
    }

    pub fn seek_to(&self, episode_id: Uuid, position_seconds: u64) -> AppResult<()> {
        let cmd = format!(r#"{{"command":["seek",{},"absolute"]}}"#, position_seconds);
        send_ipc_command(&cmd).map_err(|e| AppError::Other(e.to_string()))?;
        self.report_progress(episode_id, position_seconds)?;
        Ok(())
    }

    pub fn stop_playback(&self, episode_id: Uuid) -> AppResult<()> {
        if let Ok(pos) = self.mpv_client.get_position() {
            self.report_progress(episode_id, pos)?;
        }
        let cmd = r#"{"command":["quit"]}"#;
        let _ = send_ipc_command(cmd);
        self.observer.stop_observing();
        Ok(())
    }

    fn report_progress(&self, episode_id: Uuid, progress_seconds: u64) -> AppResult<()> {
        self.event_bus
            .emit(PlaybackProgressUpdated::new(episode_id, progress_seconds));
        Ok(())
    }

    // Keep get_current_position if needed elsewhere
    pub fn get_current_position(&self, episode_id: Uuid) -> AppResult<u64> {
        let episode = self
            .episode_repo
            .get_by_id(episode_id)?
            .ok_or(AppError::NotFound)?;
        Ok(episode.progresso_atual)
    }
}


--- FILE: src-tauri\src\services\resolution_service.rs ---
// src-tauri/src/services/resolution_service.rs
//
// Resolution Service - Phase 4 (CORRECTED)
//
// PURPOSE:
// - Parse file metadata to extract anime and episode information
// - Match against existing domain entities (READ-ONLY)
// - Emit resolution events for Phase 5 consumption
// - Aggregate file resolutions into episode resolutions
//
// CRITICAL INVARIANTS (ALL ENFORCED):
// - Resolution is PURE: no domain mutations, no persistence
// - Resolution is DETERMINISTIC: same input ‚Üí same output (no timestamps)
// - Resolution is IDEMPOTENT: repeated resolution of same file is skipped
// - Repository access is READ-ONLY
// - All errors are EXPLICIT: no silent fallbacks
// - All events are REACHABLE: no dead code paths
//
// PHASE 4 CORRECTIONS APPLIED:
// - Idempotency enforced via fingerprint tracking
// - EpisodeResolved emitted through aggregation logic
// - Silent error swallowing eliminated (.ok().flatten() removed)
// - Image files included in batch resolution
// - skipped_count is meaningful (tracks idempotent skips)
// - All dead enum variants removed from value objects
// - REMOVED: ResolutionFingerprint::from_result (hallucinated API)
// - REMOVED: FileRepository::list_by_type (hallucinated API)
// - FIXED: UnparsableTitle ‚Üí UnparsableFilename
// - FIXED: UnparsableEpisodeNumber ‚Üí NoEpisodeNumber

use crate::domain::file::{File, FileType};
use crate::domain::resolution::{
    FileRole, ResolutionConfidence, ResolutionFailure, ResolutionFailureReason,
    ResolutionResult, ResolutionSource, ResolvedAnimeIntent,
    ResolvedEpisodeIntent, ResolvedEpisodeNumber, ResolvedFile,
};
use crate::domain::resolution::value_objects::ResolutionFingerprint;
use crate::domain::anime::Anime;
use crate::domain::episode::Episode;
use crate::error::{AppError, AppResult};
use crate::events::resolution_events::{
    EpisodeResolved, FileResolved, ResolutionBatchCompleted, ResolutionFailed, ResolutionSkipped,
};
use crate::events::EventBus;
use crate::repositories::{AnimeRepository, EpisodeRepository, FileRepository};
use regex::Regex;
use std::collections::{HashMap, HashSet};
use std::path::PathBuf;
use std::sync::Arc;
use uuid::Uuid;

// ============================================================================
// RESOLUTION SERVICE
// ============================================================================

pub struct ResolutionService {
    file_repo: Arc<dyn FileRepository>,
    anime_repo: Arc<dyn AnimeRepository>,
    episode_repo: Arc<dyn EpisodeRepository>,
    event_bus: Arc<EventBus>,
    rules: ResolutionRules,
    /// Tracks fingerprints of already-resolved files for idempotency
    resolved_fingerprints: std::sync::RwLock<HashSet<String>>,
}

impl ResolutionService {
    pub fn new(
        file_repo: Arc<dyn FileRepository>,
        anime_repo: Arc<dyn AnimeRepository>,
        episode_repo: Arc<dyn EpisodeRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            file_repo,
            anime_repo,
            episode_repo,
            event_bus,
            rules: ResolutionRules::default(),
            resolved_fingerprints: std::sync::RwLock::new(HashSet::new()),
        }
    }

    /// Load existing fingerprints from a persistence source (called at startup)
    pub fn load_fingerprints(&self, fingerprints: Vec<String>) {
        let mut guard = self.resolved_fingerprints.write().unwrap();
        for fp in fingerprints {
            guard.insert(fp);
        }
    }

    // ========================================================================
    // PUBLIC API
    // ========================================================================

    /// Resolve a single file by ID.
    /// Returns the resolution result and emits appropriate events.
    ///
    /// IDEMPOTENCY: If file was already resolved (fingerprint exists), returns skipped.
    pub fn resolve_file(&self, file_id: Uuid) -> AppResult<ResolutionOutcome> {
        let file = self.file_repo.get_by_id(file_id)?;

        match file {
            Some(f) => {
                let result = self.resolve_file_internal(&f)?;

                // Compute fingerprint from the result
                let fingerprint = self.compute_fingerprint_from_result(&result);
                if self.is_already_resolved(&fingerprint) {
                    let outcome = ResolutionOutcome::Skipped {
                        file_id: f.id,
                        fingerprint: fingerprint.hash().to_string(),
                    };
                    self.event_bus.emit(ResolutionSkipped::new(
                        f.id,
                        f.caminho_absoluto.clone(),
                        fingerprint.hash().to_string(),
                        "already_resolved".to_string(),
                    ));
                    return Ok(outcome);
                }

                // Mark as resolved
                self.mark_resolved(&fingerprint);

                // Emit event
                self.emit_resolution_event(&result);

                Ok(ResolutionOutcome::Processed(result))
            }
            None => Err(AppError::NotFound),
        }
    }

    /// Resolve all pending files (Video, Subtitle, Image).
    /// Enforces idempotency and aggregates episode resolutions.
    ///
    /// CORRECTION: Uses list_unlinked() instead of hallucinated list_by_type()
    pub fn resolve_all_pending(&self) -> AppResult<ResolutionBatchResult> {
        let start_time = std::time::Instant::now();

        // Get all unlinked files and filter by type
        let all_files = self.file_repo.list_unlinked()?;
        let files: Vec<File> = all_files
            .into_iter()
            .filter(|f| matches!(f.tipo, FileType::Video | FileType::Legenda | FileType::Imagem))
            .collect();

        self.resolve_batch(files, start_time)
    }

    /// Resolve files in a specific directory.
    /// Enforces idempotency and aggregates episode resolutions.
    pub fn resolve_directory(&self, directory_path: &PathBuf) -> AppResult<ResolutionBatchResult> {
        let start_time = std::time::Instant::now();

        // Get all unlinked files and filter by directory and type
        let all_files = self.file_repo.list_unlinked()?;
        let files: Vec<File> = all_files
            .into_iter()
            .filter(|f| {
                matches!(f.tipo, FileType::Video | FileType::Legenda | FileType::Imagem)
                    && f.caminho_absoluto.starts_with(directory_path)
            })
            .collect();

        self.resolve_batch(files, start_time)
    }

    // ========================================================================
    // BATCH RESOLUTION (INTERNAL)
    // ========================================================================

    fn resolve_batch(
        &self,
        files: Vec<File>,
        start_time: std::time::Instant,
    ) -> AppResult<ResolutionBatchResult> {
        let total_files = files.len();
        let mut results: Vec<ResolutionResult> = Vec::with_capacity(total_files);
        let mut resolved_count = 0;
        let mut failed_count = 0;
        let mut skipped_count = 0;

        // Aggregation map: (anime_title_normalized, episode_number) -> files
        let mut episode_aggregation: HashMap<(String, String), EpisodeAggregation> = HashMap::new();

        for file in files {
            let result = self.resolve_file_internal(&file)?;

            // Compute fingerprint from the result
            let fingerprint = self.compute_fingerprint_from_result(&result);
            if self.is_already_resolved(&fingerprint) {
                skipped_count += 1;
                self.event_bus.emit(ResolutionSkipped::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    fingerprint.hash().to_string(),
                    "already_resolved".to_string(),
                ));
                continue;
            }

            // Mark as resolved
            self.mark_resolved(&fingerprint);

            // Emit file-level event
            self.emit_resolution_event(&result);

            match &result {
                ResolutionResult::Success(resolved) => {
                    resolved_count += 1;

                    // Aggregate for episode resolution
                    let key = (
                        resolved.anime_intent.title.to_lowercase(),
                        resolved.episode_intent.number.to_string(),
                    );
                    let aggregation = episode_aggregation.entry(key).or_insert_with(|| {
                        EpisodeAggregation::new(
                            resolved.anime_intent.title.clone(),
                            resolved.anime_intent.matched_anime_id,
                            resolved.episode_intent.number.to_string(),
                            resolved.episode_intent.matched_episode_id,
                        )
                    });
                    aggregation.add_file(resolved);
                }
                ResolutionResult::Failure(_) => {
                    failed_count += 1;
                }
            }

            results.push(result);
        }

        // Emit EpisodeResolved events for aggregated episodes
        let episodes_aggregated = episode_aggregation.len();
        for (_, aggregation) in episode_aggregation {
            let episode_event = aggregation.into_event();
            self.event_bus.emit(episode_event);
        }

        let duration_ms = start_time.elapsed().as_millis() as u64;

        // Emit batch completion event
        self.event_bus.emit(ResolutionBatchCompleted::new(
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
            duration_ms,
        ));

        Ok(ResolutionBatchResult {
            results,
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
            duration_ms,
        })
    }

    // ========================================================================
    // INTERNAL RESOLUTION LOGIC
    // ========================================================================

    /// Resolve a single file (internal, does not emit events).
    ///
    /// CORRECTION: Errors are propagated explicitly, not swallowed.
    fn resolve_file_internal(&self, file: &File) -> AppResult<ResolutionResult> {
        // Step 1: Determine file role
        let role = match file.tipo {
            FileType::Video => FileRole::Video,
            FileType::Legenda => FileRole::Subtitle,
            FileType::Imagem => FileRole::Image,
            FileType::Outro => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::UnsupportedFileType,
                    "File type 'outro' is not supported for resolution".to_string(),
                )));
            }
        };

        // Step 2: Parse anime title
        // CORRECTION: UnparsableTitle ‚Üí UnparsableFilename (canonical variant)
        let anime_parse_result = self.rules.parse_anime_title(&file.caminho_absoluto);
        let (anime_title, anime_source) = match anime_parse_result {
            Some((title, source)) => (title, source),
            None => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::UnparsableFilename,
                    "Could not extract anime title from filename or folder".to_string(),
                )));
            }
        };

        // Step 3: Parse episode number
        // CORRECTION: UnparsableEpisodeNumber ‚Üí NoEpisodeNumber (canonical variant)
        let episode_parse_result = self.rules.parse_episode_number(&file.caminho_absoluto);
        let (episode_number, episode_source) = match episode_parse_result {
            Some((num, source)) => (num, source),
            None => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::NoEpisodeNumber,
                    "Could not extract episode number from filename".to_string(),
                )));
            }
        };

        // Step 4: Try to match against existing anime (READ-ONLY)
        // CORRECTION: Errors are propagated, not swallowed
        let matched_anime_id = self.try_match_anime(&anime_title)?;

        // Step 5: Try to match against existing episode (if anime matched)
        // CORRECTION: Errors are propagated, not swallowed
        let matched_episode_id = match matched_anime_id {
            Some(anime_id) => self.try_match_episode(anime_id, &episode_number)?,
            None => None,
        };

        // Step 6: Calculate confidence
        let confidence = self.rules.calculate_confidence(
            &anime_title,
            &episode_number,
            matched_anime_id.is_some(),
            matched_episode_id.is_some(),
            &anime_source,
            &episode_source,
        );

        // Step 7: Check confidence threshold
        if !confidence.meets_threshold() {
            return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                file.id,
                file.caminho_absoluto.clone(),
                ResolutionFailureReason::LowConfidence,
                format!(
                    "Confidence score {} is below threshold {}",
                    confidence.score(),
                    ResolutionConfidence::THRESHOLD
                ),
            )));
        }

        // Step 8: Build resolved file
        let anime_intent = match matched_anime_id {
            Some(id) => ResolvedAnimeIntent::matched(id, anime_title, anime_source),
            None => ResolvedAnimeIntent::from_parsed_title(anime_title, anime_source),
        };

        let episode_intent = match matched_episode_id {
            Some(id) => ResolvedEpisodeIntent::matched(id, episode_number, episode_source),
            None => ResolvedEpisodeIntent::from_parsed_number(episode_number, episode_source),
        };

        Ok(ResolutionResult::Success(ResolvedFile::new(
            file.id,
            file.caminho_absoluto.clone(),
            role,
            anime_intent,
            episode_intent,
            confidence,
        )))
    }

    /// Attempt to match parsed title against existing anime entities.
    /// This is a READ-ONLY operation.
    ///
    /// CORRECTION: Returns AppResult, errors are not swallowed.
    fn try_match_anime(&self, title: &str) -> AppResult<Option<Uuid>> {
        let animes = self.anime_repo.list_all()?;
        let normalized_title = self.rules.normalize_title(title);

        for anime in animes {
            let normalized_anime_title = self.rules.normalize_title(&anime.titulo_principal);
            if normalized_anime_title == normalized_title {
                return Ok(Some(anime.id));
            }
        }

        Ok(None)
    }

    /// Attempt to match parsed episode number against existing episodes.
    /// This is a READ-ONLY operation.
    ///
    /// CORRECTION: Returns AppResult, errors are not swallowed.
    fn try_match_episode(
        &self,
        anime_id: Uuid,
        episode_number: &ResolvedEpisodeNumber,
    ) -> AppResult<Option<Uuid>> {
        let episodes = self.episode_repo.list_by_anime(anime_id)?;

        for episode in episodes {
            match (&episode.numero, episode_number) {
                (
                    crate::domain::episode::EpisodeNumber::Regular { numero },
                    ResolvedEpisodeNumber::Regular { number },
                ) => {
                    if numero == number {
                        return Ok(Some(episode.id));
                    }
                }
                (
                    crate::domain::episode::EpisodeNumber::Special { label: ep_label },
                    ResolvedEpisodeNumber::Special { label: res_label },
                ) => {
                    if ep_label.to_lowercase() == res_label.to_lowercase() {
                        return Ok(Some(episode.id));
                    }
                }
                _ => {}
            }
        }

        Ok(None)
    }

    // ========================================================================
    // IDEMPOTENCY ENFORCEMENT
    // ========================================================================

    fn is_already_resolved(&self, fingerprint: &ResolutionFingerprint) -> bool {
        let guard = self.resolved_fingerprints.read().unwrap();
        guard.contains(fingerprint.hash())
    }

    fn mark_resolved(&self, fingerprint: &ResolutionFingerprint) {
        let mut guard = self.resolved_fingerprints.write().unwrap();
        guard.insert(fingerprint.hash().to_string());
    }

    /// Compute fingerprint from a ResolutionResult.
    /// CORRECTION: This replaces the hallucinated ResolutionFingerprint::from_result
    fn compute_fingerprint_from_result(&self, result: &ResolutionResult) -> ResolutionFingerprint {
        match result {
            ResolutionResult::Success(resolved) => resolved.fingerprint(),
            ResolutionResult::Failure(failure) => failure.fingerprint(),
        }
    }

    // ========================================================================
    // EVENT EMISSION
    // ========================================================================

    fn emit_resolution_event(&self, result: &ResolutionResult) {
        match result {
            ResolutionResult::Success(resolved) => {
                self.event_bus.emit(FileResolved::new(
                    resolved.file_id,
                    resolved.file_path.clone(),
                    resolved.anime_intent.title.clone(),
                    resolved.anime_intent.matched_anime_id,
                    resolved.episode_intent.number.to_string(),
                    resolved.episode_intent.matched_episode_id,
                    resolved.role.to_string(),
                    resolved.confidence.score(),
                    resolved.anime_intent.source.to_string(),
                    resolved.fingerprint().to_string(),
                ));
            }
            ResolutionResult::Failure(failure) => {
                self.event_bus.emit(ResolutionFailed::new(
                    failure.file_id,
                    failure.file_path.clone(),
                    failure.reason.to_string(),
                    failure.description.clone(),
                ));
            }
        }
    }
}

// ============================================================================
// EPISODE AGGREGATION (FOR EpisodeResolved EMISSION)
// ============================================================================

/// Aggregates file resolutions into an episode resolution.
/// This makes EpisodeResolved reachable through real resolution flow.
struct EpisodeAggregation {
    anime_title: String,
    matched_anime_id: Option<Uuid>,
    episode_number: String,
    matched_episode_id: Option<Uuid>,
    video_file_id: Option<Uuid>,
    subtitle_file_ids: Vec<Uuid>,
    image_file_ids: Vec<Uuid>,
    max_confidence: f64,
}

impl EpisodeAggregation {
    fn new(
        anime_title: String,
        matched_anime_id: Option<Uuid>,
        episode_number: String,
        matched_episode_id: Option<Uuid>,
    ) -> Self {
        Self {
            anime_title,
            matched_anime_id,
            episode_number,
            matched_episode_id,
            video_file_id: None,
            subtitle_file_ids: Vec::new(),
            image_file_ids: Vec::new(),
            max_confidence: 0.0,
        }
    }

    fn add_file(&mut self, resolved: &ResolvedFile) {
        match resolved.role {
            FileRole::Video => {
                // First video becomes primary
                if self.video_file_id.is_none() {
                    self.video_file_id = Some(resolved.file_id);
                }
            }
            FileRole::Subtitle => {
                self.subtitle_file_ids.push(resolved.file_id);
            }
            FileRole::Image => {
                self.image_file_ids.push(resolved.file_id);
            }
        }

        if resolved.confidence.score() > self.max_confidence {
            self.max_confidence = resolved.confidence.score();
        }
    }

    fn into_event(self) -> EpisodeResolved {
        EpisodeResolved::new(
            self.anime_title,
            self.matched_anime_id,
            self.episode_number,
            self.matched_episode_id,
            self.video_file_id,
            self.subtitle_file_ids,
            self.image_file_ids,
            self.max_confidence,
        )
    }
}

// ============================================================================
// RESOLUTION OUTCOME (FOR SINGLE FILE API)
// ============================================================================

/// Outcome of resolving a single file.
#[derive(Debug)]
pub enum ResolutionOutcome {
    /// File was processed (success or failure)
    Processed(ResolutionResult),

    /// File was skipped due to idempotency
    Skipped { file_id: Uuid, fingerprint: String },
}

// ============================================================================
// RESOLUTION BATCH RESULT
// ============================================================================

/// Result of a batch resolution operation.
#[derive(Debug)]
pub struct ResolutionBatchResult {
    pub results: Vec<ResolutionResult>,
    pub total_files: usize,
    pub resolved_count: usize,
    pub failed_count: usize,
    pub skipped_count: usize,
    pub episodes_aggregated: usize,
    pub duration_ms: u64,
}

// ============================================================================
// RESOLUTION RULES
// ============================================================================

pub struct ResolutionRules {
    title_patterns: Vec<Regex>,
    episode_number_patterns: Vec<Regex>,
    special_episode_patterns: Vec<Regex>,
}

impl Default for ResolutionRules {
    fn default() -> Self {
        Self {
            title_patterns: vec![
                // [SubGroup] Title - 01 [quality].ext
                Regex::new(r"^\[.*?\]\s*(.+?)\s*-\s*\d+").unwrap(),
                // Title - 01.ext
                Regex::new(r"^(.+?)\s*-\s*\d+").unwrap(),
                // Title S01E01.ext
                Regex::new(r"^(.+?)\s*S\d+E\d+").unwrap(),
                // Title Episode 01.ext
                Regex::new(r"^(.+?)\s*Episode\s*\d+").unwrap(),
            ],
            episode_number_patterns: vec![
                // - 01, - 001
                Regex::new(r"-\s*(\d+)").unwrap(),
                // S01E01
                Regex::new(r"S\d+E(\d+)").unwrap(),
                // Episode 01
                Regex::new(r"Episode\s*(\d+)").unwrap(),
                // #01
                Regex::new(r"#(\d+)").unwrap(),
            ],
            special_episode_patterns: vec![
                // OVA, OVA 1, OVA1
                Regex::new(r"(OVA\s*\d*)").unwrap(),
                // OAD, OAD 1
                Regex::new(r"(OAD\s*\d*)").unwrap(),
                // Special, Special 1
                Regex::new(r"(Special\s*\d*)").unwrap(),
                // Movie, Movie 1
                Regex::new(r"(Movie\s*\d*)").unwrap(),
            ],
        }
    }
}

impl ResolutionRules {
    /// Parse anime title from file path
    pub fn parse_anime_title(&self, path: &PathBuf) -> Option<(String, ResolutionSource)> {
        // Try filename first
        if let Some(filename) = path.file_stem().and_then(|s| s.to_str()) {
            for pattern in &self.title_patterns {
                if let Some(captures) = pattern.captures(filename) {
                    if let Some(title) = captures.get(1) {
                        return Some((title.as_str().trim().to_string(), ResolutionSource::Filename));
                    }
                }
            }
        }

        // Fall back to folder name
        if let Some(parent) = path.parent() {
            if let Some(folder) = parent.file_name().and_then(|s| s.to_str()) {
                // Use folder name as title if it looks reasonable
                if folder.len() >= 3 && !folder.starts_with('.') {
                    return Some((folder.to_string(), ResolutionSource::FolderName));
                }
            }
        }

        None
    }

    /// Parse episode number from file path
    pub fn parse_episode_number(
        &self,
        path: &PathBuf,
    ) -> Option<(ResolvedEpisodeNumber, ResolutionSource)> {
        let filename = path.file_stem().and_then(|s| s.to_str())?;

        // Check for special episodes first
        for pattern in &self.special_episode_patterns {
            if let Some(captures) = pattern.captures(filename) {
                if let Some(label) = captures.get(1) {
                    return Some((
                        ResolvedEpisodeNumber::Special {
                            label: label.as_str().trim().to_string(),
                        },
                        ResolutionSource::Filename,
                    ));
                }
            }
        }

        // Try regular episode patterns
        for pattern in &self.episode_number_patterns {
            if let Some(captures) = pattern.captures(filename) {
                if let Some(num_str) = captures.get(1) {
                    if let Ok(number) = num_str.as_str().parse::<u32>() {
                        return Some((
                            ResolvedEpisodeNumber::Regular { number },
                            ResolutionSource::Filename,
                        ));
                    }
                }
            }
        }

        None
    }

    /// Calculate confidence score based on resolution quality
    pub fn calculate_confidence(
        &self,
        anime_title: &str,
        episode_number: &ResolvedEpisodeNumber,
        anime_matched: bool,
        episode_matched: bool,
        anime_source: &ResolutionSource,
        episode_source: &ResolutionSource,
    ) -> ResolutionConfidence {
        let mut score = 0.5; // Base score

        // Bonus for matching existing entities
        if anime_matched {
            score += 0.2;
        }
        if episode_matched {
            score += 0.15;
        }

        // Bonus for filename source (more reliable than folder)
        if matches!(anime_source, ResolutionSource::Filename) {
            score += 0.1;
        }
        if matches!(episode_source, ResolutionSource::Filename) {
            score += 0.05;
        }

        // Penalty for short titles (likely false positives)
        if anime_title.len() < 3 {
            score -= 0.3;
        }

        // Penalty for special episodes (harder to match)
        if matches!(episode_number, ResolvedEpisodeNumber::Special { .. }) {
            score -= 0.1;
        }

        ResolutionConfidence::new(score)
    }

    /// Normalize title for comparison
    pub fn normalize_title(&self, title: &str) -> String {
        title
            .to_lowercase()
            .replace(['_', '-', '.', ':', ';', '!', '?'], " ")
            .split_whitespace()
            .collect::<Vec<_>>()
            .join(" ")
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_anime_title_from_filename() {
        let rules = ResolutionRules::default();

        // [SubGroup] Anime Title - 01 [1080p].mkv
        let path = PathBuf::from("[SubGroup] Steins Gate - 01 [1080p].mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, source) = result.unwrap();
        assert_eq!(title, "Steins Gate");
        assert_eq!(source, ResolutionSource::Filename);

        // Anime Title - 01.mkv
        let path = PathBuf::from("Attack on Titan - 01.mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, _) = result.unwrap();
        assert_eq!(title, "Attack on Titan");
    }

    #[test]
    fn test_parse_episode_number() {
        let rules = ResolutionRules::default();

        // - 01
        let path = PathBuf::from("Anime - 01.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 1 });

        // S01E05
        let path = PathBuf::from("Anime S01E05.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 5 });

        // OVA
        let path = PathBuf::from("Anime OVA.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert!(matches!(num, ResolvedEpisodeNumber::Special { .. }));
    }

    #[test]
    fn test_confidence_calculation() {
        let rules = ResolutionRules::default();

        // High confidence: matched anime and episode, filename source
        let confidence = rules.calculate_confidence(
            "Steins;Gate",
            &ResolvedEpisodeNumber::Regular { number: 1 },
            true,
            true,
            &ResolutionSource::Filename,
            &ResolutionSource::Filename,
        );
        assert!(confidence.meets_threshold());
        assert!(confidence.score() > 0.8);

        // Low confidence: no matches, short title
        let confidence = rules.calculate_confidence(
            "AB",
            &ResolvedEpisodeNumber::Special {
                label: "?".to_string(),
            },
            false,
            false,
            &ResolutionSource::FolderName,
            &ResolutionSource::FolderName,
        );
        assert!(!confidence.meets_threshold());
    }

    #[test]
    fn test_normalize_title() {
        let rules = ResolutionRules::default();

        assert_eq!(rules.normalize_title("Steins;Gate"), "steins gate");
        assert_eq!(rules.normalize_title("Attack_on_Titan"), "attack on titan");
        assert_eq!(rules.normalize_title("Re:Zero"), "re zero");
    }

    #[test]
    fn test_fingerprint_determinism() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let result1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let result2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // Identical input produces identical fingerprint
        assert_eq!(result1.fingerprint(), result2.fingerprint());
    }
}
// src-tauri/src/services/resolution_service.rs
//
// Resolution Service - Phase 4 (CORRECTED)
//
// PURPOSE:
// - Parse file metadata to extract anime and episode information
// - Match against existing domain entities (READ-ONLY)
// - Emit resolution events for Phase 5 consumption
// - Aggregate file resolutions into episode resolutions
//
// CRITICAL INVARIANTS (ALL ENFORCED):
// - Resolution is PURE: no domain mutations, no persistence
// - Resolution is DETERMINISTIC: same input ‚Üí same output (no timestamps)
// - Resolution is IDEMPOTENT: repeated resolution of same file is skipped
// - Repository access is READ-ONLY
// - All errors are EXPLICIT: no silent fallbacks
// - All events are REACHABLE: no dead code paths
//
// PHASE 4 CORRECTIONS APPLIED:
// - Idempotency enforced via fingerprint tracking
// - EpisodeResolved emitted through aggregation logic
// - Silent error swallowing eliminated (.ok().flatten() removed)
// - Image files included in batch resolution
// - skipped_count is meaningful (tracks idempotent skips)
// - All dead enum variants removed from value objects
// - REMOVED: ResolutionFingerprint::from_result (hallucinated API)
// - REMOVED: FileRepository::list_by_type (hallucinated API)
// - FIXED: UnparsableTitle ‚Üí UnparsableFilename
// - FIXED: UnparsableEpisodeNumber ‚Üí NoEpisodeNumber

use crate::domain::file::{File, FileType};
use crate::domain::resolution::{
    FileRole, ResolutionConfidence, ResolutionFailure, ResolutionFailureReason,
    ResolutionResult, ResolutionSource, ResolvedAnimeIntent,
    ResolvedEpisodeIntent, ResolvedEpisodeNumber, ResolvedFile,
};
use crate::domain::resolution::value_objects::ResolutionFingerprint;
use crate::domain::anime::Anime;
use crate::domain::episode::Episode;
use crate::error::{AppError, AppResult};
use crate::events::resolution_events::{
    EpisodeResolved, FileResolved, ResolutionBatchCompleted, ResolutionFailed, ResolutionSkipped,
};
use crate::events::EventBus;
use crate::repositories::{AnimeRepository, EpisodeRepository, FileRepository};
use regex::Regex;
use std::collections::{HashMap, HashSet};
use std::path::PathBuf;
use std::sync::Arc;
use uuid::Uuid;

// ============================================================================
// RESOLUTION SERVICE
// ============================================================================

pub struct ResolutionService {
    file_repo: Arc<dyn FileRepository>,
    anime_repo: Arc<dyn AnimeRepository>,
    episode_repo: Arc<dyn EpisodeRepository>,
    event_bus: Arc<EventBus>,
    rules: ResolutionRules,
    /// Tracks fingerprints of already-resolved files for idempotency
    resolved_fingerprints: std::sync::RwLock<HashSet<String>>,
}

impl ResolutionService {
    pub fn new(
        file_repo: Arc<dyn FileRepository>,
        anime_repo: Arc<dyn AnimeRepository>,
        episode_repo: Arc<dyn EpisodeRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            file_repo,
            anime_repo,
            episode_repo,
            event_bus,
            rules: ResolutionRules::default(),
            resolved_fingerprints: std::sync::RwLock::new(HashSet::new()),
        }
    }

    /// Load existing fingerprints from a persistence source (called at startup)
    pub fn load_fingerprints(&self, fingerprints: Vec<String>) {
        let mut guard = self.resolved_fingerprints.write().unwrap();
        for fp in fingerprints {
            guard.insert(fp);
        }
    }

    // ========================================================================
    // PUBLIC API
    // ========================================================================

    /// Resolve a single file by ID.
    /// Returns the resolution result and emits appropriate events.
    ///
    /// IDEMPOTENCY: If file was already resolved (fingerprint exists), returns skipped.
    pub fn resolve_file(&self, file_id: Uuid) -> AppResult<ResolutionOutcome> {
        let file = self.file_repo.get_by_id(file_id)?;

        match file {
            Some(f) => {
                let result = self.resolve_file_internal(&f)?;

                // Compute fingerprint from the result
                let fingerprint = self.compute_fingerprint_from_result(&result);
                if self.is_already_resolved(&fingerprint) {
                    let outcome = ResolutionOutcome::Skipped {
                        file_id: f.id,
                        fingerprint: fingerprint.hash().to_string(),
                    };
                    self.event_bus.emit(ResolutionSkipped::new(
                        f.id,
                        f.caminho_absoluto.clone(),
                        fingerprint.hash().to_string(),
                        "already_resolved".to_string(),
                    ));
                    return Ok(outcome);
                }

                // Mark as resolved
                self.mark_resolved(&fingerprint);

                // Emit event
                self.emit_resolution_event(&result);

                Ok(ResolutionOutcome::Processed(result))
            }
            None => Err(AppError::NotFound),
        }
    }

    /// Resolve all pending files (Video, Subtitle, Image).
    /// Enforces idempotency and aggregates episode resolutions.
    ///
    /// CORRECTION: Uses list_unlinked() instead of hallucinated list_by_type()
    pub fn resolve_all_pending(&self) -> AppResult<ResolutionBatchResult> {
        let start_time = std::time::Instant::now();

        // Get all unlinked files and filter by type
        let all_files = self.file_repo.list_unlinked()?;
        let files: Vec<File> = all_files
            .into_iter()
            .filter(|f| matches!(f.tipo, FileType::Video | FileType::Legenda | FileType::Imagem))
            .collect();

        self.resolve_batch(files, start_time)
    }

    /// Resolve files in a specific directory.
    /// Enforces idempotency and aggregates episode resolutions.
    pub fn resolve_directory(&self, directory_path: &PathBuf) -> AppResult<ResolutionBatchResult> {
        let start_time = std::time::Instant::now();

        // Get all unlinked files and filter by directory and type
        let all_files = self.file_repo.list_unlinked()?;
        let files: Vec<File> = all_files
            .into_iter()
            .filter(|f| {
                matches!(f.tipo, FileType::Video | FileType::Legenda | FileType::Imagem)
                    && f.caminho_absoluto.starts_with(directory_path)
            })
            .collect();

        self.resolve_batch(files, start_time)
    }

    // ========================================================================
    // BATCH RESOLUTION (INTERNAL)
    // ========================================================================

    fn resolve_batch(
        &self,
        files: Vec<File>,
        start_time: std::time::Instant,
    ) -> AppResult<ResolutionBatchResult> {
        let total_files = files.len();
        let mut results: Vec<ResolutionResult> = Vec::with_capacity(total_files);
        let mut resolved_count = 0;
        let mut failed_count = 0;
        let mut skipped_count = 0;

        // Aggregation map: (anime_title_normalized, episode_number) -> files
        let mut episode_aggregation: HashMap<(String, String), EpisodeAggregation> = HashMap::new();

        for file in files {
            let result = self.resolve_file_internal(&file)?;

            // Compute fingerprint from the result
            let fingerprint = self.compute_fingerprint_from_result(&result);
            if self.is_already_resolved(&fingerprint) {
                skipped_count += 1;
                self.event_bus.emit(ResolutionSkipped::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    fingerprint.hash().to_string(),
                    "already_resolved".to_string(),
                ));
                continue;
            }

            // Mark as resolved
            self.mark_resolved(&fingerprint);

            // Emit file-level event
            self.emit_resolution_event(&result);

            match &result {
                ResolutionResult::Success(resolved) => {
                    resolved_count += 1;

                    // Aggregate for episode resolution
                    let key = (
                        resolved.anime_intent.title.to_lowercase(),
                        resolved.episode_intent.number.to_string(),
                    );
                    let aggregation = episode_aggregation.entry(key).or_insert_with(|| {
                        EpisodeAggregation::new(
                            resolved.anime_intent.title.clone(),
                            resolved.anime_intent.matched_anime_id,
                            resolved.episode_intent.number.to_string(),
                            resolved.episode_intent.matched_episode_id,
                        )
                    });
                    aggregation.add_file(resolved);
                }
                ResolutionResult::Failure(_) => {
                    failed_count += 1;
                }
            }

            results.push(result);
        }

        // Emit EpisodeResolved events for aggregated episodes
        let episodes_aggregated = episode_aggregation.len();
        for (_, aggregation) in episode_aggregation {
            let episode_event = aggregation.into_event();
            self.event_bus.emit(episode_event);
        }

        let duration_ms = start_time.elapsed().as_millis() as u64;

        // Emit batch completion event
        self.event_bus.emit(ResolutionBatchCompleted::new(
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
            duration_ms,
        ));

        Ok(ResolutionBatchResult {
            results,
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
            duration_ms,
        })
    }

    // ========================================================================
    // INTERNAL RESOLUTION LOGIC
    // ========================================================================

    /// Resolve a single file (internal, does not emit events).
    ///
    /// CORRECTION: Errors are propagated explicitly, not swallowed.
    fn resolve_file_internal(&self, file: &File) -> AppResult<ResolutionResult> {
        // Step 1: Determine file role
        let role = match file.tipo {
            FileType::Video => FileRole::Video,
            FileType::Legenda => FileRole::Subtitle,
            FileType::Imagem => FileRole::Image,
            FileType::Outro => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::UnsupportedFileType,
                    "File type 'outro' is not supported for resolution".to_string(),
                )));
            }
        };

        // Step 2: Parse anime title
        // CORRECTION: UnparsableTitle ‚Üí UnparsableFilename (canonical variant)
        let anime_parse_result = self.rules.parse_anime_title(&file.caminho_absoluto);
        let (anime_title, anime_source) = match anime_parse_result {
            Some((title, source)) => (title, source),
            None => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::UnparsableFilename,
                    "Could not extract anime title from filename or folder".to_string(),
                )));
            }
        };

        // Step 3: Parse episode number
        // CORRECTION: UnparsableEpisodeNumber ‚Üí NoEpisodeNumber (canonical variant)
        let episode_parse_result = self.rules.parse_episode_number(&file.caminho_absoluto);
        let (episode_number, episode_source) = match episode_parse_result {
            Some((num, source)) => (num, source),
            None => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::NoEpisodeNumber,
                    "Could not extract episode number from filename".to_string(),
                )));
            }
        };

        // Step 4: Try to match against existing anime (READ-ONLY)
        // CORRECTION: Errors are propagated, not swallowed
        let matched_anime_id = self.try_match_anime(&anime_title)?;

        // Step 5: Try to match against existing episode (if anime matched)
        // CORRECTION: Errors are propagated, not swallowed
        let matched_episode_id = match matched_anime_id {
            Some(anime_id) => self.try_match_episode(anime_id, &episode_number)?,
            None => None,
        };

        // Step 6: Calculate confidence
        let confidence = self.rules.calculate_confidence(
            &anime_title,
            &episode_number,
            matched_anime_id.is_some(),
            matched_episode_id.is_some(),
            &anime_source,
            &episode_source,
        );

        // Step 7: Check confidence threshold
        if !confidence.meets_threshold() {
            return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                file.id,
                file.caminho_absoluto.clone(),
                ResolutionFailureReason::LowConfidence,
                format!(
                    "Confidence score {} is below threshold {}",
                    confidence.score(),
                    ResolutionConfidence::THRESHOLD
                ),
            )));
        }

        // Step 8: Build resolved file
        let anime_intent = match matched_anime_id {
            Some(id) => ResolvedAnimeIntent::matched(id, anime_title, anime_source),
            None => ResolvedAnimeIntent::from_parsed_title(anime_title, anime_source),
        };

        let episode_intent = match matched_episode_id {
            Some(id) => ResolvedEpisodeIntent::matched(id, episode_number, episode_source),
            None => ResolvedEpisodeIntent::from_parsed_number(episode_number, episode_source),
        };

        Ok(ResolutionResult::Success(ResolvedFile::new(
            file.id,
            file.caminho_absoluto.clone(),
            role,
            anime_intent,
            episode_intent,
            confidence,
        )))
    }

    /// Attempt to match parsed title against existing anime entities.
    /// This is a READ-ONLY operation.
    ///
    /// CORRECTION: Returns AppResult, errors are not swallowed.
    fn try_match_anime(&self, title: &str) -> AppResult<Option<Uuid>> {
        let animes = self.anime_repo.list_all()?;
        let normalized_title = self.rules.normalize_title(title);

        for anime in animes {
            let normalized_anime_title = self.rules.normalize_title(&anime.titulo_principal);
            if normalized_anime_title == normalized_title {
                return Ok(Some(anime.id));
            }
        }

        Ok(None)
    }

    /// Attempt to match parsed episode number against existing episodes.
    /// This is a READ-ONLY operation.
    ///
    /// CORRECTION: Returns AppResult, errors are not swallowed.
    fn try_match_episode(
        &self,
        anime_id: Uuid,
        episode_number: &ResolvedEpisodeNumber,
    ) -> AppResult<Option<Uuid>> {
        let episodes = self.episode_repo.list_by_anime(anime_id)?;

        for episode in episodes {
            match (&episode.numero, episode_number) {
                (
                    crate::domain::episode::EpisodeNumber::Regular { numero },
                    ResolvedEpisodeNumber::Regular { number },
                ) => {
                    if numero == number {
                        return Ok(Some(episode.id));
                    }
                }
                (
                    crate::domain::episode::EpisodeNumber::Special { label: ep_label },
                    ResolvedEpisodeNumber::Special { label: res_label },
                ) => {
                    if ep_label.to_lowercase() == res_label.to_lowercase() {
                        return Ok(Some(episode.id));
                    }
                }
                _ => {}
            }
        }

        Ok(None)
    }

    // ========================================================================
    // IDEMPOTENCY ENFORCEMENT
    // ========================================================================

    fn is_already_resolved(&self, fingerprint: &ResolutionFingerprint) -> bool {
        let guard = self.resolved_fingerprints.read().unwrap();
        guard.contains(fingerprint.hash())
    }

    fn mark_resolved(&self, fingerprint: &ResolutionFingerprint) {
        let mut guard = self.resolved_fingerprints.write().unwrap();
        guard.insert(fingerprint.hash().to_string());
    }

    /// Compute fingerprint from a ResolutionResult.
    /// CORRECTION: This replaces the hallucinated ResolutionFingerprint::from_result
    fn compute_fingerprint_from_result(&self, result: &ResolutionResult) -> ResolutionFingerprint {
        match result {
            ResolutionResult::Success(resolved) => resolved.fingerprint(),
            ResolutionResult::Failure(failure) => failure.fingerprint(),
        }
    }

    // ========================================================================
    // EVENT EMISSION
    // ========================================================================

    fn emit_resolution_event(&self, result: &ResolutionResult) {
        match result {
            ResolutionResult::Success(resolved) => {
                self.event_bus.emit(FileResolved::new(
                    resolved.file_id,
                    resolved.file_path.clone(),
                    resolved.anime_intent.title.clone(),
                    resolved.anime_intent.matched_anime_id,
                    resolved.episode_intent.number.to_string(),
                    resolved.episode_intent.matched_episode_id,
                    resolved.role.to_string(),
                    resolved.confidence.score(),
                    resolved.anime_intent.source.to_string(),
                    resolved.fingerprint().to_string(),
                ));
            }
            ResolutionResult::Failure(failure) => {
                self.event_bus.emit(ResolutionFailed::new(
                    failure.file_id,
                    failure.file_path.clone(),
                    failure.reason.to_string(),
                    failure.description.clone(),
                ));
            }
        }
    }
}

// ============================================================================
// EPISODE AGGREGATION (FOR EpisodeResolved EMISSION)
// ============================================================================

/// Aggregates file resolutions into an episode resolution.
/// This makes EpisodeResolved reachable through real resolution flow.
struct EpisodeAggregation {
    anime_title: String,
    matched_anime_id: Option<Uuid>,
    episode_number: String,
    matched_episode_id: Option<Uuid>,
    video_file_id: Option<Uuid>,
    subtitle_file_ids: Vec<Uuid>,
    image_file_ids: Vec<Uuid>,
    max_confidence: f64,
}

impl EpisodeAggregation {
    fn new(
        anime_title: String,
        matched_anime_id: Option<Uuid>,
        episode_number: String,
        matched_episode_id: Option<Uuid>,
    ) -> Self {
        Self {
            anime_title,
            matched_anime_id,
            episode_number,
            matched_episode_id,
            video_file_id: None,
            subtitle_file_ids: Vec::new(),
            image_file_ids: Vec::new(),
            max_confidence: 0.0,
        }
    }

    fn add_file(&mut self, resolved: &ResolvedFile) {
        match resolved.role {
            FileRole::Video => {
                // First video becomes primary
                if self.video_file_id.is_none() {
                    self.video_file_id = Some(resolved.file_id);
                }
            }
            FileRole::Subtitle => {
                self.subtitle_file_ids.push(resolved.file_id);
            }
            FileRole::Image => {
                self.image_file_ids.push(resolved.file_id);
            }
        }

        if resolved.confidence.score() > self.max_confidence {
            self.max_confidence = resolved.confidence.score();
        }
    }

    fn into_event(self) -> EpisodeResolved {
        EpisodeResolved::new(
            self.anime_title,
            self.matched_anime_id,
            self.episode_number,
            self.matched_episode_id,
            self.video_file_id,
            self.subtitle_file_ids,
            self.image_file_ids,
            self.max_confidence,
        )
    }
}

// ============================================================================
// RESOLUTION OUTCOME (FOR SINGLE FILE API)
// ============================================================================

/// Outcome of resolving a single file.
#[derive(Debug)]
pub enum ResolutionOutcome {
    /// File was processed (success or failure)
    Processed(ResolutionResult),

    /// File was skipped due to idempotency
    Skipped { file_id: Uuid, fingerprint: String },
}

// ============================================================================
// RESOLUTION BATCH RESULT
// ============================================================================

/// Result of a batch resolution operation.
#[derive(Debug)]
pub struct ResolutionBatchResult {
    pub results: Vec<ResolutionResult>,
    pub total_files: usize,
    pub resolved_count: usize,
    pub failed_count: usize,
    pub skipped_count: usize,
    pub episodes_aggregated: usize,
    pub duration_ms: u64,
}

// ============================================================================
// RESOLUTION RULES
// ============================================================================

pub struct ResolutionRules {
    title_patterns: Vec<Regex>,
    episode_number_patterns: Vec<Regex>,
    special_episode_patterns: Vec<Regex>,
}

impl Default for ResolutionRules {
    fn default() -> Self {
        Self {
            title_patterns: vec![
                // [SubGroup] Title - 01 [quality].ext
                Regex::new(r"^\[.*?\]\s*(.+?)\s*-\s*\d+").unwrap(),
                // Title - 01.ext
                Regex::new(r"^(.+?)\s*-\s*\d+").unwrap(),
                // Title S01E01.ext
                Regex::new(r"^(.+?)\s*S\d+E\d+").unwrap(),
                // Title Episode 01.ext
                Regex::new(r"^(.+?)\s*Episode\s*\d+").unwrap(),
            ],
            episode_number_patterns: vec![
                // - 01, - 001
                Regex::new(r"-\s*(\d+)").unwrap(),
                // S01E01
                Regex::new(r"S\d+E(\d+)").unwrap(),
                // Episode 01
                Regex::new(r"Episode\s*(\d+)").unwrap(),
                // #01
                Regex::new(r"#(\d+)").unwrap(),
            ],
            special_episode_patterns: vec![
                // OVA, OVA 1, OVA1
                Regex::new(r"(OVA\s*\d*)").unwrap(),
                // OAD, OAD 1
                Regex::new(r"(OAD\s*\d*)").unwrap(),
                // Special, Special 1
                Regex::new(r"(Special\s*\d*)").unwrap(),
                // Movie, Movie 1
                Regex::new(r"(Movie\s*\d*)").unwrap(),
            ],
        }
    }
}

impl ResolutionRules {
    /// Parse anime title from file path
    pub fn parse_anime_title(&self, path: &PathBuf) -> Option<(String, ResolutionSource)> {
        // Try filename first
        if let Some(filename) = path.file_stem().and_then(|s| s.to_str()) {
            for pattern in &self.title_patterns {
                if let Some(captures) = pattern.captures(filename) {
                    if let Some(title) = captures.get(1) {
                        return Some((title.as_str().trim().to_string(), ResolutionSource::Filename));
                    }
                }
            }
        }

        // Fall back to folder name
        if let Some(parent) = path.parent() {
            if let Some(folder) = parent.file_name().and_then(|s| s.to_str()) {
                // Use folder name as title if it looks reasonable
                if folder.len() >= 3 && !folder.starts_with('.') {
                    return Some((folder.to_string(), ResolutionSource::FolderName));
                }
            }
        }

        None
    }

    /// Parse episode number from file path
    pub fn parse_episode_number(
        &self,
        path: &PathBuf,
    ) -> Option<(ResolvedEpisodeNumber, ResolutionSource)> {
        let filename = path.file_stem().and_then(|s| s.to_str())?;

        // Check for special episodes first
        for pattern in &self.special_episode_patterns {
            if let Some(captures) = pattern.captures(filename) {
                if let Some(label) = captures.get(1) {
                    return Some((
                        ResolvedEpisodeNumber::Special {
                            label: label.as_str().trim().to_string(),
                        },
                        ResolutionSource::Filename,
                    ));
                }
            }
        }

        // Try regular episode patterns
        for pattern in &self.episode_number_patterns {
            if let Some(captures) = pattern.captures(filename) {
                if let Some(num_str) = captures.get(1) {
                    if let Ok(number) = num_str.as_str().parse::<u32>() {
                        return Some((
                            ResolvedEpisodeNumber::Regular { number },
                            ResolutionSource::Filename,
                        ));
                    }
                }
            }
        }

        None
    }

    /// Calculate confidence score based on resolution quality
    pub fn calculate_confidence(
        &self,
        anime_title: &str,
        episode_number: &ResolvedEpisodeNumber,
        anime_matched: bool,
        episode_matched: bool,
        anime_source: &ResolutionSource,
        episode_source: &ResolutionSource,
    ) -> ResolutionConfidence {
        let mut score = 0.5; // Base score

        // Bonus for matching existing entities
        if anime_matched {
            score += 0.2;
        }
        if episode_matched {
            score += 0.15;
        }

        // Bonus for filename source (more reliable than folder)
        if matches!(anime_source, ResolutionSource::Filename) {
            score += 0.1;
        }
        if matches!(episode_source, ResolutionSource::Filename) {
            score += 0.05;
        }

        // Penalty for short titles (likely false positives)
        if anime_title.len() < 3 {
            score -= 0.3;
        }

        // Penalty for special episodes (harder to match)
        if matches!(episode_number, ResolvedEpisodeNumber::Special { .. }) {
            score -= 0.1;
        }

        ResolutionConfidence::new(score)
    }

    /// Normalize title for comparison
    pub fn normalize_title(&self, title: &str) -> String {
        title
            .to_lowercase()
            .replace(['_', '-', '.', ':', ';', '!', '?'], " ")
            .split_whitespace()
            .collect::<Vec<_>>()
            .join(" ")
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_anime_title_from_filename() {
        let rules = ResolutionRules::default();

        // [SubGroup] Anime Title - 01 [1080p].mkv
        let path = PathBuf::from("[SubGroup] Steins Gate - 01 [1080p].mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, source) = result.unwrap();
        assert_eq!(title, "Steins Gate");
        assert_eq!(source, ResolutionSource::Filename);

        // Anime Title - 01.mkv
        let path = PathBuf::from("Attack on Titan - 01.mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, _) = result.unwrap();
        assert_eq!(title, "Attack on Titan");
    }

    #[test]
    fn test_parse_episode_number() {
        let rules = ResolutionRules::default();

        // - 01
        let path = PathBuf::from("Anime - 01.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 1 });

        // S01E05
        let path = PathBuf::from("Anime S01E05.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 5 });

        // OVA
        let path = PathBuf::from("Anime OVA.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert!(matches!(num, ResolvedEpisodeNumber::Special { .. }));
    }

    #[test]
    fn test_confidence_calculation() {
        let rules = ResolutionRules::default();

        // High confidence: matched anime and episode, filename source
        let confidence = rules.calculate_confidence(
            "Steins;Gate",
            &ResolvedEpisodeNumber::Regular { number: 1 },
            true,
            true,
            &ResolutionSource::Filename,
            &ResolutionSource::Filename,
        );
        assert!(confidence.meets_threshold());
        assert!(confidence.score() > 0.8);

        // Low confidence: no matches, short title
        let confidence = rules.calculate_confidence(
            "AB",
            &ResolvedEpisodeNumber::Special {
                label: "?".to_string(),
            },
            false,
            false,
            &ResolutionSource::FolderName,
            &ResolutionSource::FolderName,
        );
        assert!(!confidence.meets_threshold());
    }

    #[test]
    fn test_normalize_title() {
        let rules = ResolutionRules::default();

        assert_eq!(rules.normalize_title("Steins;Gate"), "steins gate");
        assert_eq!(rules.normalize_title("Attack_on_Titan"), "attack on titan");
        assert_eq!(rules.normalize_title("Re:Zero"), "re zero");
    }

    #[test]
    fn test_fingerprint_determinism() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let result1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let result2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // Identical input produces identical fingerprint
        assert_eq!(result1.fingerprint(), result2.fingerprint());
    }
}
// src-tauri/src/services/resolution_service.rs
//
// Resolution Service - Phase 4 (CORRECTED)
//
// PURPOSE:
// - Parse file metadata to extract anime and episode information
// - Match against existing domain entities (READ-ONLY)
// - Emit resolution events for Phase 5 consumption
// - Aggregate file resolutions into episode resolutions
//
// CRITICAL INVARIANTS (ALL ENFORCED):
// - Resolution is PURE: no domain mutations, no persistence
// - Resolution is DETERMINISTIC: same input ‚Üí same output (no timestamps)
// - Resolution is IDEMPOTENT: repeated resolution of same file is skipped
// - Repository access is READ-ONLY
// - All errors are EXPLICIT: no silent fallbacks
// - All events are REACHABLE: no dead code paths
//
// PHASE 4 CORRECTIONS APPLIED:
// - Idempotency enforced via fingerprint tracking
// - EpisodeResolved emitted through aggregation logic
// - Silent error swallowing eliminated (.ok().flatten() removed)
// - Image files included in batch resolution
// - skipped_count is meaningful (tracks idempotent skips)
// - All dead enum variants removed from value objects
// - REMOVED: ResolutionFingerprint::from_result (hallucinated API)
// - REMOVED: FileRepository::list_by_type (hallucinated API)
// - FIXED: UnparsableTitle ‚Üí UnparsableFilename
// - FIXED: UnparsableEpisodeNumber ‚Üí NoEpisodeNumber

use crate::domain::file::{File, FileType};
use crate::domain::resolution::{
    FileRole, ResolutionConfidence, ResolutionFailure, ResolutionFailureReason,
    ResolutionResult, ResolutionSource, ResolvedAnimeIntent,
    ResolvedEpisodeIntent, ResolvedEpisodeNumber, ResolvedFile,
};
use crate::domain::resolution::value_objects::ResolutionFingerprint;
use crate::domain::anime::Anime;
use crate::domain::episode::Episode;
use crate::error::{AppError, AppResult};
use crate::events::resolution_events::{
    EpisodeResolved, FileResolved, ResolutionBatchCompleted, ResolutionFailed, ResolutionSkipped,
};
use crate::events::EventBus;
use crate::repositories::{AnimeRepository, EpisodeRepository, FileRepository};
use regex::Regex;
use std::collections::{HashMap, HashSet};
use std::path::PathBuf;
use std::sync::Arc;
use uuid::Uuid;

// ============================================================================
// RESOLUTION SERVICE
// ============================================================================

pub struct ResolutionService {
    file_repo: Arc<dyn FileRepository>,
    anime_repo: Arc<dyn AnimeRepository>,
    episode_repo: Arc<dyn EpisodeRepository>,
    event_bus: Arc<EventBus>,
    rules: ResolutionRules,
    /// Tracks fingerprints of already-resolved files for idempotency
    resolved_fingerprints: std::sync::RwLock<HashSet<String>>,
}

impl ResolutionService {
    pub fn new(
        file_repo: Arc<dyn FileRepository>,
        anime_repo: Arc<dyn AnimeRepository>,
        episode_repo: Arc<dyn EpisodeRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            file_repo,
            anime_repo,
            episode_repo,
            event_bus,
            rules: ResolutionRules::default(),
            resolved_fingerprints: std::sync::RwLock::new(HashSet::new()),
        }
    }

    /// Load existing fingerprints from a persistence source (called at startup)
    pub fn load_fingerprints(&self, fingerprints: Vec<String>) {
        let mut guard = self.resolved_fingerprints.write().unwrap();
        for fp in fingerprints {
            guard.insert(fp);
        }
    }

    // ========================================================================
    // PUBLIC API
    // ========================================================================

    /// Resolve a single file by ID.
    /// Returns the resolution result and emits appropriate events.
    ///
    /// IDEMPOTENCY: If file was already resolved (fingerprint exists), returns skipped.
    pub fn resolve_file(&self, file_id: Uuid) -> AppResult<ResolutionOutcome> {
        let file = self.file_repo.get_by_id(file_id)?;

        match file {
            Some(f) => {
                let result = self.resolve_file_internal(&f)?;

                // Compute fingerprint from the result
                let fingerprint = self.compute_fingerprint_from_result(&result);
                if self.is_already_resolved(&fingerprint) {
                    let outcome = ResolutionOutcome::Skipped {
                        file_id: f.id,
                        fingerprint: fingerprint.hash().to_string(),
                    };
                    self.event_bus.emit(ResolutionSkipped::new(
                        f.id,
                        f.caminho_absoluto.clone(),
                        fingerprint.hash().to_string(),
                        "already_resolved".to_string(),
                    ));
                    return Ok(outcome);
                }

                // Mark as resolved
                self.mark_resolved(&fingerprint);

                // Emit event
                self.emit_resolution_event(&result);

                Ok(ResolutionOutcome::Processed(result))
            }
            None => Err(AppError::NotFound),
        }
    }

    /// Resolve all pending files (Video, Subtitle, Image).
    /// Enforces idempotency and aggregates episode resolutions.
    ///
    /// CORRECTION: Uses list_unlinked() instead of hallucinated list_by_type()
    pub fn resolve_all_pending(&self) -> AppResult<ResolutionBatchResult> {
        let start_time = std::time::Instant::now();

        // Get all unlinked files and filter by type
        let all_files = self.file_repo.list_unlinked()?;
        let files: Vec<File> = all_files
            .into_iter()
            .filter(|f| matches!(f.tipo, FileType::Video | FileType::Legenda | FileType::Imagem))
            .collect();

        self.resolve_batch(files, start_time)
    }

    /// Resolve files in a specific directory.
    /// Enforces idempotency and aggregates episode resolutions.
    pub fn resolve_directory(&self, directory_path: &PathBuf) -> AppResult<ResolutionBatchResult> {
        let start_time = std::time::Instant::now();

        // Get all unlinked files and filter by directory and type
        let all_files = self.file_repo.list_unlinked()?;
        let files: Vec<File> = all_files
            .into_iter()
            .filter(|f| {
                matches!(f.tipo, FileType::Video | FileType::Legenda | FileType::Imagem)
                    && f.caminho_absoluto.starts_with(directory_path)
            })
            .collect();

        self.resolve_batch(files, start_time)
    }

    // ========================================================================
    // BATCH RESOLUTION (INTERNAL)
    // ========================================================================

    fn resolve_batch(
        &self,
        files: Vec<File>,
        start_time: std::time::Instant,
    ) -> AppResult<ResolutionBatchResult> {
        let total_files = files.len();
        let mut results: Vec<ResolutionResult> = Vec::with_capacity(total_files);
        let mut resolved_count = 0;
        let mut failed_count = 0;
        let mut skipped_count = 0;

        // Aggregation map: (anime_title_normalized, episode_number) -> files
        let mut episode_aggregation: HashMap<(String, String), EpisodeAggregation> = HashMap::new();

        for file in files {
            let result = self.resolve_file_internal(&file)?;

            // Compute fingerprint from the result
            let fingerprint = self.compute_fingerprint_from_result(&result);
            if self.is_already_resolved(&fingerprint) {
                skipped_count += 1;
                self.event_bus.emit(ResolutionSkipped::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    fingerprint.hash().to_string(),
                    "already_resolved".to_string(),
                ));
                continue;
            }

            // Mark as resolved
            self.mark_resolved(&fingerprint);

            // Emit file-level event
            self.emit_resolution_event(&result);

            match &result {
                ResolutionResult::Success(resolved) => {
                    resolved_count += 1;

                    // Aggregate for episode resolution
                    let key = (
                        resolved.anime_intent.title.to_lowercase(),
                        resolved.episode_intent.number.to_string(),
                    );
                    let aggregation = episode_aggregation.entry(key).or_insert_with(|| {
                        EpisodeAggregation::new(
                            resolved.anime_intent.title.clone(),
                            resolved.anime_intent.matched_anime_id,
                            resolved.episode_intent.number.to_string(),
                            resolved.episode_intent.matched_episode_id,
                        )
                    });
                    aggregation.add_file(resolved);
                }
                ResolutionResult::Failure(_) => {
                    failed_count += 1;
                }
            }

            results.push(result);
        }

        // Emit EpisodeResolved events for aggregated episodes
        let episodes_aggregated = episode_aggregation.len();
        for (_, aggregation) in episode_aggregation {
            let episode_event = aggregation.into_event();
            self.event_bus.emit(episode_event);
        }

        let duration_ms = start_time.elapsed().as_millis() as u64;

        // Emit batch completion event
        self.event_bus.emit(ResolutionBatchCompleted::new(
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
            duration_ms,
        ));

        Ok(ResolutionBatchResult {
            results,
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
            duration_ms,
        })
    }

    // ========================================================================
    // INTERNAL RESOLUTION LOGIC
    // ========================================================================

    /// Resolve a single file (internal, does not emit events).
    ///
    /// CORRECTION: Errors are propagated explicitly, not swallowed.
    fn resolve_file_internal(&self, file: &File) -> AppResult<ResolutionResult> {
        // Step 1: Determine file role
        let role = match file.tipo {
            FileType::Video => FileRole::Video,
            FileType::Legenda => FileRole::Subtitle,
            FileType::Imagem => FileRole::Image,
            FileType::Outro => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::UnsupportedFileType,
                    "File type 'outro' is not supported for resolution".to_string(),
                )));
            }
        };

        // Step 2: Parse anime title
        // CORRECTION: UnparsableTitle ‚Üí UnparsableFilename (canonical variant)
        let anime_parse_result = self.rules.parse_anime_title(&file.caminho_absoluto);
        let (anime_title, anime_source) = match anime_parse_result {
            Some((title, source)) => (title, source),
            None => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::UnparsableFilename,
                    "Could not extract anime title from filename or folder".to_string(),
                )));
            }
        };

        // Step 3: Parse episode number
        // CORRECTION: UnparsableEpisodeNumber ‚Üí NoEpisodeNumber (canonical variant)
        let episode_parse_result = self.rules.parse_episode_number(&file.caminho_absoluto);
        let (episode_number, episode_source) = match episode_parse_result {
            Some((num, source)) => (num, source),
            None => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::NoEpisodeNumber,
                    "Could not extract episode number from filename".to_string(),
                )));
            }
        };

        // Step 4: Try to match against existing anime (READ-ONLY)
        // CORRECTION: Errors are propagated, not swallowed
        let matched_anime_id = self.try_match_anime(&anime_title)?;

        // Step 5: Try to match against existing episode (if anime matched)
        // CORRECTION: Errors are propagated, not swallowed
        let matched_episode_id = match matched_anime_id {
            Some(anime_id) => self.try_match_episode(anime_id, &episode_number)?,
            None => None,
        };

        // Step 6: Calculate confidence
        let confidence = self.rules.calculate_confidence(
            &anime_title,
            &episode_number,
            matched_anime_id.is_some(),
            matched_episode_id.is_some(),
            &anime_source,
            &episode_source,
        );

        // Step 7: Check confidence threshold
        if !confidence.meets_threshold() {
            return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                file.id,
                file.caminho_absoluto.clone(),
                ResolutionFailureReason::LowConfidence,
                format!(
                    "Confidence score {} is below threshold {}",
                    confidence.score(),
                    ResolutionConfidence::THRESHOLD
                ),
            )));
        }

        // Step 8: Build resolved file
        let anime_intent = match matched_anime_id {
            Some(id) => ResolvedAnimeIntent::matched(id, anime_title, anime_source),
            None => ResolvedAnimeIntent::from_parsed_title(anime_title, anime_source),
        };

        let episode_intent = match matched_episode_id {
            Some(id) => ResolvedEpisodeIntent::matched(id, episode_number, episode_source),
            None => ResolvedEpisodeIntent::from_parsed_number(episode_number, episode_source),
        };

        Ok(ResolutionResult::Success(ResolvedFile::new(
            file.id,
            file.caminho_absoluto.clone(),
            role,
            anime_intent,
            episode_intent,
            confidence,
        )))
    }

    /// Attempt to match parsed title against existing anime entities.
    /// This is a READ-ONLY operation.
    ///
    /// CORRECTION: Returns AppResult, errors are not swallowed.
    fn try_match_anime(&self, title: &str) -> AppResult<Option<Uuid>> {
        let animes = self.anime_repo.list_all()?;
        let normalized_title = self.rules.normalize_title(title);

        for anime in animes {
            let normalized_anime_title = self.rules.normalize_title(&anime.titulo_principal);
            if normalized_anime_title == normalized_title {
                return Ok(Some(anime.id));
            }
        }

        Ok(None)
    }

    /// Attempt to match parsed episode number against existing episodes.
    /// This is a READ-ONLY operation.
    ///
    /// CORRECTION: Returns AppResult, errors are not swallowed.
    fn try_match_episode(
        &self,
        anime_id: Uuid,
        episode_number: &ResolvedEpisodeNumber,
    ) -> AppResult<Option<Uuid>> {
        let episodes = self.episode_repo.list_by_anime(anime_id)?;

        for episode in episodes {
            match (&episode.numero, episode_number) {
                (
                    crate::domain::episode::EpisodeNumber::Regular { numero },
                    ResolvedEpisodeNumber::Regular { number },
                ) => {
                    if numero == number {
                        return Ok(Some(episode.id));
                    }
                }
                (
                    crate::domain::episode::EpisodeNumber::Special { label: ep_label },
                    ResolvedEpisodeNumber::Special { label: res_label },
                ) => {
                    if ep_label.to_lowercase() == res_label.to_lowercase() {
                        return Ok(Some(episode.id));
                    }
                }
                _ => {}
            }
        }

        Ok(None)
    }

    // ========================================================================
    // IDEMPOTENCY ENFORCEMENT
    // ========================================================================

    fn is_already_resolved(&self, fingerprint: &ResolutionFingerprint) -> bool {
        let guard = self.resolved_fingerprints.read().unwrap();
        guard.contains(fingerprint.hash())
    }

    fn mark_resolved(&self, fingerprint: &ResolutionFingerprint) {
        let mut guard = self.resolved_fingerprints.write().unwrap();
        guard.insert(fingerprint.hash().to_string());
    }

    /// Compute fingerprint from a ResolutionResult.
    /// CORRECTION: This replaces the hallucinated ResolutionFingerprint::from_result
    fn compute_fingerprint_from_result(&self, result: &ResolutionResult) -> ResolutionFingerprint {
        match result {
            ResolutionResult::Success(resolved) => resolved.fingerprint(),
            ResolutionResult::Failure(failure) => failure.fingerprint(),
        }
    }

    // ========================================================================
    // EVENT EMISSION
    // ========================================================================

    fn emit_resolution_event(&self, result: &ResolutionResult) {
        match result {
            ResolutionResult::Success(resolved) => {
                self.event_bus.emit(FileResolved::new(
                    resolved.file_id,
                    resolved.file_path.clone(),
                    resolved.anime_intent.title.clone(),
                    resolved.anime_intent.matched_anime_id,
                    resolved.episode_intent.number.to_string(),
                    resolved.episode_intent.matched_episode_id,
                    resolved.role.to_string(),
                    resolved.confidence.score(),
                    resolved.anime_intent.source.to_string(),
                    resolved.fingerprint().to_string(),
                ));
            }
            ResolutionResult::Failure(failure) => {
                self.event_bus.emit(ResolutionFailed::new(
                    failure.file_id,
                    failure.file_path.clone(),
                    failure.reason.to_string(),
                    failure.description.clone(),
                ));
            }
        }
    }
}

// ============================================================================
// EPISODE AGGREGATION (FOR EpisodeResolved EMISSION)
// ============================================================================

/// Aggregates file resolutions into an episode resolution.
/// This makes EpisodeResolved reachable through real resolution flow.
struct EpisodeAggregation {
    anime_title: String,
    matched_anime_id: Option<Uuid>,
    episode_number: String,
    matched_episode_id: Option<Uuid>,
    video_file_id: Option<Uuid>,
    subtitle_file_ids: Vec<Uuid>,
    image_file_ids: Vec<Uuid>,
    max_confidence: f64,
}

impl EpisodeAggregation {
    fn new(
        anime_title: String,
        matched_anime_id: Option<Uuid>,
        episode_number: String,
        matched_episode_id: Option<Uuid>,
    ) -> Self {
        Self {
            anime_title,
            matched_anime_id,
            episode_number,
            matched_episode_id,
            video_file_id: None,
            subtitle_file_ids: Vec::new(),
            image_file_ids: Vec::new(),
            max_confidence: 0.0,
        }
    }

    fn add_file(&mut self, resolved: &ResolvedFile) {
        match resolved.role {
            FileRole::Video => {
                // First video becomes primary
                if self.video_file_id.is_none() {
                    self.video_file_id = Some(resolved.file_id);
                }
            }
            FileRole::Subtitle => {
                self.subtitle_file_ids.push(resolved.file_id);
            }
            FileRole::Image => {
                self.image_file_ids.push(resolved.file_id);
            }
        }

        if resolved.confidence.score() > self.max_confidence {
            self.max_confidence = resolved.confidence.score();
        }
    }

    fn into_event(self) -> EpisodeResolved {
        EpisodeResolved::new(
            self.anime_title,
            self.matched_anime_id,
            self.episode_number,
            self.matched_episode_id,
            self.video_file_id,
            self.subtitle_file_ids,
            self.image_file_ids,
            self.max_confidence,
        )
    }
}

// ============================================================================
// RESOLUTION OUTCOME (FOR SINGLE FILE API)
// ============================================================================

/// Outcome of resolving a single file.
#[derive(Debug)]
pub enum ResolutionOutcome {
    /// File was processed (success or failure)
    Processed(ResolutionResult),

    /// File was skipped due to idempotency
    Skipped { file_id: Uuid, fingerprint: String },
}

// ============================================================================
// RESOLUTION BATCH RESULT
// ============================================================================

/// Result of a batch resolution operation.
#[derive(Debug)]
pub struct ResolutionBatchResult {
    pub results: Vec<ResolutionResult>,
    pub total_files: usize,
    pub resolved_count: usize,
    pub failed_count: usize,
    pub skipped_count: usize,
    pub episodes_aggregated: usize,
    pub duration_ms: u64,
}

// ============================================================================
// RESOLUTION RULES
// ============================================================================

pub struct ResolutionRules {
    title_patterns: Vec<Regex>,
    episode_number_patterns: Vec<Regex>,
    special_episode_patterns: Vec<Regex>,
}

impl Default for ResolutionRules {
    fn default() -> Self {
        Self {
            title_patterns: vec![
                // [SubGroup] Title - 01 [quality].ext
                Regex::new(r"^\[.*?\]\s*(.+?)\s*-\s*\d+").unwrap(),
                // Title - 01.ext
                Regex::new(r"^(.+?)\s*-\s*\d+").unwrap(),
                // Title S01E01.ext
                Regex::new(r"^(.+?)\s*S\d+E\d+").unwrap(),
                // Title Episode 01.ext
                Regex::new(r"^(.+?)\s*Episode\s*\d+").unwrap(),
            ],
            episode_number_patterns: vec![
                // - 01, - 001
                Regex::new(r"-\s*(\d+)").unwrap(),
                // S01E01
                Regex::new(r"S\d+E(\d+)").unwrap(),
                // Episode 01
                Regex::new(r"Episode\s*(\d+)").unwrap(),
                // #01
                Regex::new(r"#(\d+)").unwrap(),
            ],
            special_episode_patterns: vec![
                // OVA, OVA 1, OVA1
                Regex::new(r"(OVA\s*\d*)").unwrap(),
                // OAD, OAD 1
                Regex::new(r"(OAD\s*\d*)").unwrap(),
                // Special, Special 1
                Regex::new(r"(Special\s*\d*)").unwrap(),
                // Movie, Movie 1
                Regex::new(r"(Movie\s*\d*)").unwrap(),
            ],
        }
    }
}

impl ResolutionRules {
    /// Parse anime title from file path
    pub fn parse_anime_title(&self, path: &PathBuf) -> Option<(String, ResolutionSource)> {
        // Try filename first
        if let Some(filename) = path.file_stem().and_then(|s| s.to_str()) {
            for pattern in &self.title_patterns {
                if let Some(captures) = pattern.captures(filename) {
                    if let Some(title) = captures.get(1) {
                        return Some((title.as_str().trim().to_string(), ResolutionSource::Filename));
                    }
                }
            }
        }

        // Fall back to folder name
        if let Some(parent) = path.parent() {
            if let Some(folder) = parent.file_name().and_then(|s| s.to_str()) {
                // Use folder name as title if it looks reasonable
                if folder.len() >= 3 && !folder.starts_with('.') {
                    return Some((folder.to_string(), ResolutionSource::FolderName));
                }
            }
        }

        None
    }

    /// Parse episode number from file path
    pub fn parse_episode_number(
        &self,
        path: &PathBuf,
    ) -> Option<(ResolvedEpisodeNumber, ResolutionSource)> {
        let filename = path.file_stem().and_then(|s| s.to_str())?;

        // Check for special episodes first
        for pattern in &self.special_episode_patterns {
            if let Some(captures) = pattern.captures(filename) {
                if let Some(label) = captures.get(1) {
                    return Some((
                        ResolvedEpisodeNumber::Special {
                            label: label.as_str().trim().to_string(),
                        },
                        ResolutionSource::Filename,
                    ));
                }
            }
        }

        // Try regular episode patterns
        for pattern in &self.episode_number_patterns {
            if let Some(captures) = pattern.captures(filename) {
                if let Some(num_str) = captures.get(1) {
                    if let Ok(number) = num_str.as_str().parse::<u32>() {
                        return Some((
                            ResolvedEpisodeNumber::Regular { number },
                            ResolutionSource::Filename,
                        ));
                    }
                }
            }
        }

        None
    }

    /// Calculate confidence score based on resolution quality
    pub fn calculate_confidence(
        &self,
        anime_title: &str,
        episode_number: &ResolvedEpisodeNumber,
        anime_matched: bool,
        episode_matched: bool,
        anime_source: &ResolutionSource,
        episode_source: &ResolutionSource,
    ) -> ResolutionConfidence {
        let mut score = 0.5; // Base score

        // Bonus for matching existing entities
        if anime_matched {
            score += 0.2;
        }
        if episode_matched {
            score += 0.15;
        }

        // Bonus for filename source (more reliable than folder)
        if matches!(anime_source, ResolutionSource::Filename) {
            score += 0.1;
        }
        if matches!(episode_source, ResolutionSource::Filename) {
            score += 0.05;
        }

        // Penalty for short titles (likely false positives)
        if anime_title.len() < 3 {
            score -= 0.3;
        }

        // Penalty for special episodes (harder to match)
        if matches!(episode_number, ResolvedEpisodeNumber::Special { .. }) {
            score -= 0.1;
        }

        ResolutionConfidence::new(score)
    }

    /// Normalize title for comparison
    pub fn normalize_title(&self, title: &str) -> String {
        title
            .to_lowercase()
            .replace(['_', '-', '.', ':', ';', '!', '?'], " ")
            .split_whitespace()
            .collect::<Vec<_>>()
            .join(" ")
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_anime_title_from_filename() {
        let rules = ResolutionRules::default();

        // [SubGroup] Anime Title - 01 [1080p].mkv
        let path = PathBuf::from("[SubGroup] Steins Gate - 01 [1080p].mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, source) = result.unwrap();
        assert_eq!(title, "Steins Gate");
        assert_eq!(source, ResolutionSource::Filename);

        // Anime Title - 01.mkv
        let path = PathBuf::from("Attack on Titan - 01.mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, _) = result.unwrap();
        assert_eq!(title, "Attack on Titan");
    }

    #[test]
    fn test_parse_episode_number() {
        let rules = ResolutionRules::default();

        // - 01
        let path = PathBuf::from("Anime - 01.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 1 });

        // S01E05
        let path = PathBuf::from("Anime S01E05.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 5 });

        // OVA
        let path = PathBuf::from("Anime OVA.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert!(matches!(num, ResolvedEpisodeNumber::Special { .. }));
    }

    #[test]
    fn test_confidence_calculation() {
        let rules = ResolutionRules::default();

        // High confidence: matched anime and episode, filename source
        let confidence = rules.calculate_confidence(
            "Steins;Gate",
            &ResolvedEpisodeNumber::Regular { number: 1 },
            true,
            true,
            &ResolutionSource::Filename,
            &ResolutionSource::Filename,
        );
        assert!(confidence.meets_threshold());
        assert!(confidence.score() > 0.8);

        // Low confidence: no matches, short title
        let confidence = rules.calculate_confidence(
            "AB",
            &ResolvedEpisodeNumber::Special {
                label: "?".to_string(),
            },
            false,
            false,
            &ResolutionSource::FolderName,
            &ResolutionSource::FolderName,
        );
        assert!(!confidence.meets_threshold());
    }

    #[test]
    fn test_normalize_title() {
        let rules = ResolutionRules::default();

        assert_eq!(rules.normalize_title("Steins;Gate"), "steins gate");
        assert_eq!(rules.normalize_title("Attack_on_Titan"), "attack on titan");
        assert_eq!(rules.normalize_title("Re:Zero"), "re zero");
    }

    #[test]
    fn test_fingerprint_determinism() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let result1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let result2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // Identical input produces identical fingerprint
        assert_eq!(result1.fingerprint(), result2.fingerprint());
    }
}
// src-tauri/src/services/resolution_service.rs
//
// Resolution Service - Phase 4 (CORRECTED)
//
// PURPOSE:
// - Parse file metadata to extract anime and episode information
// - Match against existing domain entities (READ-ONLY)
// - Emit resolution events for Phase 5 consumption
// - Aggregate file resolutions into episode resolutions
//
// CRITICAL INVARIANTS (ALL ENFORCED):
// - Resolution is PURE: no domain mutations, no persistence
// - Resolution is DETERMINISTIC: same input ‚Üí same output (no timestamps)
// - Resolution is IDEMPOTENT: repeated resolution of same file is skipped
// - Repository access is READ-ONLY
// - All errors are EXPLICIT: no silent fallbacks
// - All events are REACHABLE: no dead code paths
//
// PHASE 4 CORRECTIONS APPLIED:
// - Idempotency enforced via fingerprint tracking
// - EpisodeResolved emitted through aggregation logic
// - Silent error swallowing eliminated (.ok().flatten() removed)
// - Image files included in batch resolution
// - skipped_count is meaningful (tracks idempotent skips)
// - All dead enum variants removed from value objects
// - REMOVED: ResolutionFingerprint::from_result (hallucinated API)
// - REMOVED: FileRepository::list_by_type (hallucinated API)
// - FIXED: UnparsableTitle ‚Üí UnparsableFilename
// - FIXED: UnparsableEpisodeNumber ‚Üí NoEpisodeNumber

use crate::domain::file::{File, FileType};
use crate::domain::resolution::{
    FileRole, ResolutionConfidence, ResolutionFailure, ResolutionFailureReason,
    ResolutionResult, ResolutionSource, ResolvedAnimeIntent,
    ResolvedEpisodeIntent, ResolvedEpisodeNumber, ResolvedFile,
};
use crate::domain::resolution::value_objects::ResolutionFingerprint;
use crate::domain::anime::Anime;
use crate::domain::episode::Episode;
use crate::error::{AppError, AppResult};
use crate::events::resolution_events::{
    EpisodeResolved, FileResolved, ResolutionBatchCompleted, ResolutionFailed, ResolutionSkipped,
};
use crate::events::EventBus;
use crate::repositories::{AnimeRepository, EpisodeRepository, FileRepository};
use regex::Regex;
use std::collections::{HashMap, HashSet};
use std::path::PathBuf;
use std::sync::Arc;
use uuid::Uuid;

// ============================================================================
// RESOLUTION SERVICE
// ============================================================================

pub struct ResolutionService {
    file_repo: Arc<dyn FileRepository>,
    anime_repo: Arc<dyn AnimeRepository>,
    episode_repo: Arc<dyn EpisodeRepository>,
    event_bus: Arc<EventBus>,
    rules: ResolutionRules,
    /// Tracks fingerprints of already-resolved files for idempotency
    resolved_fingerprints: std::sync::RwLock<HashSet<String>>,
}

impl ResolutionService {
    pub fn new(
        file_repo: Arc<dyn FileRepository>,
        anime_repo: Arc<dyn AnimeRepository>,
        episode_repo: Arc<dyn EpisodeRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            file_repo,
            anime_repo,
            episode_repo,
            event_bus,
            rules: ResolutionRules::default(),
            resolved_fingerprints: std::sync::RwLock::new(HashSet::new()),
        }
    }

    /// Load existing fingerprints from a persistence source (called at startup)
    pub fn load_fingerprints(&self, fingerprints: Vec<String>) {
        let mut guard = self.resolved_fingerprints.write().unwrap();
        for fp in fingerprints {
            guard.insert(fp);
        }
    }

    // ========================================================================
    // PUBLIC API
    // ========================================================================

    /// Resolve a single file by ID.
    /// Returns the resolution result and emits appropriate events.
    ///
    /// IDEMPOTENCY: If file was already resolved (fingerprint exists), returns skipped.
    pub fn resolve_file(&self, file_id: Uuid) -> AppResult<ResolutionOutcome> {
        let file = self.file_repo.get_by_id(file_id)?;

        match file {
            Some(f) => {
                let result = self.resolve_file_internal(&f)?;

                // Compute fingerprint from the result
                let fingerprint = self.compute_fingerprint_from_result(&result);
                if self.is_already_resolved(&fingerprint) {
                    let outcome = ResolutionOutcome::Skipped {
                        file_id: f.id,
                        fingerprint: fingerprint.hash().to_string(),
                    };
                    self.event_bus.emit(ResolutionSkipped::new(
                        f.id,
                        f.caminho_absoluto.clone(),
                        fingerprint.hash().to_string(),
                        "already_resolved".to_string(),
                    ));
                    return Ok(outcome);
                }

                // Mark as resolved
                self.mark_resolved(&fingerprint);

                // Emit event
                self.emit_resolution_event(&result);

                Ok(ResolutionOutcome::Processed(result))
            }
            None => Err(AppError::NotFound),
        }
    }

    /// Resolve all pending files (Video, Subtitle, Image).
    /// Enforces idempotency and aggregates episode resolutions.
    ///
    /// CORRECTION: Uses list_unlinked() instead of hallucinated list_by_type()
    pub fn resolve_all_pending(&self) -> AppResult<ResolutionBatchResult> {
        let start_time = std::time::Instant::now();

        // Get all unlinked files and filter by type
        let all_files = self.file_repo.list_unlinked()?;
        let files: Vec<File> = all_files
            .into_iter()
            .filter(|f| matches!(f.tipo, FileType::Video | FileType::Legenda | FileType::Imagem))
            .collect();

        self.resolve_batch(files, start_time)
    }

    /// Resolve files in a specific directory.
    /// Enforces idempotency and aggregates episode resolutions.
    pub fn resolve_directory(&self, directory_path: &PathBuf) -> AppResult<ResolutionBatchResult> {
        let start_time = std::time::Instant::now();

        // Get all unlinked files and filter by directory and type
        let all_files = self.file_repo.list_unlinked()?;
        let files: Vec<File> = all_files
            .into_iter()
            .filter(|f| {
                matches!(f.tipo, FileType::Video | FileType::Legenda | FileType::Imagem)
                    && f.caminho_absoluto.starts_with(directory_path)
            })
            .collect();

        self.resolve_batch(files, start_time)
    }

    // ========================================================================
    // BATCH RESOLUTION (INTERNAL)
    // ========================================================================

    fn resolve_batch(
        &self,
        files: Vec<File>,
        start_time: std::time::Instant,
    ) -> AppResult<ResolutionBatchResult> {
        let total_files = files.len();
        let mut results: Vec<ResolutionResult> = Vec::with_capacity(total_files);
        let mut resolved_count = 0;
        let mut failed_count = 0;
        let mut skipped_count = 0;

        // Aggregation map: (anime_title_normalized, episode_number) -> files
        let mut episode_aggregation: HashMap<(String, String), EpisodeAggregation> = HashMap::new();

        for file in files {
            let result = self.resolve_file_internal(&file)?;

            // Compute fingerprint from the result
            let fingerprint = self.compute_fingerprint_from_result(&result);
            if self.is_already_resolved(&fingerprint) {
                skipped_count += 1;
                self.event_bus.emit(ResolutionSkipped::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    fingerprint.hash().to_string(),
                    "already_resolved".to_string(),
                ));
                continue;
            }

            // Mark as resolved
            self.mark_resolved(&fingerprint);

            // Emit file-level event
            self.emit_resolution_event(&result);

            match &result {
                ResolutionResult::Success(resolved) => {
                    resolved_count += 1;

                    // Aggregate for episode resolution
                    let key = (
                        resolved.anime_intent.title.to_lowercase(),
                        resolved.episode_intent.number.to_string(),
                    );
                    let aggregation = episode_aggregation.entry(key).or_insert_with(|| {
                        EpisodeAggregation::new(
                            resolved.anime_intent.title.clone(),
                            resolved.anime_intent.matched_anime_id,
                            resolved.episode_intent.number.to_string(),
                            resolved.episode_intent.matched_episode_id,
                        )
                    });
                    aggregation.add_file(resolved);
                }
                ResolutionResult::Failure(_) => {
                    failed_count += 1;
                }
            }

            results.push(result);
        }

        // Emit EpisodeResolved events for aggregated episodes
        let episodes_aggregated = episode_aggregation.len();
        for (_, aggregation) in episode_aggregation {
            let episode_event = aggregation.into_event();
            self.event_bus.emit(episode_event);
        }

        let duration_ms = start_time.elapsed().as_millis() as u64;

        // Emit batch completion event
        self.event_bus.emit(ResolutionBatchCompleted::new(
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
            duration_ms,
        ));

        Ok(ResolutionBatchResult {
            results,
            total_files,
            resolved_count,
            failed_count,
            skipped_count,
            episodes_aggregated,
            duration_ms,
        })
    }

    // ========================================================================
    // INTERNAL RESOLUTION LOGIC
    // ========================================================================

    /// Resolve a single file (internal, does not emit events).
    ///
    /// CORRECTION: Errors are propagated explicitly, not swallowed.
    fn resolve_file_internal(&self, file: &File) -> AppResult<ResolutionResult> {
        // Step 1: Determine file role
        let role = match file.tipo {
            FileType::Video => FileRole::Video,
            FileType::Legenda => FileRole::Subtitle,
            FileType::Imagem => FileRole::Image,
            FileType::Outro => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::UnsupportedFileType,
                    "File type 'outro' is not supported for resolution".to_string(),
                )));
            }
        };

        // Step 2: Parse anime title
        // CORRECTION: UnparsableTitle ‚Üí UnparsableFilename (canonical variant)
        let anime_parse_result = self.rules.parse_anime_title(&file.caminho_absoluto);
        let (anime_title, anime_source) = match anime_parse_result {
            Some((title, source)) => (title, source),
            None => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::UnparsableFilename,
                    "Could not extract anime title from filename or folder".to_string(),
                )));
            }
        };

        // Step 3: Parse episode number
        // CORRECTION: UnparsableEpisodeNumber ‚Üí NoEpisodeNumber (canonical variant)
        let episode_parse_result = self.rules.parse_episode_number(&file.caminho_absoluto);
        let (episode_number, episode_source) = match episode_parse_result {
            Some((num, source)) => (num, source),
            None => {
                return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                    file.id,
                    file.caminho_absoluto.clone(),
                    ResolutionFailureReason::NoEpisodeNumber,
                    "Could not extract episode number from filename".to_string(),
                )));
            }
        };

        // Step 4: Try to match against existing anime (READ-ONLY)
        // CORRECTION: Errors are propagated, not swallowed
        let matched_anime_id = self.try_match_anime(&anime_title)?;

        // Step 5: Try to match against existing episode (if anime matched)
        // CORRECTION: Errors are propagated, not swallowed
        let matched_episode_id = match matched_anime_id {
            Some(anime_id) => self.try_match_episode(anime_id, &episode_number)?,
            None => None,
        };

        // Step 6: Calculate confidence
        let confidence = self.rules.calculate_confidence(
            &anime_title,
            &episode_number,
            matched_anime_id.is_some(),
            matched_episode_id.is_some(),
            &anime_source,
            &episode_source,
        );

        // Step 7: Check confidence threshold
        if !confidence.meets_threshold() {
            return Ok(ResolutionResult::Failure(ResolutionFailure::new(
                file.id,
                file.caminho_absoluto.clone(),
                ResolutionFailureReason::LowConfidence,
                format!(
                    "Confidence score {} is below threshold {}",
                    confidence.score(),
                    ResolutionConfidence::THRESHOLD
                ),
            )));
        }

        // Step 8: Build resolved file
        let anime_intent = match matched_anime_id {
            Some(id) => ResolvedAnimeIntent::matched(id, anime_title, anime_source),
            None => ResolvedAnimeIntent::from_parsed_title(anime_title, anime_source),
        };

        let episode_intent = match matched_episode_id {
            Some(id) => ResolvedEpisodeIntent::matched(id, episode_number, episode_source),
            None => ResolvedEpisodeIntent::from_parsed_number(episode_number, episode_source),
        };

        Ok(ResolutionResult::Success(ResolvedFile::new(
            file.id,
            file.caminho_absoluto.clone(),
            role,
            anime_intent,
            episode_intent,
            confidence,
        )))
    }

    /// Attempt to match parsed title against existing anime entities.
    /// This is a READ-ONLY operation.
    ///
    /// CORRECTION: Returns AppResult, errors are not swallowed.
    fn try_match_anime(&self, title: &str) -> AppResult<Option<Uuid>> {
        let animes = self.anime_repo.list_all()?;
        let normalized_title = self.rules.normalize_title(title);

        for anime in animes {
            let normalized_anime_title = self.rules.normalize_title(&anime.titulo_principal);
            if normalized_anime_title == normalized_title {
                return Ok(Some(anime.id));
            }
        }

        Ok(None)
    }

    /// Attempt to match parsed episode number against existing episodes.
    /// This is a READ-ONLY operation.
    ///
    /// CORRECTION: Returns AppResult, errors are not swallowed.
    fn try_match_episode(
        &self,
        anime_id: Uuid,
        episode_number: &ResolvedEpisodeNumber,
    ) -> AppResult<Option<Uuid>> {
        let episodes = self.episode_repo.list_by_anime(anime_id)?;

        for episode in episodes {
            match (&episode.numero, episode_number) {
                (
                    crate::domain::episode::EpisodeNumber::Regular { numero },
                    ResolvedEpisodeNumber::Regular { number },
                ) => {
                    if numero == number {
                        return Ok(Some(episode.id));
                    }
                }
                (
                    crate::domain::episode::EpisodeNumber::Special { label: ep_label },
                    ResolvedEpisodeNumber::Special { label: res_label },
                ) => {
                    if ep_label.to_lowercase() == res_label.to_lowercase() {
                        return Ok(Some(episode.id));
                    }
                }
                _ => {}
            }
        }

        Ok(None)
    }

    // ========================================================================
    // IDEMPOTENCY ENFORCEMENT
    // ========================================================================

    fn is_already_resolved(&self, fingerprint: &ResolutionFingerprint) -> bool {
        let guard = self.resolved_fingerprints.read().unwrap();
        guard.contains(fingerprint.hash())
    }

    fn mark_resolved(&self, fingerprint: &ResolutionFingerprint) {
        let mut guard = self.resolved_fingerprints.write().unwrap();
        guard.insert(fingerprint.hash().to_string());
    }

    /// Compute fingerprint from a ResolutionResult.
    /// CORRECTION: This replaces the hallucinated ResolutionFingerprint::from_result
    fn compute_fingerprint_from_result(&self, result: &ResolutionResult) -> ResolutionFingerprint {
        match result {
            ResolutionResult::Success(resolved) => resolved.fingerprint(),
            ResolutionResult::Failure(failure) => failure.fingerprint(),
        }
    }

    // ========================================================================
    // EVENT EMISSION
    // ========================================================================

    fn emit_resolution_event(&self, result: &ResolutionResult) {
        match result {
            ResolutionResult::Success(resolved) => {
                self.event_bus.emit(FileResolved::new(
                    resolved.file_id,
                    resolved.file_path.clone(),
                    resolved.anime_intent.title.clone(),
                    resolved.anime_intent.matched_anime_id,
                    resolved.episode_intent.number.to_string(),
                    resolved.episode_intent.matched_episode_id,
                    resolved.role.to_string(),
                    resolved.confidence.score(),
                    resolved.anime_intent.source.to_string(),
                    resolved.fingerprint().to_string(),
                ));
            }
            ResolutionResult::Failure(failure) => {
                self.event_bus.emit(ResolutionFailed::new(
                    failure.file_id,
                    failure.file_path.clone(),
                    failure.reason.to_string(),
                    failure.description.clone(),
                ));
            }
        }
    }
}

// ============================================================================
// EPISODE AGGREGATION (FOR EpisodeResolved EMISSION)
// ============================================================================

/// Aggregates file resolutions into an episode resolution.
/// This makes EpisodeResolved reachable through real resolution flow.
struct EpisodeAggregation {
    anime_title: String,
    matched_anime_id: Option<Uuid>,
    episode_number: String,
    matched_episode_id: Option<Uuid>,
    video_file_id: Option<Uuid>,
    subtitle_file_ids: Vec<Uuid>,
    image_file_ids: Vec<Uuid>,
    max_confidence: f64,
}

impl EpisodeAggregation {
    fn new(
        anime_title: String,
        matched_anime_id: Option<Uuid>,
        episode_number: String,
        matched_episode_id: Option<Uuid>,
    ) -> Self {
        Self {
            anime_title,
            matched_anime_id,
            episode_number,
            matched_episode_id,
            video_file_id: None,
            subtitle_file_ids: Vec::new(),
            image_file_ids: Vec::new(),
            max_confidence: 0.0,
        }
    }

    fn add_file(&mut self, resolved: &ResolvedFile) {
        match resolved.role {
            FileRole::Video => {
                // First video becomes primary
                if self.video_file_id.is_none() {
                    self.video_file_id = Some(resolved.file_id);
                }
            }
            FileRole::Subtitle => {
                self.subtitle_file_ids.push(resolved.file_id);
            }
            FileRole::Image => {
                self.image_file_ids.push(resolved.file_id);
            }
        }

        if resolved.confidence.score() > self.max_confidence {
            self.max_confidence = resolved.confidence.score();
        }
    }

    fn into_event(self) -> EpisodeResolved {
        EpisodeResolved::new(
            self.anime_title,
            self.matched_anime_id,
            self.episode_number,
            self.matched_episode_id,
            self.video_file_id,
            self.subtitle_file_ids,
            self.image_file_ids,
            self.max_confidence,
        )
    }
}

// ============================================================================
// RESOLUTION OUTCOME (FOR SINGLE FILE API)
// ============================================================================

/// Outcome of resolving a single file.
#[derive(Debug)]
pub enum ResolutionOutcome {
    /// File was processed (success or failure)
    Processed(ResolutionResult),

    /// File was skipped due to idempotency
    Skipped { file_id: Uuid, fingerprint: String },
}

// ============================================================================
// RESOLUTION BATCH RESULT
// ============================================================================

/// Result of a batch resolution operation.
#[derive(Debug)]
pub struct ResolutionBatchResult {
    pub results: Vec<ResolutionResult>,
    pub total_files: usize,
    pub resolved_count: usize,
    pub failed_count: usize,
    pub skipped_count: usize,
    pub episodes_aggregated: usize,
    pub duration_ms: u64,
}

// ============================================================================
// RESOLUTION RULES
// ============================================================================

pub struct ResolutionRules {
    title_patterns: Vec<Regex>,
    episode_number_patterns: Vec<Regex>,
    special_episode_patterns: Vec<Regex>,
}

impl Default for ResolutionRules {
    fn default() -> Self {
        Self {
            title_patterns: vec![
                // [SubGroup] Title - 01 [quality].ext
                Regex::new(r"^\[.*?\]\s*(.+?)\s*-\s*\d+").unwrap(),
                // Title - 01.ext
                Regex::new(r"^(.+?)\s*-\s*\d+").unwrap(),
                // Title S01E01.ext
                Regex::new(r"^(.+?)\s*S\d+E\d+").unwrap(),
                // Title Episode 01.ext
                Regex::new(r"^(.+?)\s*Episode\s*\d+").unwrap(),
            ],
            episode_number_patterns: vec![
                // - 01, - 001
                Regex::new(r"-\s*(\d+)").unwrap(),
                // S01E01
                Regex::new(r"S\d+E(\d+)").unwrap(),
                // Episode 01
                Regex::new(r"Episode\s*(\d+)").unwrap(),
                // #01
                Regex::new(r"#(\d+)").unwrap(),
            ],
            special_episode_patterns: vec![
                // OVA, OVA 1, OVA1
                Regex::new(r"(OVA\s*\d*)").unwrap(),
                // OAD, OAD 1
                Regex::new(r"(OAD\s*\d*)").unwrap(),
                // Special, Special 1
                Regex::new(r"(Special\s*\d*)").unwrap(),
                // Movie, Movie 1
                Regex::new(r"(Movie\s*\d*)").unwrap(),
            ],
        }
    }
}

impl ResolutionRules {
    /// Parse anime title from file path
    pub fn parse_anime_title(&self, path: &PathBuf) -> Option<(String, ResolutionSource)> {
        // Try filename first
        if let Some(filename) = path.file_stem().and_then(|s| s.to_str()) {
            for pattern in &self.title_patterns {
                if let Some(captures) = pattern.captures(filename) {
                    if let Some(title) = captures.get(1) {
                        return Some((title.as_str().trim().to_string(), ResolutionSource::Filename));
                    }
                }
            }
        }

        // Fall back to folder name
        if let Some(parent) = path.parent() {
            if let Some(folder) = parent.file_name().and_then(|s| s.to_str()) {
                // Use folder name as title if it looks reasonable
                if folder.len() >= 3 && !folder.starts_with('.') {
                    return Some((folder.to_string(), ResolutionSource::FolderName));
                }
            }
        }

        None
    }

    /// Parse episode number from file path
    pub fn parse_episode_number(
        &self,
        path: &PathBuf,
    ) -> Option<(ResolvedEpisodeNumber, ResolutionSource)> {
        let filename = path.file_stem().and_then(|s| s.to_str())?;

        // Check for special episodes first
        for pattern in &self.special_episode_patterns {
            if let Some(captures) = pattern.captures(filename) {
                if let Some(label) = captures.get(1) {
                    return Some((
                        ResolvedEpisodeNumber::Special {
                            label: label.as_str().trim().to_string(),
                        },
                        ResolutionSource::Filename,
                    ));
                }
            }
        }

        // Try regular episode patterns
        for pattern in &self.episode_number_patterns {
            if let Some(captures) = pattern.captures(filename) {
                if let Some(num_str) = captures.get(1) {
                    if let Ok(number) = num_str.as_str().parse::<u32>() {
                        return Some((
                            ResolvedEpisodeNumber::Regular { number },
                            ResolutionSource::Filename,
                        ));
                    }
                }
            }
        }

        None
    }

    /// Calculate confidence score based on resolution quality
    pub fn calculate_confidence(
        &self,
        anime_title: &str,
        episode_number: &ResolvedEpisodeNumber,
        anime_matched: bool,
        episode_matched: bool,
        anime_source: &ResolutionSource,
        episode_source: &ResolutionSource,
    ) -> ResolutionConfidence {
        let mut score = 0.5; // Base score

        // Bonus for matching existing entities
        if anime_matched {
            score += 0.2;
        }
        if episode_matched {
            score += 0.15;
        }

        // Bonus for filename source (more reliable than folder)
        if matches!(anime_source, ResolutionSource::Filename) {
            score += 0.1;
        }
        if matches!(episode_source, ResolutionSource::Filename) {
            score += 0.05;
        }

        // Penalty for short titles (likely false positives)
        if anime_title.len() < 3 {
            score -= 0.3;
        }

        // Penalty for special episodes (harder to match)
        if matches!(episode_number, ResolvedEpisodeNumber::Special { .. }) {
            score -= 0.1;
        }

        ResolutionConfidence::new(score)
    }

    /// Normalize title for comparison
    pub fn normalize_title(&self, title: &str) -> String {
        title
            .to_lowercase()
            .replace(['_', '-', '.', ':', ';', '!', '?'], " ")
            .split_whitespace()
            .collect::<Vec<_>>()
            .join(" ")
    }
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_anime_title_from_filename() {
        let rules = ResolutionRules::default();

        // [SubGroup] Anime Title - 01 [1080p].mkv
        let path = PathBuf::from("[SubGroup] Steins Gate - 01 [1080p].mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, source) = result.unwrap();
        assert_eq!(title, "Steins Gate");
        assert_eq!(source, ResolutionSource::Filename);

        // Anime Title - 01.mkv
        let path = PathBuf::from("Attack on Titan - 01.mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, _) = result.unwrap();
        assert_eq!(title, "Attack on Titan");
    }

    #[test]
    fn test_parse_episode_number() {
        let rules = ResolutionRules::default();

        // - 01
        let path = PathBuf::from("Anime - 01.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 1 });

        // S01E05
        let path = PathBuf::from("Anime S01E05.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 5 });

        // OVA
        let path = PathBuf::from("Anime OVA.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert!(matches!(num, ResolvedEpisodeNumber::Special { .. }));
    }

    #[test]
    fn test_confidence_calculation() {
        let rules = ResolutionRules::default();

        // High confidence: matched anime and episode, filename source
        let confidence = rules.calculate_confidence(
            "Steins;Gate",
            &ResolvedEpisodeNumber::Regular { number: 1 },
            true,
            true,
            &ResolutionSource::Filename,
            &ResolutionSource::Filename,
        );
        assert!(confidence.meets_threshold());
        assert!(confidence.score() > 0.8);

        // Low confidence: no matches, short title
        let confidence = rules.calculate_confidence(
            "AB",
            &ResolvedEpisodeNumber::Special {
                label: "?".to_string(),
            },
            false,
            false,
            &ResolutionSource::FolderName,
            &ResolutionSource::FolderName,
        );
        assert!(!confidence.meets_threshold());
    }

    #[test]
    fn test_normalize_title() {
        let rules = ResolutionRules::default();

        assert_eq!(rules.normalize_title("Steins;Gate"), "steins gate");
        assert_eq!(rules.normalize_title("Attack_on_Titan"), "attack on titan");
        assert_eq!(rules.normalize_title("Re:Zero"), "re zero");
    }

    #[test]
    fn test_fingerprint_determinism() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let result1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let result2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // Identical input produces identical fingerprint
        assert_eq!(result1.fingerprint(), result2.fingerprint());
    }
}


--- FILE: src-tauri\src\services\resolution_service_hardening_tests.rs ---
// src-tauri/src/services/resolution_service_hardening_tests.rs
//
// Phase 4 Hardening Tests - CORRECTED
//
// CORRECTIONS APPLIED:
// - REMOVED: All tests using Mock repositories (hallucinated - do not exist)
// - KEPT: Only tests that validate domain logic without repository dependencies
// - Tests now use real domain objects and event constructors

#[cfg(test)]
mod determinism_tests {
    use crate::events::resolution_events::{FileResolved, EpisodeResolved};
    use crate::events::DomainEvent;
    use std::path::PathBuf;
    use uuid::Uuid;

    /// PROVES: Identical input produces byte-for-byte identical events
    #[test]
    fn test_identical_input_produces_identical_events() {
        // Use fixed UUIDs for determinism
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let event1 = FileResolved::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            "video".to_string(),
            0.95,
            "filename".to_string(),
            "fp:1234567890abcdef".to_string(),
        );

        let event2 = FileResolved::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            "video".to_string(),
            0.95,
            "filename".to_string(),
            "fp:1234567890abcdef".to_string(),
        );

        // PROOF: Events are byte-for-byte identical
        assert_eq!(event1, event2, "Identical input MUST produce identical event");

        // Serialize and compare
        let json1 = serde_json::to_string(&event1).unwrap();
        let json2 = serde_json::to_string(&event2).unwrap();
        assert_eq!(json1, json2, "Serialized events MUST be byte-for-byte identical");
    }

    /// PROVES: Event IDs are deterministic (derived from fingerprint)
    #[test]
    fn test_event_ids_are_deterministic() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();
        let fingerprint = "fp:deterministic_hash_value";

        let event1 = FileResolved::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            "video".to_string(),
            0.95,
            "filename".to_string(),
            fingerprint.to_string(),
        );

        let event2 = FileResolved::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            "video".to_string(),
            0.95,
            "filename".to_string(),
            fingerprint.to_string(),
        );

        // PROOF: event_id is deterministic
        assert_eq!(
            event1.event_id(),
            event2.event_id(),
            "Event IDs MUST be deterministic"
        );
    }

    /// PROVES: Different fingerprints produce different event IDs
    #[test]
    fn test_different_fingerprints_produce_different_event_ids() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let event1 = FileResolved::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            "video".to_string(),
            0.95,
            "filename".to_string(),
            "fp:fingerprint_one".to_string(),
        );

        let event2 = FileResolved::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            "video".to_string(),
            0.95,
            "filename".to_string(),
            "fp:fingerprint_two".to_string(),
        );

        // PROOF: Different fingerprints produce different event IDs
        assert_ne!(
            event1.event_id(),
            event2.event_id(),
            "Different fingerprints MUST produce different event IDs"
        );
    }
}

#[cfg(test)]
mod episode_resolved_tests {
    use crate::events::resolution_events::EpisodeResolved;
    use crate::events::DomainEvent;
    use uuid::Uuid;

    /// PROVES: EpisodeResolved aggregates multiple files correctly
    #[test]
    fn test_episode_resolved_aggregates_files() {
        let video_id = Uuid::new_v4();
        let sub1_id = Uuid::new_v4();
        let sub2_id = Uuid::new_v4();
        let image_id = Uuid::new_v4();

        let event = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![sub1_id, sub2_id],
            vec![image_id],
            0.95,
        );

        // PROOF: All files are aggregated
        assert_eq!(event.video_file_id, Some(video_id));
        assert_eq!(event.subtitle_file_ids.len(), 2);
        assert_eq!(event.image_file_ids.len(), 1);
        assert!(event.subtitle_file_ids.contains(&sub1_id));
        assert!(event.subtitle_file_ids.contains(&sub2_id));
        assert!(event.image_file_ids.contains(&image_id));
    }

    /// PROVES: EpisodeResolved fingerprint is deterministic
    #[test]
    fn test_episode_resolved_fingerprint_is_deterministic() {
        let video_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();
        let sub_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440001").unwrap();

        let event1 = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![sub_id],
            vec![],
            0.95,
        );

        let event2 = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![sub_id],
            vec![],
            0.95,
        );

        // PROOF: Fingerprints are identical
        assert_eq!(
            event1.fingerprint, event2.fingerprint,
            "EpisodeResolved fingerprint MUST be deterministic"
        );
    }

    /// PROVES: EpisodeResolved event_id is derived from fingerprint
    #[test]
    fn test_episode_resolved_event_id_from_fingerprint() {
        let video_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let event1 = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![],
            vec![],
            0.95,
        );

        let event2 = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![],
            vec![],
            0.95,
        );

        // PROOF: event_id is deterministic
        assert_eq!(
            event1.event_id(),
            event2.event_id(),
            "EpisodeResolved event_id MUST be deterministic"
        );
    }
}

#[cfg(test)]
mod file_resolved_tests {
    use crate::events::resolution_events::FileResolved;
    use crate::events::DomainEvent;
    use std::path::PathBuf;
    use uuid::Uuid;

    /// PROVES: FileResolved has all required fields
    #[test]
    fn test_file_resolved_has_required_fields() {
        let file_id = Uuid::new_v4();
        let path = PathBuf::from("/test/anime/Episode 01.mkv");

        let event = FileResolved::new(
            file_id,
            path.clone(),
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            "video".to_string(),
            0.95,
            "filename".to_string(),
            "fp:test_fingerprint".to_string(),
        );

        // PROOF: All fields are populated
        assert_eq!(event.file_id, file_id);
        assert_eq!(event.path, path);
        assert_eq!(event.anime_title, "Test Anime");
        assert_eq!(event.episode_number, "1");
        assert_eq!(event.file_role, "video");
        assert_eq!(event.source, "filename");
        assert!((event.confidence - 0.95).abs() < 0.001);
        assert!(!event.fingerprint.is_empty());
    }

    /// PROVES: FileResolved with matched IDs includes them
    #[test]
    fn test_file_resolved_with_matched_ids() {
        let file_id = Uuid::new_v4();
        let anime_id = Uuid::new_v4();
        let episode_id = Uuid::new_v4();

        let event = FileResolved::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            "Test Anime".to_string(),
            Some(anime_id),
            "1".to_string(),
            Some(episode_id),
            "video".to_string(),
            0.95,
            "filename".to_string(),
            "fp:test_fingerprint".to_string(),
        );

        // PROOF: Matched IDs are included
        assert_eq!(event.matched_anime_id, Some(anime_id));
        assert_eq!(event.matched_episode_id, Some(episode_id));
    }
}

#[cfg(test)]
mod fingerprint_tests {
    use crate::domain::resolution::{
        FileRole, ResolutionConfidence, ResolutionFailure, ResolutionFailureReason,
        ResolutionSource, ResolvedAnimeIntent, ResolvedEpisodeIntent, ResolvedEpisodeNumber,
        ResolvedFile,
    };
    use std::path::PathBuf;
    use uuid::Uuid;

    /// PROVES: ResolvedFile fingerprint is deterministic
    #[test]
    fn test_resolved_file_fingerprint_determinism() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let resolved1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let resolved2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // PROOF: Fingerprints are identical
        assert_eq!(
            resolved1.fingerprint(),
            resolved2.fingerprint(),
            "ResolvedFile fingerprint MUST be deterministic"
        );
    }

    /// PROVES: ResolutionFailure fingerprint is deterministic
    #[test]
    fn test_resolution_failure_fingerprint_determinism() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let failure1 = ResolutionFailure::new(
            file_id,
            PathBuf::from("/test/unknown.bin"),
            ResolutionFailureReason::UnsupportedFileType,
            "Not a video file".to_string(),
        );

        let failure2 = ResolutionFailure::new(
            file_id,
            PathBuf::from("/test/unknown.bin"),
            ResolutionFailureReason::UnsupportedFileType,
            "Not a video file".to_string(),
        );

        // PROOF: Fingerprints are identical
        assert_eq!(
            failure1.fingerprint(),
            failure2.fingerprint(),
            "ResolutionFailure fingerprint MUST be deterministic"
        );
    }

    /// PROVES: Different failures have different fingerprints
    #[test]
    fn test_different_failures_have_different_fingerprints() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let failure1 = ResolutionFailure::new(
            file_id,
            PathBuf::from("/test/unknown.bin"),
            ResolutionFailureReason::UnsupportedFileType,
            "Not a video file".to_string(),
        );

        let failure2 = ResolutionFailure::new(
            file_id,
            PathBuf::from("/test/unknown.bin"),
            ResolutionFailureReason::UnparsableFilename,
            "Cannot parse filename".to_string(),
        );

        // PROOF: Different reasons produce different fingerprints
        assert_ne!(
            failure1.fingerprint(),
            failure2.fingerprint(),
            "Different failure reasons MUST produce different fingerprints"
        );
    }
}


--- FILE: src-tauri\src\services\resolution_service_tests.rs ---
// src-tauri/src/services/resolution_service_tests.rs
//
// PHASE 4 HARDENED TESTS - CORRECTED
//
// These tests PROVE that Phase 4 corrections are complete.
// They enforce impossibility, not intention.
//
// CORRECTIONS APPLIED:
// - REMOVED: ResolutionFingerprint::from_result (hallucinated API)
// - FIXED: UnparsableTitle ‚Üí UnparsableFilename
// - FIXED: UnparsableEpisodeNumber ‚Üí NoEpisodeNumber
// - Uses only canonical enum variants

#[cfg(test)]
mod idempotency_enforcement_tests {
    use crate::domain::resolution::{
        FileRole, ResolutionConfidence, ResolutionSource, ResolvedAnimeIntent,
        ResolvedEpisodeIntent, ResolvedEpisodeNumber, ResolvedFile,
    };
    use std::collections::HashSet;
    use std::path::PathBuf;
    use uuid::Uuid;

    /// PROVES: Identical input produces identical fingerprint
    #[test]
    fn test_fingerprint_is_deterministic() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let resolved1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let resolved2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // PROOF: Fingerprints are byte-for-byte identical
        assert_eq!(
            resolved1.fingerprint(),
            resolved2.fingerprint(),
            "Identical input MUST produce identical fingerprint"
        );
    }

    /// PROVES: Different input produces different fingerprint
    #[test]
    fn test_fingerprint_uniqueness() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let resolved1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let resolved2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 02.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 2 }, // Different episode
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // PROOF: Different episodes have different fingerprints
        assert_ne!(
            resolved1.fingerprint(),
            resolved2.fingerprint(),
            "Different input MUST produce different fingerprint"
        );
    }

    /// PROVES: Fingerprint can be used for idempotency tracking
    #[test]
    fn test_fingerprint_set_deduplication() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let resolved = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let mut fingerprint_set: HashSet<String> = HashSet::new();

        // First insertion succeeds
        let fp1 = resolved.fingerprint().to_string();
        assert!(
            fingerprint_set.insert(fp1.clone()),
            "First fingerprint insertion MUST succeed"
        );

        // Second insertion of same fingerprint fails (deduplication)
        let fp2 = resolved.fingerprint().to_string();
        assert!(
            !fingerprint_set.insert(fp2),
            "Duplicate fingerprint insertion MUST fail"
        );

        // Set contains exactly one entry
        assert_eq!(
            fingerprint_set.len(),
            1,
            "Fingerprint set MUST contain exactly one entry after deduplication"
        );
    }

    /// PROVES: Fingerprints work for both success and failure results
    #[test]
    fn test_fingerprint_for_success_and_failure() {
        use crate::domain::resolution::{ResolutionFailure, ResolutionFailureReason};

        let file_id = Uuid::new_v4();

        let success = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        let failure = ResolutionFailure::new(
            file_id,
            PathBuf::from("/test/unknown.bin"),
            ResolutionFailureReason::UnsupportedFileType,
            "Not supported".to_string(),
        );

        let fp_success = success.fingerprint();
        let fp_failure = failure.fingerprint();

        // PROOF: Both success and failure produce valid fingerprints
        assert!(!fp_success.hash().is_empty(), "Success fingerprint MUST NOT be empty");
        assert!(!fp_failure.hash().is_empty(), "Failure fingerprint MUST NOT be empty");

        // PROOF: Success and failure fingerprints are different
        assert_ne!(
            fp_success.hash(),
            fp_failure.hash(),
            "Success and failure fingerprints MUST be different"
        );
    }
}

#[cfg(test)]
mod episode_resolved_reachability_tests {
    use crate::events::resolution_events::EpisodeResolved;
    use crate::events::DomainEvent;
    use uuid::Uuid;

    /// PROVES: EpisodeResolved can be constructed
    #[test]
    fn test_episode_resolved_is_constructable() {
        let video_id = Uuid::new_v4();
        let sub_id = Uuid::new_v4();

        let event = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![sub_id],
            vec![],
            0.95,
        );

        // PROOF: Event is constructed with all fields populated
        assert_eq!(event.anime_title, "Test Anime");
        assert_eq!(event.episode_number, "1");
        assert_eq!(event.video_file_id, Some(video_id));
        assert_eq!(event.subtitle_file_ids.len(), 1);
        assert!(!event.fingerprint.is_empty());
    }

    /// PROVES: EpisodeResolved fingerprint is deterministic
    #[test]
    fn test_episode_resolved_fingerprint_determinism() {
        let video_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();
        let sub_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440001").unwrap();

        let event1 = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![sub_id],
            vec![],
            0.95,
        );

        let event2 = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![sub_id],
            vec![],
            0.95,
        );

        // PROOF: Identical input produces identical fingerprint
        assert_eq!(
            event1.fingerprint, event2.fingerprint,
            "EpisodeResolved fingerprint MUST be deterministic"
        );
    }

    /// PROVES: EpisodeResolved event_id is derived from fingerprint (deterministic)
    #[test]
    fn test_episode_resolved_event_id_determinism() {
        let video_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let event1 = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![],
            vec![],
            0.95,
        );

        let event2 = EpisodeResolved::new(
            "Test Anime".to_string(),
            None,
            "1".to_string(),
            None,
            Some(video_id),
            vec![],
            vec![],
            0.95,
        );

        // PROOF: event_id is deterministic
        assert_eq!(
            event1.event_id(),
            event2.event_id(),
            "EpisodeResolved event_id MUST be deterministic"
        );
    }
}

#[cfg(test)]
mod dead_variant_elimination_tests {
    use crate::domain::resolution::{
        FileRole, ResolutionFailureReason, ResolutionSource, ResolvedEpisodeNumber,
    };

    /// PROVES: FileRole has exactly 3 variants (Auxiliary removed)
    #[test]
    fn test_file_role_has_no_auxiliary() {
        // Exhaustive match proves no other variants exist
        let roles = [FileRole::Video, FileRole::Subtitle, FileRole::Image];

        for role in &roles {
            match role {
                FileRole::Video => assert_eq!(role.to_string(), "video"),
                FileRole::Subtitle => assert_eq!(role.to_string(), "subtitle"),
                FileRole::Image => assert_eq!(role.to_string(), "image"),
                // If Auxiliary existed, this would not compile
            }
        }

        // PROOF: Exactly 3 variants
        assert_eq!(roles.len(), 3, "FileRole MUST have exactly 3 variants");
    }

    /// PROVES: ResolutionSource has exactly 2 variants (FolderHierarchy, DatabaseMatch, Combined removed)
    #[test]
    fn test_resolution_source_has_no_dead_variants() {
        let sources = [ResolutionSource::Filename, ResolutionSource::FolderName];

        for source in &sources {
            match source {
                ResolutionSource::Filename => assert_eq!(source.to_string(), "filename"),
                ResolutionSource::FolderName => assert_eq!(source.to_string(), "folder_name"),
                // If dead variants existed, this would not compile
            }
        }

        // PROOF: Exactly 2 variants
        assert_eq!(sources.len(), 2, "ResolutionSource MUST have exactly 2 variants");
    }

    /// PROVES: ResolvedEpisodeNumber has exactly 2 variants (Range removed)
    #[test]
    fn test_resolved_episode_number_has_no_range() {
        let numbers = [
            ResolvedEpisodeNumber::Regular { number: 1 },
            ResolvedEpisodeNumber::Special {
                label: "OVA".to_string(),
            },
        ];

        for num in &numbers {
            match num {
                ResolvedEpisodeNumber::Regular { number } => {
                    assert_eq!(num.to_string(), number.to_string())
                }
                ResolvedEpisodeNumber::Special { label } => assert_eq!(num.to_string(), *label),
                // If Range existed, this would not compile
            }
        }

        // PROOF: Exactly 2 variants
        assert_eq!(
            numbers.len(),
            2,
            "ResolvedEpisodeNumber MUST have exactly 2 variants"
        );
    }

    /// PROVES: ResolutionFailureReason has exactly 5 canonical variants
    /// CORRECTED: UnparsableTitle ‚Üí UnparsableFilename, UnparsableEpisodeNumber ‚Üí NoEpisodeNumber
    #[test]
    fn test_resolution_failure_reason_has_canonical_variants() {
        let reasons = [
            ResolutionFailureReason::UnparsableFilename,
            ResolutionFailureReason::NoEpisodeNumber,
            ResolutionFailureReason::LowConfidence,
            ResolutionFailureReason::UnsupportedFileType,
            ResolutionFailureReason::RepositoryError,
        ];

        for reason in &reasons {
            match reason {
                ResolutionFailureReason::UnparsableFilename => {
                    assert_eq!(reason.to_string(), "unparsable_filename")
                }
                ResolutionFailureReason::NoEpisodeNumber => {
                    assert_eq!(reason.to_string(), "no_episode_number")
                }
                ResolutionFailureReason::LowConfidence => {
                    assert_eq!(reason.to_string(), "low_confidence")
                }
                ResolutionFailureReason::UnsupportedFileType => {
                    assert_eq!(reason.to_string(), "unsupported_file_type")
                }
                ResolutionFailureReason::RepositoryError => {
                    assert_eq!(reason.to_string(), "repository_error")
                }
                // If dead variants existed, this would not compile
            }
        }

        // PROOF: Exactly 5 variants
        assert_eq!(
            reasons.len(),
            5,
            "ResolutionFailureReason MUST have exactly 5 variants"
        );
    }
}

#[cfg(test)]
mod determinism_tests {
    use crate::domain::resolution::{
        FileRole, ResolutionConfidence, ResolutionFailure, ResolutionFailureReason,
        ResolutionSource, ResolvedAnimeIntent, ResolvedEpisodeIntent, ResolvedEpisodeNumber,
        ResolvedFile,
    };
    use std::path::PathBuf;
    use uuid::Uuid;

    /// PROVES: ResolvedFile has no timestamp field
    #[test]
    fn test_resolved_file_has_no_timestamp() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let resolved1 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // Wait to ensure time passes
        std::thread::sleep(std::time::Duration::from_millis(10));

        let resolved2 = ResolvedFile::new(
            file_id,
            PathBuf::from("/test/anime/Episode 01.mkv"),
            FileRole::Video,
            ResolvedAnimeIntent::from_parsed_title(
                "Test Anime".to_string(),
                ResolutionSource::Filename,
            ),
            ResolvedEpisodeIntent::from_parsed_number(
                ResolvedEpisodeNumber::Regular { number: 1 },
                ResolutionSource::Filename,
            ),
            ResolutionConfidence::high(),
        );

        // PROOF: Fingerprints are identical despite time difference
        assert_eq!(
            resolved1.fingerprint(),
            resolved2.fingerprint(),
            "ResolvedFile MUST NOT contain timestamps"
        );
    }

    /// PROVES: ResolutionFailure has no timestamp field
    #[test]
    fn test_resolution_failure_has_no_timestamp() {
        let file_id = Uuid::parse_str("550e8400-e29b-41d4-a716-446655440000").unwrap();

        let failure1 = ResolutionFailure::new(
            file_id,
            PathBuf::from("/test/unknown.bin"),
            ResolutionFailureReason::UnsupportedFileType,
            "Not supported".to_string(),
        );

        // Wait to ensure time passes
        std::thread::sleep(std::time::Duration::from_millis(10));

        let failure2 = ResolutionFailure::new(
            file_id,
            PathBuf::from("/test/unknown.bin"),
            ResolutionFailureReason::UnsupportedFileType,
            "Not supported".to_string(),
        );

        // PROOF: Fingerprints are identical despite time difference
        assert_eq!(
            failure1.fingerprint(),
            failure2.fingerprint(),
            "ResolutionFailure MUST NOT contain timestamps"
        );
    }
}

#[cfg(test)]
mod resolution_rules_tests {
    use crate::services::resolution_service::ResolutionRules;
    use crate::domain::resolution::{ResolutionSource, ResolvedEpisodeNumber};
    use std::path::PathBuf;

    #[test]
    fn test_parse_anime_title_from_filename() {
        let rules = ResolutionRules::default();

        // [SubGroup] Anime Title - 01 [1080p].mkv
        let path = PathBuf::from("[SubGroup] Steins Gate - 01 [1080p].mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, source) = result.unwrap();
        assert_eq!(title, "Steins Gate");
        assert_eq!(source, ResolutionSource::Filename);

        // Anime Title - 01.mkv
        let path = PathBuf::from("Attack on Titan - 01.mkv");
        let result = rules.parse_anime_title(&path);
        assert!(result.is_some());
        let (title, _) = result.unwrap();
        assert_eq!(title, "Attack on Titan");
    }

    #[test]
    fn test_parse_episode_number() {
        let rules = ResolutionRules::default();

        // - 01
        let path = PathBuf::from("Anime - 01.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 1 });

        // S01E05
        let path = PathBuf::from("Anime S01E05.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert_eq!(num, ResolvedEpisodeNumber::Regular { number: 5 });

        // OVA
        let path = PathBuf::from("Anime OVA.mkv");
        let result = rules.parse_episode_number(&path);
        assert!(result.is_some());
        let (num, _) = result.unwrap();
        assert!(matches!(num, ResolvedEpisodeNumber::Special { .. }));
    }

    #[test]
    fn test_normalize_title() {
        let rules = ResolutionRules::default();

        assert_eq!(rules.normalize_title("Steins;Gate"), "steins gate");
        assert_eq!(rules.normalize_title("Attack_on_Titan"), "attack on titan");
        assert_eq!(rules.normalize_title("Re:Zero"), "re zero");
    }
}


--- FILE: src-tauri\src\services\services\mod.rs ---
// Module root ‚Äî intentionally empty


--- FILE: src-tauri\src\services\statistics_service.rs ---
// src-tauri/src/services/statistics_service.rs
use crate::domain::episode::EpisodeState;
use crate::domain::statistics::{
    AnimeStatistics, GlobalStatistics, StatisticsSnapshot, StatisticsType,
};
use crate::error::AppResult;
use crate::events::{EpisodeCompleted, EventBus, StatisticsUpdated};
use crate::repositories::{AnimeRepository, EpisodeRepository, StatisticsRepository};
use chrono::Utc;
use std::sync::Arc;
use uuid::Uuid;

pub struct StatisticsService {
    statistics_repo: Arc<dyn StatisticsRepository>,
    anime_repo: Arc<dyn AnimeRepository>,
    episode_repo: Arc<dyn EpisodeRepository>,
    event_bus: Arc<EventBus>,
}

impl StatisticsService {
    pub fn new(
        statistics_repo: Arc<dyn StatisticsRepository>,
        anime_repo: Arc<dyn AnimeRepository>,
        episode_repo: Arc<dyn EpisodeRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            statistics_repo,
            anime_repo,
            episode_repo,
            event_bus,
        }
    }

    pub fn calculate_global_statistics(&self) -> AppResult<GlobalStatistics> {
        let animes = self.anime_repo.list_all()?;
        let mut total_episodes = 0;
        let mut episodes_assistidos = 0;
        let mut tempo_total_assistido = 0u64;
        let mut animes_em_progresso = 0;
        let mut animes_completos = 0;

        for anime in &animes {
            let episodes = self.episode_repo.list_by_anime(anime.id)?;
            let mut anime_has_progress = false;
            let mut all_episodes_done = !episodes.is_empty();

            for ep in &episodes {
                total_episodes += 1;
                tempo_total_assistido += ep.progresso_atual;

                if ep.estado == EpisodeState::Concluido {
                    episodes_assistidos += 1;
                    anime_has_progress = true;
                } else if ep.progresso_atual > 0 {
                    anime_has_progress = true;
                    all_episodes_done = false;
                } else {
                    all_episodes_done = false;
                }
            }

            if all_episodes_done {
                animes_completos += 1;
            } else if anime_has_progress {
                animes_em_progresso += 1;
            }
        }

        let stats = GlobalStatistics {
            total_animes: animes.len() as u32,
            total_episodes,
            episodes_assistidos,
            tempo_total_assistido,
            animes_em_progresso,
            animes_completos,
        };

        let snapshot =
            StatisticsSnapshot::new(StatisticsType::Global, serde_json::to_value(&stats)?);

        self.statistics_repo.save_snapshot(&snapshot)?;
        Ok(stats)
    }

    pub fn register_event_handlers(&self) {
        let episode_repo = Arc::clone(&self.episode_repo);
        let statistics_repo = Arc::clone(&self.statistics_repo);
        let event_bus = Arc::clone(&self.event_bus);

        self.event_bus
            .subscribe::<EpisodeCompleted, _>(move |event| {
                if let Ok(episodes) = episode_repo.list_by_anime(event.anime_id) {
                    let total_episodes = episodes.len() as u32;
                    let mut episodes_assistidos = 0;
                    let mut tempo_assistido = 0u64;

                    for ep in &episodes {
                        if ep.estado == EpisodeState::Concluido {
                            episodes_assistidos += 1;
                        }
                        tempo_assistido += ep.progresso_atual;
                    }

                    let progresso_percentual = if total_episodes > 0 {
                        (episodes_assistidos as f32 / total_episodes as f32) * 100.0
                    } else {
                        0.0
                    };

                    let stats = AnimeStatistics {
                        anime_id: event.anime_id,
                        total_episodes,
                        episodes_assistidos,
                        tempo_assistido,
                        progresso_percentual,
                        ultimo_episodio_assistido: Some(event.episode_id),
                        data_ultima_visualizacao: Some(Utc::now()),
                    };

                    let snapshot = StatisticsSnapshot::new(
                        StatisticsType::PorAnime {
                            anime_id: event.anime_id,
                        },
                        serde_json::to_value(&stats).unwrap(),
                    );

                    let _ = statistics_repo.save_snapshot(&snapshot);
                }
                event_bus.emit(StatisticsUpdated::new());
            });
    }
}


--- FILE: src-tauri\src\services\subtitle_service.rs ---
// src-tauri/src/services/subtitle_service.rs
use crate::domain::subtitle::{SubtitleFormat, SubtitleTransformation, TransformationType};
use crate::error::{AppError, AppResult};
use crate::events::{
    EventBus, SubtitleStyleApplied, SubtitleTimingAdjusted, SubtitleVersionCreated,
};
use crate::infrastructure::subtitle_workspace::{
    SubtitleWorkspace, SubtitleWorkspaceCleaned, SubtitleWorkspaceCreated,
};
use crate::repositories::{FileRepository, SubtitleRepository};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use uuid::Uuid;

#[derive(Debug, Clone)]
pub struct StyleTransformRequest {
    pub subtitle_id: Uuid,
    pub font_name: Option<String>,
    pub font_size: Option<u32>,
    pub primary_color: Option<String>,
    pub outline_color: Option<String>,
    pub outline_width: Option<f32>,
    pub shadow_offset: Option<f32>,
}

#[derive(Debug, Clone)]
pub struct TimingTransformRequest {
    pub subtitle_id: Uuid,
    pub offset_ms: i64,
}

pub struct SubtitleService {
    subtitle_repo: Arc<dyn SubtitleRepository>,
    file_repo: Arc<dyn FileRepository>,
    event_bus: Arc<EventBus>,
}

impl SubtitleService {
    pub fn new(
        subtitle_repo: Arc<dyn SubtitleRepository>,
        file_repo: Arc<dyn FileRepository>,
        event_bus: Arc<EventBus>,
    ) -> Self {
        Self {
            subtitle_repo,
            file_repo,
            event_bus,
        }
    }

    pub fn apply_style_transformation(&self, request: StyleTransformRequest) -> AppResult<Uuid> {
        let params = serde_json::json!({
            "font_name": request.font_name,
            "font_size": request.font_size,
        });

        self.execute_transformation_pipeline(
            request.subtitle_id,
            TransformationType::Style,
            params,
            |path, format| self.apply_style_to_file(path, format, &request),
            |original_id, new_id| {
                self.event_bus
                    .emit(SubtitleStyleApplied::new(original_id, new_id));
            },
        )
    }

    pub fn apply_timing_transformation(&self, request: TimingTransformRequest) -> AppResult<Uuid> {
        let params = serde_json::json!({ "offset_ms": request.offset_ms });
        self.execute_transformation_pipeline(
            request.subtitle_id,
            TransformationType::Timing,
            params,
            |path, format| self.apply_timing_to_file(path, format, request.offset_ms),
            |original_id, new_id| {
                self.event_bus.emit(SubtitleTimingAdjusted::new(
                    original_id,
                    new_id,
                    request.offset_ms,
                ));
            },
        )
    }

    pub fn get_transformation_history(
        &self,
        subtitle_id: Uuid,
    ) -> AppResult<Vec<SubtitleTransformation>> {
        self.subtitle_repo.get_transformations(subtitle_id)
    }

    fn execute_transformation_pipeline<F, E>(
        &self,
        subtitle_id: Uuid,
        trans_type: TransformationType,
        params: serde_json::Value,
        transform_fn: F,
        emit_custom_event: E,
    ) -> AppResult<Uuid>
    where
        F: FnOnce(&Path, &SubtitleFormat) -> AppResult<()>,
        E: FnOnce(Uuid, Uuid),
    {
        let original = self
            .subtitle_repo
            .get_subtitle_by_id(subtitle_id)?
            .ok_or(AppError::NotFound)?;

        let original_file = self
            .file_repo
            .get_by_id(original.file_id)?
            .ok_or(AppError::NotFound)?;

        let mut workspace = SubtitleWorkspace::new(original_file.caminho_absoluto.clone())?;
        self.event_bus
            .emit(SubtitleWorkspaceCreated::new(workspace.id, original.id));

        transform_fn(workspace.working_file_path(), &original.formato)?;

        let new_file_path =
            self.generate_versioned_path(&original_file.caminho_absoluto, original.versao + 1);
        workspace.copy_working_file_to(&new_file_path)?;

        let file_metadata = std::fs::metadata(&new_file_path)?;
        let new_file = crate::domain::file::File::new(
            new_file_path,
            crate::domain::file::FileType::Legenda,
            file_metadata.len(),
            chrono::DateTime::from(
                file_metadata
                    .modified()
                    .unwrap_or(std::time::SystemTime::now()),
            ),
            crate::domain::file::FileOrigin::Manual,
        );

        self.file_repo.save(&new_file)?;

        let new_subtitle = original.derive_from(new_file.id, original.formato);
        self.subtitle_repo.save_subtitle(&new_subtitle)?;

        let transformation = SubtitleTransformation::new(original.id, trans_type, params);
        self.subtitle_repo.save_transformation(&transformation)?;

        emit_custom_event(original.id, new_subtitle.id);
        self.event_bus.emit(SubtitleVersionCreated::new(
            new_subtitle.id,
            new_subtitle.versao,
        ));

        workspace.cleanup()?;
        self.event_bus
            .emit(SubtitleWorkspaceCleaned::new(workspace.id));

        Ok(new_subtitle.id)
    }

    fn apply_style_to_file(
        &self,
        file_path: &Path,
        format: &SubtitleFormat,
        request: &StyleTransformRequest,
    ) -> AppResult<()> {
        match format {
            SubtitleFormat::ASS => self.apply_style_to_ass(file_path, request),
            _ => Ok(()),
        }
    }

    fn apply_timing_to_file(
        &self,
        file_path: &Path,
        format: &SubtitleFormat,
        offset_ms: i64,
    ) -> AppResult<()> {
        match format {
            SubtitleFormat::ASS => self.apply_timing_to_ass(file_path, offset_ms),
            SubtitleFormat::SRT | SubtitleFormat::VTT => {
                self.apply_timing_to_srt(file_path, offset_ms)
            }
        }
    }

    fn generate_versioned_path(&self, original: &PathBuf, version: u32) -> PathBuf {
        let stem = original
            .file_stem()
            .and_then(|s| s.to_str())
            .unwrap_or("subtitle");
        let ext = original
            .extension()
            .and_then(|e| e.to_str())
            .unwrap_or("srt");
        let parent = original.parent().unwrap_or(Path::new("."));
        parent.join(format!("{}.v{}.{}", stem, version, ext))
    }

    fn apply_style_to_ass(&self, path: &Path, request: &StyleTransformRequest) -> AppResult<()> {
        let content = std::fs::read_to_string(path)?;
        let mut lines: Vec<String> = content.lines().map(|s| s.to_string()).collect();
        let mut in_styles = false;

        for line in lines.iter_mut() {
            if line.starts_with("[V4+ Styles]") {
                in_styles = true;
                continue;
            }
            if in_styles && line.starts_with("Style:") {
                let parts: Vec<&str> = line.split(',').collect();
                if parts.len() > 10 {
                    let mut new_parts: Vec<String> = parts.iter().map(|&s| s.to_string()).collect();
                    if let Some(ref font) = request.font_name {
                        new_parts[1] = font.clone();
                    }
                    if let Some(size) = request.font_size {
                        new_parts[2] = size.to_string();
                    }
                    *line = new_parts.join(",");
                }
            }
            if in_styles && line.is_empty() {
                in_styles = false;
            }
        }
        std::fs::write(path, lines.join("\n"))?;
        Ok(())
    }

    fn apply_timing_to_ass(&self, _path: &Path, _offset_ms: i64) -> AppResult<()> {
        Ok(())
    }
    fn apply_timing_to_srt(&self, _path: &Path, _offset_ms: i64) -> AppResult<()> {
        Ok(())
    }
}


--- FILE: src-tauri\tauri.conf.json ---
{
    "$schema": "../gen/schemas/desktop-schema.json",
    "productName": "AnimeHub",
    "version": "0.1.0",
    "identifier": "com.animehub.app",
    "build": {
        "beforeDevCommand": "npm run dev",
        "beforeBuildCommand": "npm run build",
        "devUrl": "http://localhost:5173"
    },
    "app": {
        "windows": [
            {
                "title": "AnimeHub",
                "width": 1280,
                "height": 800,
                "resizable": true,
                "fullscreen": false
            }
        ],
        "security": {
            "csp": null
        }
    },
    "plugins": {
        "dialog": null
    }
}

--- FILE: src\app.css ---


--- FILE: src\app.html ---
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <link rel="icon" href="%sveltekit.assets%/favicon.png" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    %sveltekit.head%
</head>

<body data-sveltekit-preload-data="hover">
    <div style="display: contents">%sveltekit.body%</div>
</body>

</html>

--- FILE: src\lib\api\anime.ts ---


--- FILE: src\lib\api\episode.ts ---


--- FILE: src\lib\api\file.ts ---


--- FILE: src\lib\api\playback.ts ---


--- FILE: src\lib\api\subtitle.ts ---


--- FILE: src\lib\components\anime\AnimeHeader.svelte ---


--- FILE: src\lib\components\anime\EpisodeItem.svelte ---


--- FILE: src\lib\components\anime\EpisodeList.svelte ---


--- FILE: src\lib\components\common\Sidebar.svelte ---


--- FILE: src\lib\components\library\AnimeCard.svelte ---


--- FILE: src\lib\components\library\AnimeGrid.svelte ---


--- FILE: src\lib\stores\anime.ts ---


--- FILE: src\lib\stores\episode.ts ---


--- FILE: src\lib\stores\playback.ts ---


--- FILE: src\lib\stores\ui.ts ---


--- FILE: src\lib\types\anime.ts ---


--- FILE: src\lib\types\episode.ts ---


--- FILE: src\lib\types\events.ts ---


--- FILE: src\lib\types\file.ts ---


--- FILE: src\lib\types\subtitle.ts ---


--- FILE: src\routes\+layout.svelte ---


--- FILE: src\routes\+page.svelte ---


--- FILE: src\routes\anime\[id]\+page.svelte ---


--- FILE: src\routes\calendar\+page.svelte ---


--- FILE: src\routes\library\+page.svelte ---


--- FILE: src\routes\statistics\+page.svelte ---


--- FILE: src\routes\subtitles\+page.svelte ---


--- FILE: svelte.config.js ---
import adapter from '@sveltejs/adapter-static';
import { vitePreprocess } from '@sveltejs/vite-plugin-svelte';

/** @type {import('@sveltejs/kit').Config} */
const config = {
    preprocess: vitePreprocess(),

    kit: {
        adapter: adapter({
            pages: 'build',
            assets: 'build',
            fallback: 'index.html',
            precompress: false,
            strict: true
        }),
        alias: {
            $lib: './src/lib',
            $components: './src/lib/components',
            $stores: './src/lib/stores',
            $types: './src/lib/types',
            $api: './src/lib/api'
        }
    }
};

export default config;

--- FILE: tailwind.config.js ---
/** @type {import('tailwindcss').Config} */
export default {
    content: ['./src/**/*.{html,js,svelte,ts}'],
    theme: {
        extend: {
            colors: {
                // Dark mode palette
                background: {
                    primary: '#0a0a0a',
                    secondary: '#141414',
                    tertiary: '#1e1e1e'
                },
                text: {
                    primary: '#ffffff',
                    secondary: '#a0a0a0',
                    tertiary: '#707070'
                },
                accent: {
                    primary: '#3b82f6',
                    hover: '#2563eb'
                },
                state: {
                    completed: '#22c55e',
                    progress: '#f59e0b',
                    unwatched: '#6b7280',
                    error: '#ef4444'
                }
            },
            fontFamily: {
                sans: ['Inter', 'system-ui', 'sans-serif']
            }
        }
    },
    plugins: []
};

--- FILE: vite.config.ts ---
import { defineConfig } from 'vite';
import { sveltekit } from '@sveltejs/kit/vite';

export default defineConfig({
    plugins: [sveltekit()],
    clearScreen: false,
    server: {
        port: 5173,
        strictPort: true,
        watch: {
            ignored: ['**/src-tauri/**']
        }
    },
    envPrefix: ['VITE_', 'TAURI_'],
    build: {
        target: 'esnext',
        minify: !process.env.TAURI_DEBUG ? 'esbuild' : false,
        sourcemap: !!process.env.TAURI_DEBUG
    }
});
